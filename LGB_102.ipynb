{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Graident Boosting\n",
        "canonical lncRNA, -1 threshold, cross-valiation, middle-exclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "bfaea8a3-43bb-4d4a-dbf1-d903a7ea49c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-20 15:21:50.528187\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "7524d4a5-7073-4727-f11c-530ab187a0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/Localization/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATA_DIR=\"/\"\n",
        "    MODEL_DIR=\"/\"\n",
        "print(DATA_DIR)\n",
        "SAVE_MODEL_FILENAME = None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX-UEr8FLA8",
        "outputId": "9d11b4eb-414e-4300-d32c-2596540910df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.16\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import numpy as np\n",
        "np.random.seed(42) # supposedly sets scikit-learn\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "from matplotlib import pyplot as plt \n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
        "\n",
        "K=5\n",
        "ALPHABET=4**K + 1\n",
        "EPOCHS=150 \n",
        "RCI_THRESHOLD_MECHANISM = 'ZERO'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
        "RCI_THRESHOLD_VALUE = -1  # use -1 for lncRNA, use 0 for mRNA\n",
        "BREAK = False   # optionally break after first fold\n",
        "EXCLUSIONS = [1]   # possibly exclude cell line 1 = H1.hESC\n",
        "FILTER_TRAIN        = True\n",
        "FILTER_TAILS_TRAIN  = False\n",
        "FILTER_MIDDLE_TRAIN = True\n",
        "FILTER_TEST         = True\n",
        "FILTER_TAILS_TEST   = False\n",
        "FILTER_MIDDLE_TEST  = True\n",
        "MIDDLE_LOW          = -2   # -2 for lncRNA, -1 for mRNA\n",
        "MIDDLE_HIGH         = 0    #  0 for lncRNA, +1 for mRNA\n",
        "\n",
        "REPEATS = 2\n",
        "FOLDS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "LnkpVKdMFLA-"
      },
      "outputs": [],
      "source": [
        "RCI_FILE_TRAIN = 'train.lncRNA_RCI.all_cell_lines.csv'\n",
        "RCI_FILE_TEST  = None # use None for cross-validation\n",
        "\n",
        "SEQ_FILE_TRAIN = 'train.canon_lncRNA_transcripts.csv'\n",
        "SEQ_FILE_TEST  = None # use None for cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "e3p4QzQJFLA_"
      },
      "outputs": [],
      "source": [
        "def get_ordered_list():\n",
        "    ordered_list = \\\n",
        "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
        "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
        "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
        "    return ordered_list\n",
        "all_cell_lines = get_ordered_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self):\n",
        "        self.cache=dict() \n",
        "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
        "        self.gene2rci = dict()\n",
        "        \n",
        "    def load_gene_rci_values(self,filepath,exclusions):\n",
        "        '''\n",
        "        Load all the genes from the given RCI csv file.\n",
        "        The given file usually contains train or test, not both.\n",
        "        Return dict with keys=gene:str and values=RCI:float.\n",
        "        '''\n",
        "        self.gene2rci = {}\n",
        "        overall_sum = 0\n",
        "        with open (filepath,'r') as handle:\n",
        "            for row in handle:\n",
        "                line = row.strip()\n",
        "                fields = line.split(',')\n",
        "                gene_id = fields.pop(0)\n",
        "                cell_line_index = 0\n",
        "                rci_values = []\n",
        "                log_mean=0.0\n",
        "                for rci_str in fields:\n",
        "                    if cell_line_index not in exclusions:\n",
        "                        if rci_str != \"nan\":\n",
        "                            rci_val = float(rci_str)\n",
        "                            rci_values.append(rci_val)\n",
        "                    cell_line_index += 1\n",
        "                if len(rci_values)>0:\n",
        "                    values = np.array(rci_values)\n",
        "                    antilogs = [2**x for x in values]\n",
        "                    big_mean = np.mean(antilogs)\n",
        "                    # Avoid division by zero\n",
        "                    if np.absolute(big_mean)<0.000001:\n",
        "                        log_mean = -1000000 # neg infinity\n",
        "                    else:\n",
        "                        log_mean = np.log2(big_mean) \n",
        "                    self.gene2rci[gene_id] = log_mean\n",
        "        print('Number of RCI values loaded',len(self.gene2rci.keys()))\n",
        "        return self.gene2rci\n",
        "\n",
        "    def _seq_to_kmer_values(self,rna,K):\n",
        "        vec=[] # seq converted to list of K-mers \n",
        "        N_indicator = 0 # indicator value\n",
        "        length = len(rna)\n",
        "        for i in range(length-K+1):\n",
        "            kmer = rna[i:i+K]\n",
        "            if 'N' in kmer:\n",
        "                value = N_indicator\n",
        "            elif kmer in self.cache.keys():\n",
        "                value = self.cache[kmer]\n",
        "            else:\n",
        "                value = 0\n",
        "                for j in range(K):\n",
        "                    value *= 4   \n",
        "                    nextnuc = kmer[j] \n",
        "                    nucval = self.vals[nextnuc]\n",
        "                    value += nucval\n",
        "                value += 1   # NNN => 0, AAA => 1\n",
        "                self.cache[kmer] = value\n",
        "            vec.append(value)\n",
        "        return vec\n",
        "\n",
        "    def load_sequence(self,filepath):\n",
        "        '''\n",
        "        Load all the sequences from the given file. \n",
        "        Load our version of GenCode -- csv, easier to parse than fasta.\n",
        "        Each line has IDs plus sequence.\n",
        "        The IDs in the file do not include dot-version numbers.\n",
        "        The file may already be filtered e.g. canonical transcripts.\n",
        "        '''\n",
        "        allids=[]\n",
        "        allseq=[]\n",
        "        #NREPEAT = str('N'*MAXLEN)   # not used for MLP\n",
        "        with open (filepath,'r') as handle:\n",
        "            header = None\n",
        "            for row in handle:\n",
        "                if header is None:\n",
        "                    header = row\n",
        "                else:\n",
        "                    line    = row.strip()\n",
        "                    fields  = line.split(',')\n",
        "                    tran_id = fields[0]  # without version number\n",
        "                    gene_id = fields[1]  # without version number\n",
        "                    seq_len = int(fields[3])\n",
        "                    seq_txt = fields[4]\n",
        "                    # Keep only transcripts having numeric RCI given the cell lines in use.\n",
        "                    # We have validated this by spot checking.\n",
        "                    # TO DO: validate this programmatically.\n",
        "                    if gene_id in self.gene2rci.keys():\n",
        "                        allids.append( (gene_id,tran_id) )\n",
        "                        hot_vec = self._seq_to_kmer_values(seq_txt,K)\n",
        "                        allseq.append(hot_vec)\n",
        "        self.cache=dict() # save RAM\n",
        "        return allids,allseq\n",
        "\n",
        "    def load_spectra(self,filepath):\n",
        "        '''\n",
        "        Load all (variable-length) sequences as lists of kmers.\n",
        "        Then convert each sequence to (fixed-length) kmer histograms.\n",
        "        '''\n",
        "        allids,allseq = self.load_sequence(filepath)\n",
        "        allspectra = []\n",
        "        for seq in allseq:\n",
        "            spectrum = np.zeros(ALPHABET)\n",
        "            for kmer in seq:\n",
        "                spectrum[kmer] += 1\n",
        "            spectrum /= len(seq)\n",
        "            allspectra.append(spectrum)\n",
        "        return allids,allspectra        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    gbc = GBC()\n",
        "    return gbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-wufgFLBF",
        "outputId": "dd4cb553-d1f3-4433-eb86-52039513aa79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-20 15:21:52.382317\n",
            "GradientBoostingClassifier()\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "model=build_model()\n",
        "print(model)  # Print this only once\n",
        "model=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrC1alOKq07"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "W9xiFzNbFLBE"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "class CrossValidator():\n",
        "    def __init__(self,epochs,score_threshold=0.5):\n",
        "        self.epochs = epochs\n",
        "        self.score_threshold = score_threshold\n",
        "        self.mechanism = 'ZERO'\n",
        "        self.discriminator = RCI_THRESHOLD_VALUE\n",
        "        self.flip = False\n",
        "        self.reset_statistics()\n",
        "        \n",
        "    def reset_statistics(self):\n",
        "        self.cv_accuracy=[]\n",
        "        self.cv_precision=[]\n",
        "        self.cv_recall=[]\n",
        "        self.cv_f1=[]\n",
        "        self.cv_auprc=[]\n",
        "        self.cv_auroc=[]\n",
        "        self.cv_mcc=[]\n",
        "        \n",
        "    def _get_X_y(self, all_ids, all_seqs, rci_map): \n",
        "        # Prepare X and y for training or testing.\n",
        "        subsetX=[]\n",
        "        subsetY=[]\n",
        "        for t in range(len(all_ids)):\n",
        "            gene_id,tran_id = all_ids[t]\n",
        "            oneX            = all_seqs[t]\n",
        "            oneY            = rci_map[gene_id]\n",
        "            subsetX.append(oneX)\n",
        "            subsetY.append(oneY)\n",
        "        subsetX = np.array(subsetX)\n",
        "        subsetY = np.array(subsetY).reshape((-1,1))\n",
        "        return subsetX,subsetY\n",
        "    \n",
        "    def set_threshold_mechanism(self, mechanism):\n",
        "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
        "            raise Exception('Unrecognized mechansm:',mechanism)\n",
        "        self.mechanism = mechanism\n",
        "    \n",
        "    def _apply_threshold(self, array_of_rci):\n",
        "        # Takes list of float, returns list of labels [0,1].\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            labels = self.discriminator.predict(array_of_rci)\n",
        "            if self.flip:\n",
        "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
        "                labels = np.array(list(map(IS_CYTO, labels)))\n",
        "        else:  # 'THE_MEAN' or 'ZERO'\n",
        "            rci_threshold = self.discriminator\n",
        "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
        "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
        "        return labels\n",
        "    \n",
        "    def _prepare_threshold(self, rci_values, create=True):\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            if create:  # during training, create a new GMM\n",
        "                gmm = GaussianMixture(n_components=2, verbose=0, \n",
        "                  covariance_type='spherical', n_init=100) # random_state=42) \n",
        "                gmm.fit(rci_values)\n",
        "            else:   # during testing, use existing GMM\n",
        "                gmm=self.discriminator\n",
        "            self.flip = False\n",
        "            # The GMM labels are arbitrary.\n",
        "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
        "                self.flip = True\n",
        "            self.discriminator = gmm   # redundant but consistent\n",
        "        elif self.mechanism == 'THE_MEAN':\n",
        "            self.discriminator = np.mean(rci_values)\n",
        "        elif self.mechanism == 'ZERO':\n",
        "            self.discriminator = RCI_THRESHOLD_VALUE\n",
        "        else: # not expected\n",
        "            self.discriminator = 0\n",
        "    \n",
        "    def _explain_threshold(self):\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            gmm=self.discriminator\n",
        "            print('Discriminator is GMM')\n",
        "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
        "            print('Variances',gmm.covariances_)\n",
        "            print('Priors',gmm.weights_)\n",
        "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
        "            print(test_rcis)\n",
        "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
        "        else:\n",
        "            print('Discriminator',self.mechanism,self.discriminator)\n",
        "    \n",
        "    def _show_sizes(self,label,values):\n",
        "        a = np.count_nonzero(values==1)\n",
        "        b = np.count_nonzero(values==0)\n",
        "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
        "        \n",
        "    def save_model(self,filename):\n",
        "        if self.model is not None:\n",
        "            filepath = MODEL_DIR + filename\n",
        "            #self.model.save(filepath)\n",
        "            print('? Saved model to',filepath)\n",
        "        \n",
        "    def load_model(self,filename):\n",
        "        filepath = MODEL_DIR + filename\n",
        "        #self.model = keras.models.load_model(filepath)\n",
        "        print('? Loaded model from',filepath)\n",
        "        \n",
        "    def train_new_model(self,train_ids,train_seq,train_rci,\n",
        "            valid_ids=None,valid_seq=None,valid_rci=None):\n",
        "        print(datetime.now())\n",
        "        X_train,y_rci = self._get_X_y(train_ids,train_seq,train_rci) \n",
        "        self._prepare_threshold(y_rci,True)  \n",
        "        self._explain_threshold()\n",
        "        y_train = self._apply_threshold(y_rci)\n",
        "        self._show_sizes('Train',y_train)\n",
        "        if valid_ids is not None:\n",
        "            X_valid,y_rci = self._get_X_y(valid_ids,valid_seq,valid_rci) \n",
        "            y_valid = self._apply_threshold(y_rci)\n",
        "            self._show_sizes('Valid',y_valid)\n",
        "        y_rci = None\n",
        "\n",
        "        self.model=build_model()\n",
        "        \n",
        "        print(\"FIT\")\n",
        "        print(datetime.now())\n",
        "        self.model.fit(X_train, y_train) # sample weight\n",
        "\n",
        "    def test_without_training(self,test_ids,test_seq,test_rci):\n",
        "        # For final test, do no train.\n",
        "        # Assume set_sequences() set the test set.\n",
        "        print(datetime.now())\n",
        "        X_test,y_rci = self._get_X_y(test_ids,test_seq,test_rci) \n",
        "        y_test = self._apply_threshold(y_rci)\n",
        "        y_rci = None\n",
        "        \n",
        "        print(\"PREDICT\")\n",
        "        print(datetime.now())        \n",
        "        yhat_pairs=self.model.predict_proba(X_test)  # [ prob of 0, prob of 1 ]\n",
        "        yhat_pred=[pair[1] for pair in yhat_pairs]\n",
        "        yhat_classes=self.model.predict(X_test)  # 0 or 1\n",
        "        \n",
        "        print('debug pred',yhat_pred[:3])\n",
        "        print('debug class',yhat_classes[:3])\n",
        "\n",
        "        self._show_sizes('Test',y_test)\n",
        "        self._show_sizes('Predict',yhat_classes)\n",
        "        print('Test sizes',X_test.shape,y_test.shape)\n",
        "        print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
        "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "        print('Score threshold',self.score_threshold)\n",
        "        cm1 = confusion_matrix(y_test,yhat_classes)\n",
        "        print('Confusion matrix\\n',cm1)\n",
        "        cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
        "        print('Normalized matrix\\n',cm2)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
        "        precision = precision_score(y_test, yhat_classes)*100.\n",
        "        recall = recall_score(y_test, yhat_classes)*100.\n",
        "        f1 = f1_score(y_test, yhat_classes)*100.\n",
        "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
        "        auprc = auc(prc_X,prc_Y)*100.\n",
        "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
        "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
        "\n",
        "        correct_pos = 0\n",
        "        correct_neg = 0\n",
        "        wrong_pos = 0\n",
        "        wrong_neg = 0\n",
        "        for i in range(len(y_test)):\n",
        "            if yhat_pred[i]>=0.65:\n",
        "                if y_test[i]==1:\n",
        "                    correct_pos += 1\n",
        "                else:\n",
        "                    wrong_pos += 1\n",
        "            elif yhat_pred[i]<=0.35:\n",
        "                if y_test[i]==0:\n",
        "                    correct_neg += 1\n",
        "                else:\n",
        "                    wrong_neg += 1\n",
        "        print('Extreme scores correct, pos:neg',correct_pos,correct_neg)  \n",
        "        print('Extreme scores incorrect pos:neg',wrong_pos,wrong_neg)  \n",
        "\n",
        "        print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
        "        print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
        "        print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n",
        "\n",
        "        self.cv_accuracy.append(accuracy)\n",
        "        self.cv_precision.append(precision)\n",
        "        self.cv_recall.append(recall)\n",
        "        self.cv_f1.append(f1)\n",
        "        self.cv_mcc.append(mcc)\n",
        "        self.cv_auprc.append(auprc)\n",
        "        self.cv_auroc.append(auroc)\n",
        "\n",
        "    def get_statistics(self):\n",
        "        return \\\n",
        "        self.cv_accuracy,\\\n",
        "        self.cv_precision,\\\n",
        "        self.cv_recall,\\\n",
        "        self.cv_f1,\\\n",
        "        self.cv_mcc,\\\n",
        "        self.cv_auprc,\\\n",
        "        self.cv_auroc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td97uyyj5qDq"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "poe3rwAF4Ir7"
      },
      "outputs": [],
      "source": [
        "class Separator():\n",
        "    def __init__(self):\n",
        "        self.train_ids = []\n",
        "        self.train_seq = []\n",
        "        self.train_rci = dict()\n",
        "        self.val_ids = []\n",
        "        self.val_seq = []\n",
        "        self.val_rci = dict()\n",
        "    def load(self,data_dir,rep,fold):\n",
        "        filename='cv.{}.{}.validation_genes.txt'.format(rep,fold)\n",
        "        filename = data_dir + filename\n",
        "        self.val_genes = set()\n",
        "        print('Opening file',filename)\n",
        "        with open(filename,'r') as fin:\n",
        "            for line in fin:\n",
        "                gene_id = line.strip()\n",
        "                self.val_genes.add(gene_id)\n",
        "    def process(self,allids,allseq,gene_to_rci):\n",
        "        size = len(allids)\n",
        "        for t in range(size):\n",
        "            gene_id,tran_id = allids[t]\n",
        "            oneX            = allseq[t]\n",
        "            oneY            = gene_to_rci[gene_id]\n",
        "            in_middle = gene_to_rci[gene_id] >= MIDDLE_LOW and gene_to_rci[gene_id] <= MIDDLE_HIGH\n",
        "            in_tails = gene_to_rci[gene_id] < MIDDLE_LOW or gene_to_rci[gene_id] > MIDDLE_HIGH\n",
        "            if gene_id in self.val_genes:\n",
        "                if FILTER_TEST and (\\\n",
        "                    (FILTER_TAILS_TEST and in_tails) or \\\n",
        "                    (FILTER_MIDDLE_TEST and in_middle)):\n",
        "                    pass\n",
        "                else:\n",
        "                    self.val_ids.append(allids[t])\n",
        "                    self.val_seq.append(allseq[t])\n",
        "                    self.val_rci[gene_id]=gene_to_rci[gene_id]\n",
        "            else:\n",
        "                if FILTER_TRAIN and (\\\n",
        "                    (FILTER_TAILS_TRAIN and in_tails) or \\\n",
        "                    (FILTER_MIDDLE_TRAIN and in_middle)):\n",
        "                    pass\n",
        "                else:\n",
        "                    self.train_ids.append(allids[t])\n",
        "                    self.train_seq.append(allseq[t])\n",
        "                    self.train_rci[gene_id]=gene_to_rci[gene_id]\n",
        "    def get_ids(self):\n",
        "        return self.train_ids,self.val_ids\n",
        "    def get_seq(self):\n",
        "        return self.train_seq,self.val_seq\n",
        "    def get_rci(self):\n",
        "        return self.train_rci,self.val_rci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC9m0W-pFLBH",
        "outputId": "9502837f-56df-48b8-81cf-d9e023238792",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-20 15:21:52.481856\n",
            "Load RCI from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.lncRNA_RCI.all_cell_lines.csv\n",
            "Number of RCI values loaded 4372\n",
            "Num RCI: 4372\n",
            "Load sequence from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.canon_lncRNA_transcripts.csv\n",
            "Loaded 4372 sequences.\n",
            "\n",
            "Training # 1 1\n",
            "2023-04-20 15:21:59.454889\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.1.validation_genes.txt\n",
            "2023-04-20 15:21:59.471117\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1062:1013 51.18%\n",
            "Valid 1:0 259:273 48.68%\n",
            "FIT\n",
            "2023-04-20 15:21:59.487453\n",
            "\n",
            "Testing # 1 1\n",
            "2023-04-20 15:22:54.089134\n",
            "2023-04-20 15:22:54.089196\n",
            "PREDICT\n",
            "2023-04-20 15:22:54.094517\n",
            "debug pred [0.5657341984028775, 0.11920645381378543, 0.24808610767929973]\n",
            "debug class [1 0 0]\n",
            "Test 1:0 259:273 48.68%\n",
            "Predict 1:0 265:267 49.81%\n",
            "Test sizes (532, 1025) (532,)\n",
            "Distrib of scores: 0.5075905119558255 mean 0.21018438509661377 std\n",
            "Range of scores: 0.07382770848768373 to 0.935194646683985\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[176  97]\n",
            " [ 91 168]]\n",
            "Normalized matrix\n",
            " [[0.33082707 0.18233083]\n",
            " [0.17105263 0.31578947]]\n",
            "Extreme scores correct, pos:neg 105 104\n",
            "Extreme scores incorrect pos:neg 49 36\n",
            "Accuracy: 64.66% Precision: 63.40% Recall: 64.86%\n",
            "F1: 64.12% MCC: 0.2932\n",
            "AUPRC: 67.49% AUROC: 70.12%\n",
            " accuracy [64.66165413533834]\n",
            " precision [63.39622641509434]\n",
            " recall [64.86486486486487]\n",
            " F1 [64.12213740458016]\n",
            " MCC [0.2932377768445987]\n",
            " AUPRC [67.49044045594962]\n",
            " AUROC [70.12035583464153]\n",
            "\n",
            "Training # 1 2\n",
            "2023-04-20 15:22:54.127377\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.2.validation_genes.txt\n",
            "2023-04-20 15:22:54.145977\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1048:1016 50.78%\n",
            "Valid 1:0 273:270 50.28%\n",
            "FIT\n",
            "2023-04-20 15:22:54.162159\n",
            "\n",
            "Testing # 1 2\n",
            "2023-04-20 15:23:48.560956\n",
            "2023-04-20 15:23:48.561014\n",
            "PREDICT\n",
            "2023-04-20 15:23:48.567187\n",
            "debug pred [0.4312455253592914, 0.6487455922133556, 0.08597362390233465]\n",
            "debug class [0 1 0]\n",
            "Test 1:0 273:270 50.28%\n",
            "Predict 1:0 284:259 52.30%\n",
            "Test sizes (543, 1025) (543,)\n",
            "Distrib of scores: 0.5113657569819189 mean 0.19485502160285012 std\n",
            "Range of scores: 0.05610655829347722 to 0.9309399698831352\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[166 104]\n",
            " [ 93 180]]\n",
            "Normalized matrix\n",
            " [[0.30570902 0.19152855]\n",
            " [0.17127072 0.33149171]]\n",
            "Extreme scores correct, pos:neg 104 98\n",
            "Extreme scores incorrect pos:neg 38 30\n",
            "Accuracy: 63.72% Precision: 63.38% Recall: 65.93%\n",
            "F1: 64.63% MCC: 0.2744\n",
            "AUPRC: 70.99% AUROC: 70.85%\n",
            " accuracy [63.72007366482505]\n",
            " precision [63.38028169014085]\n",
            " recall [65.93406593406593]\n",
            " F1 [64.63195691202873]\n",
            " MCC [0.27444231593419627]\n",
            " AUPRC [70.9887585506306]\n",
            " AUROC [70.85334418667752]\n",
            "\n",
            "Training # 1 3\n",
            "2023-04-20 15:23:48.598386\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.3.validation_genes.txt\n",
            "2023-04-20 15:23:48.619258\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1070:1030 50.95%\n",
            "Valid 1:0 251:256 49.51%\n",
            "FIT\n",
            "2023-04-20 15:23:48.635711\n",
            "\n",
            "Testing # 1 3\n",
            "2023-04-20 15:24:43.938226\n",
            "2023-04-20 15:24:43.938487\n",
            "PREDICT\n",
            "2023-04-20 15:24:43.942004\n",
            "debug pred [0.33685950639671747, 0.2860985381216294, 0.4364378197702694]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 251:256 49.51%\n",
            "Predict 1:0 270:237 53.25%\n",
            "Test sizes (507, 1025) (507,)\n",
            "Distrib of scores: 0.5133695832423318 mean 0.1823062178258465 std\n",
            "Range of scores: 0.09969139996556896 to 0.931527231783607\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[161  95]\n",
            " [ 76 175]]\n",
            "Normalized matrix\n",
            " [[0.31755424 0.18737673]\n",
            " [0.14990138 0.34516765]]\n",
            "Extreme scores correct, pos:neg 96 81\n",
            "Extreme scores incorrect pos:neg 41 26\n",
            "Accuracy: 66.27% Precision: 64.81% Recall: 69.72%\n",
            "F1: 67.18% MCC: 0.3268\n",
            "AUPRC: 67.53% AUROC: 70.67%\n",
            " accuracy [66.27218934911244]\n",
            " precision [64.81481481481481]\n",
            " recall [69.7211155378486]\n",
            " F1 [67.1785028790787]\n",
            " MCC [0.32679452107498447]\n",
            " AUPRC [67.5300615429426]\n",
            " AUROC [70.66577440239044]\n",
            "\n",
            "Training # 1 4\n",
            "2023-04-20 15:24:43.969942\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.4.validation_genes.txt\n",
            "2023-04-20 15:24:43.989218\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1064:1041 50.55%\n",
            "Valid 1:0 257:245 51.20%\n",
            "FIT\n",
            "2023-04-20 15:24:44.005544\n",
            "\n",
            "Testing # 1 4\n",
            "2023-04-20 15:25:38.466889\n",
            "2023-04-20 15:25:38.466938\n",
            "PREDICT\n",
            "2023-04-20 15:25:38.471267\n",
            "debug pred [0.2730817445205837, 0.2810241863154696, 0.5284121129141014]\n",
            "debug class [0 0 1]\n",
            "Test 1:0 257:245 51.20%\n",
            "Predict 1:0 232:270 46.22%\n",
            "Test sizes (502, 1025) (502,)\n",
            "Distrib of scores: 0.4893202998513661 mean 0.18951270781226637 std\n",
            "Range of scores: 0.06885467251375856 to 0.9567459785233599\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[175  70]\n",
            " [ 95 162]]\n",
            "Normalized matrix\n",
            " [[0.34860558 0.13944223]\n",
            " [0.18924303 0.32270916]]\n",
            "Extreme scores correct, pos:neg 84 94\n",
            "Extreme scores incorrect pos:neg 32 35\n",
            "Accuracy: 67.13% Precision: 69.83% Recall: 63.04%\n",
            "F1: 66.26% MCC: 0.3455\n",
            "AUPRC: 68.86% AUROC: 70.98%\n",
            " accuracy [67.13147410358566]\n",
            " precision [69.82758620689656]\n",
            " recall [63.035019455252915]\n",
            " F1 [66.25766871165645]\n",
            " MCC [0.3455288028581176]\n",
            " AUPRC [68.86261436211701]\n",
            " AUROC [70.97911538156117]\n",
            "\n",
            "Training # 1 5\n",
            "2023-04-20 15:25:38.519995\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.5.validation_genes.txt\n",
            "2023-04-20 15:25:38.546571\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1040:1044 49.90%\n",
            "Valid 1:0 281:242 53.73%\n",
            "FIT\n",
            "2023-04-20 15:25:38.571657\n",
            "\n",
            "Testing # 1 5\n",
            "2023-04-20 15:26:32.757058\n",
            "2023-04-20 15:26:32.757119\n",
            "PREDICT\n",
            "2023-04-20 15:26:32.761147\n",
            "debug pred [0.14540590536436374, 0.3698860460939823, 0.24739503301022733]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 281:242 53.73%\n",
            "Predict 1:0 280:243 53.54%\n",
            "Test sizes (523, 1025) (523,)\n",
            "Distrib of scores: 0.5113889140575142 mean 0.19268977736424886 std\n",
            "Range of scores: 0.08727913635464982 to 0.9456857986268945\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[155  87]\n",
            " [ 88 193]]\n",
            "Normalized matrix\n",
            " [[0.29636711 0.16634799]\n",
            " [0.16826004 0.36902486]]\n",
            "Extreme scores correct, pos:neg 105 86\n",
            "Extreme scores incorrect pos:neg 30 35\n",
            "Accuracy: 66.54% Precision: 68.93% Recall: 68.68%\n",
            "F1: 68.81% MCC: 0.3272\n",
            "AUPRC: 73.76% AUROC: 72.28%\n",
            " accuracy [66.53919694072657]\n",
            " precision [68.92857142857143]\n",
            " recall [68.68327402135232]\n",
            " F1 [68.80570409982175]\n",
            " MCC [0.32723718952020836]\n",
            " AUPRC [73.75880260965066]\n",
            " AUROC [72.28463868709743]\n",
            "\n",
            "Training # 2 1\n",
            "2023-04-20 15:26:32.792574\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.1.validation_genes.txt\n",
            "2023-04-20 15:26:32.812953\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1060:1030 50.72%\n",
            "Valid 1:0 261:256 50.48%\n",
            "FIT\n",
            "2023-04-20 15:26:32.828867\n",
            "\n",
            "Testing # 2 1\n",
            "2023-04-20 15:27:27.619941\n",
            "2023-04-20 15:27:27.620003\n",
            "PREDICT\n",
            "2023-04-20 15:27:27.624681\n",
            "debug pred [0.44594806187735364, 0.17170929249289985, 0.2356487219704869]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 261:256 50.48%\n",
            "Predict 1:0 243:274 47.00%\n",
            "Test sizes (517, 1025) (517,)\n",
            "Distrib of scores: 0.4923396683914253 mean 0.19430406160521307 std\n",
            "Range of scores: 0.07415865896201598 to 0.9204669874535658\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[168  88]\n",
            " [106 155]]\n",
            "Normalized matrix\n",
            " [[0.32495164 0.17021277]\n",
            " [0.20502901 0.29980658]]\n",
            "Extreme scores correct, pos:neg 87 99\n",
            "Extreme scores incorrect pos:neg 38 41\n",
            "Accuracy: 62.48% Precision: 63.79% Recall: 59.39%\n",
            "F1: 61.51% MCC: 0.2506\n",
            "AUPRC: 65.02% AUROC: 67.44%\n",
            " accuracy [62.475822050290134]\n",
            " precision [63.78600823045267]\n",
            " recall [59.38697318007663]\n",
            " F1 [61.50793650793651]\n",
            " MCC [0.25055886462768256]\n",
            " AUPRC [65.01707246917981]\n",
            " AUROC [67.43893678160919]\n",
            "\n",
            "Training # 2 2\n",
            "2023-04-20 15:27:27.654756\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.2.validation_genes.txt\n",
            "2023-04-20 15:27:27.680359\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1043:1028 50.36%\n",
            "Valid 1:0 278:258 51.87%\n",
            "FIT\n",
            "2023-04-20 15:27:27.696736\n",
            "\n",
            "Testing # 2 2\n",
            "2023-04-20 15:28:22.018315\n",
            "2023-04-20 15:28:22.018549\n",
            "PREDICT\n",
            "2023-04-20 15:28:22.022227\n",
            "debug pred [0.10409878812355015, 0.2360903515119112, 0.39030327209130805]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 278:258 51.87%\n",
            "Predict 1:0 283:253 52.80%\n",
            "Test sizes (536, 1025) (536,)\n",
            "Distrib of scores: 0.5133132833932301 mean 0.19914577485124432 std\n",
            "Range of scores: 0.05388498689539183 to 0.9234811942929789\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[170  88]\n",
            " [ 83 195]]\n",
            "Normalized matrix\n",
            " [[0.31716418 0.1641791 ]\n",
            " [0.15485075 0.36380597]]\n",
            "Extreme scores correct, pos:neg 120 92\n",
            "Extreme scores incorrect pos:neg 37 33\n",
            "Accuracy: 68.10% Precision: 68.90% Recall: 70.14%\n",
            "F1: 69.52% MCC: 0.3607\n",
            "AUPRC: 73.77% AUROC: 73.94%\n",
            " accuracy [68.09701492537313]\n",
            " precision [68.90459363957598]\n",
            " recall [70.14388489208633]\n",
            " F1 [69.51871657754009]\n",
            " MCC [0.36066799927383564]\n",
            " AUPRC [73.76742220949754]\n",
            " AUROC [73.93898834420837]\n",
            "\n",
            "Training # 2 3\n",
            "2023-04-20 15:28:22.050111\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.3.validation_genes.txt\n",
            "2023-04-20 15:28:22.070156\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1050:1041 50.22%\n",
            "Valid 1:0 271:245 52.52%\n",
            "FIT\n",
            "2023-04-20 15:28:22.085978\n",
            "\n",
            "Testing # 2 3\n",
            "2023-04-20 15:29:16.704942\n",
            "2023-04-20 15:29:16.705004\n",
            "PREDICT\n",
            "2023-04-20 15:29:16.709433\n",
            "debug pred [0.5250554677803582, 0.9237874480351136, 0.6012879412038317]\n",
            "debug class [1 1 1]\n",
            "Test 1:0 271:245 52.52%\n",
            "Predict 1:0 265:251 51.36%\n",
            "Test sizes (516, 1025) (516,)\n",
            "Distrib of scores: 0.5039999808201829 mean 0.19104420869014688 std\n",
            "Range of scores: 0.061575727511583134 to 0.9237874480351136\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[158  87]\n",
            " [ 93 178]]\n",
            "Normalized matrix\n",
            " [[0.30620155 0.16860465]\n",
            " [0.18023256 0.34496124]]\n",
            "Extreme scores correct, pos:neg 92 89\n",
            "Extreme scores incorrect pos:neg 36 28\n",
            "Accuracy: 65.12% Precision: 67.17% Recall: 65.68%\n",
            "F1: 66.42% MCC: 0.3015\n",
            "AUPRC: 70.71% AUROC: 70.95%\n",
            " accuracy [65.11627906976744]\n",
            " precision [67.16981132075472]\n",
            " recall [65.68265682656826]\n",
            " F1 [66.4179104477612]\n",
            " MCC [0.3014522333178281]\n",
            " AUPRC [70.70705594799271]\n",
            " AUROC [70.94961970027865]\n",
            "\n",
            "Training # 2 4\n",
            "2023-04-20 15:29:16.737231\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.4.validation_genes.txt\n",
            "2023-04-20 15:29:16.757676\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1080:1019 51.45%\n",
            "Valid 1:0 241:267 47.44%\n",
            "FIT\n",
            "2023-04-20 15:29:16.775866\n",
            "\n",
            "Testing # 2 4\n",
            "2023-04-20 15:30:11.112790\n",
            "2023-04-20 15:30:11.113189\n",
            "PREDICT\n",
            "2023-04-20 15:30:11.118454\n",
            "debug pred [0.5645088597050522, 0.48359369392957097, 0.5717757923468646]\n",
            "debug class [1 0 1]\n",
            "Test 1:0 241:267 47.44%\n",
            "Predict 1:0 264:244 51.97%\n",
            "Test sizes (508, 1025) (508,)\n",
            "Distrib of scores: 0.5080510041770827 mean 0.1934010985404719 std\n",
            "Range of scores: 0.0914720902280289 to 0.9386568232630509\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[172  95]\n",
            " [ 72 169]]\n",
            "Normalized matrix\n",
            " [[0.33858268 0.18700787]\n",
            " [0.14173228 0.33267717]]\n",
            "Extreme scores correct, pos:neg 92 94\n",
            "Extreme scores incorrect pos:neg 38 28\n",
            "Accuracy: 67.13% Precision: 64.02% Recall: 70.12%\n",
            "F1: 66.93% MCC: 0.3453\n",
            "AUPRC: 66.48% AUROC: 70.57%\n",
            " accuracy [67.1259842519685]\n",
            " precision [64.01515151515152]\n",
            " recall [70.12448132780082]\n",
            " F1 [66.93069306930693]\n",
            " MCC [0.34525450931461066]\n",
            " AUPRC [66.48168882652541]\n",
            " AUROC [70.572054641242]\n",
            "\n",
            "Training # 2 5\n",
            "2023-04-20 15:30:11.159907\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.5.validation_genes.txt\n",
            "2023-04-20 15:30:11.183709\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1051:1026 50.60%\n",
            "Valid 1:0 270:260 50.94%\n",
            "FIT\n",
            "2023-04-20 15:30:11.212598\n",
            "\n",
            "Testing # 2 5\n",
            "2023-04-20 15:31:04.796949\n",
            "2023-04-20 15:31:04.797008\n",
            "PREDICT\n",
            "2023-04-20 15:31:04.801336\n",
            "debug pred [0.5166636256635005, 0.5888235303239325, 0.26727920523943854]\n",
            "debug class [1 1 0]\n",
            "Test 1:0 270:260 50.94%\n",
            "Predict 1:0 271:259 51.13%\n",
            "Test sizes (530, 1025) (530,)\n",
            "Distrib of scores: 0.5061114338234172 mean 0.19128630370252456 std\n",
            "Range of scores: 0.10194207659206367 to 0.9547875171080935\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[168  92]\n",
            " [ 91 179]]\n",
            "Normalized matrix\n",
            " [[0.31698113 0.17358491]\n",
            " [0.17169811 0.33773585]]\n",
            "Extreme scores correct, pos:neg 93 99\n",
            "Extreme scores incorrect pos:neg 41 34\n",
            "Accuracy: 65.47% Precision: 66.05% Recall: 66.30%\n",
            "F1: 66.17% MCC: 0.3091\n",
            "AUPRC: 70.10% AUROC: 70.78%\n",
            " accuracy [65.47169811320754]\n",
            " precision [66.05166051660517]\n",
            " recall [66.2962962962963]\n",
            " F1 [66.17375231053605]\n",
            " MCC [0.3091410305167992]\n",
            " AUPRC [70.10229324144225]\n",
            " AUROC [70.78205128205128]\n",
            "2023-04-20 15:31:04.840000\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "\n",
        "accuracy=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "f1=[]\n",
        "mcc=[]\n",
        "auprc=[]\n",
        "auroc=[]\n",
        "\n",
        "loader = DataLoader()\n",
        "filepath = DATA_DIR+RCI_FILE_TRAIN\n",
        "print(\"Load RCI from\",filepath)\n",
        "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
        "print('Num RCI:', len(gene_to_rci.keys()))\n",
        "filepath = DATA_DIR+SEQ_FILE_TRAIN\n",
        "print('Load sequence from',filepath)\n",
        "allids,allseq = loader.load_spectra(filepath)  # for MLP (load_sequence() for CNN)\n",
        "print('Loaded',len(allseq),'sequences.')\n",
        "test_gene_to_rci = None\n",
        "test_allids = None\n",
        "test_allseq = None\n",
        "if SEQ_FILE_TEST is not None:\n",
        "    # Train on the entire train set (no cross-validation).\n",
        "    # Evaluate with the test files.\n",
        "    test_loader = DataLoader()\n",
        "    filepath = DATA_DIR+RCI_FILE_TEST\n",
        "    print(\"Load RCI from\",filepath)\n",
        "    test_gene_to_rci = test_loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
        "    print('Num RCI:', len(test_gene_to_rci.keys()))\n",
        "    filepath = DATA_DIR+SEQ_FILE_TEST\n",
        "    print('Load sequence from',filepath)\n",
        "    test_allids,test_allseq = test_loader.load_spectra(filepath)\n",
        "    print('Loaded',len(test_allseq),'sequences.')\n",
        "\n",
        "for repeat in range(REPEATS):\n",
        "    for fold in range(FOLDS):\n",
        "        show_r = repeat+1  # display one-based counting\n",
        "        show_f = fold+1    # display one-based counting\n",
        "\n",
        "        print()\n",
        "        print(\"Training #\",show_r,show_f)\n",
        "        print(datetime.now())\n",
        "        cvdo = CrossValidator(EPOCHS)\n",
        "        cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
        "        if SEQ_FILE_TEST is None:\n",
        "            # Train on 80% and evaluate on 20%.\n",
        "            separator = Separator()\n",
        "            separator.load(DATA_DIR,show_r,show_f)\n",
        "            separator.process(allids,allseq,gene_to_rci)\n",
        "            train_allids,test_allids = separator.get_ids()\n",
        "            train_allseq,test_allseq = separator.get_seq()\n",
        "            train_gene_to_rci,test_gene_to_rci = separator.get_rci()\n",
        "            cvdo.train_new_model(\n",
        "                train_allids,train_allseq,train_gene_to_rci,\n",
        "                test_allids,test_allseq,test_gene_to_rci)\n",
        "            if SAVE_MODEL_FILENAME is not None:\n",
        "                filename = f\"{SAVE_MODEL_FILENAME}.{show_r}.{show_f}.model\"\n",
        "                cvdo.save_model(filename)\n",
        "        else:\n",
        "            # Train on the entire train set (no cross-validation).\n",
        "            # Evaluate with the test files.\n",
        "            train_allids = allids\n",
        "            train_allseq = allseq\n",
        "            train_gene_to_rci = gene_to_rci\n",
        "            BREAK = True\n",
        "            cvdo.train_new_model(\n",
        "                train_allids,train_allseq,train_gene_to_rci,\n",
        "                None,None,None)\n",
        "\n",
        "        print()\n",
        "        print(\"Testing #\",show_r,show_f)\n",
        "        print(datetime.now())\n",
        "        cvdo.reset_statistics()\n",
        "        cvdo.test_without_training(\n",
        "            test_allids,test_allseq,test_gene_to_rci)\n",
        "        cv_accuracy,cv_precision,cv_recall,cv_f1,cv_mcc,cv_auprc,cv_auroc=\\\n",
        "            cvdo.get_statistics()\n",
        "\n",
        "        print(\" accuracy\" ,  cv_accuracy)\n",
        "        print(\" precision\" , cv_precision)\n",
        "        print(\" recall\" ,    cv_recall)\n",
        "        print(\" F1\" ,        cv_f1)\n",
        "        print(\" MCC\" ,       cv_mcc)\n",
        "        print(\" AUPRC\" ,     cv_auprc)\n",
        "        print(\" AUROC\" ,     cv_auroc)\n",
        "\n",
        "        accuracy.append(cv_accuracy)\n",
        "        precision.append(cv_precision)\n",
        "        recall.append(cv_recall)\n",
        "        f1.append(cv_f1)\n",
        "        mcc.append(cv_mcc)\n",
        "        auprc.append(cv_auprc)\n",
        "        auroc.append(cv_auroc)\n",
        "        if BREAK: break\n",
        "    if BREAK: break\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkCeDg_HdQ36",
        "outputId": "d696207d-abd4-441f-b075-6c94f45c5a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " accuracy mean 65.66% std 1.72\n",
            " precision mean 66.03% std 2.51\n",
            " recall mean 66.39% std 3.46\n",
            " F1 mean 66.15% std 2.31\n",
            " MCC mean 0.3134 std 0.0345\n",
            " AUPRC mean 69.47% std 2.94\n",
            " AUROC mean 70.86% std 1.63\n",
            " accuracy [[64.66165413533834], [63.72007366482505], [66.27218934911244], [67.13147410358566], [66.53919694072657], [62.475822050290134], [68.09701492537313], [65.11627906976744], [67.1259842519685], [65.47169811320754]]\n",
            " precision [[63.39622641509434], [63.38028169014085], [64.81481481481481], [69.82758620689656], [68.92857142857143], [63.78600823045267], [68.90459363957598], [67.16981132075472], [64.01515151515152], [66.05166051660517]]\n",
            " recall [[64.86486486486487], [65.93406593406593], [69.7211155378486], [63.035019455252915], [68.68327402135232], [59.38697318007663], [70.14388489208633], [65.68265682656826], [70.12448132780082], [66.2962962962963]]\n",
            " F1 [[64.12213740458016], [64.63195691202873], [67.1785028790787], [66.25766871165645], [68.80570409982175], [61.50793650793651], [69.51871657754009], [66.4179104477612], [66.93069306930693], [66.17375231053605]]\n",
            " MCC [[0.2932377768445987], [0.27444231593419627], [0.32679452107498447], [0.3455288028581176], [0.32723718952020836], [0.25055886462768256], [0.36066799927383564], [0.3014522333178281], [0.34525450931461066], [0.3091410305167992]]\n",
            " AUPRC [[67.49044045594962], [70.9887585506306], [67.5300615429426], [68.86261436211701], [73.75880260965066], [65.01707246917981], [73.76742220949754], [70.70705594799271], [66.48168882652541], [70.10229324144225]]\n",
            " AUROC [[70.12035583464153], [70.85334418667752], [70.66577440239044], [70.97911538156117], [72.28463868709743], [67.43893678160919], [73.93898834420837], [70.94961970027865], [70.572054641242], [70.78205128205128]]\n"
          ]
        }
      ],
      "source": [
        "def STD (values):\n",
        "    # ddof=1 reduces bias when extrapolating from sample to population\n",
        "    return np.std(values,ddof=1)\n",
        "\n",
        "print(\" accuracy mean %.2f%% std %.2f\" %  (np.mean(accuracy),  STD(accuracy)))\n",
        "print(\" precision mean %.2f%% std %.2f\" % (np.mean(precision), STD(precision)))\n",
        "print(\" recall mean %.2f%% std %.2f\" %    (np.mean(recall),    STD(recall)))\n",
        "print(\" F1 mean %.2f%% std %.2f\" %        (np.mean(f1),        STD(f1)))\n",
        "print(\" MCC mean %.4f std %.4f\" %       (np.mean(mcc),       STD(mcc)))\n",
        "print(\" AUPRC mean %.2f%% std %.2f\" %     (np.mean(auprc),     STD(auprc)))\n",
        "print(\" AUROC mean %.2f%% std %.2f\" %     (np.mean(auroc),     STD(auroc)))\n",
        "\n",
        "print(\" accuracy\"  , accuracy)\n",
        "print(\" precision\" , precision)\n",
        "print(\" recall\"    , recall)\n",
        "print(\" F1\"        , f1)\n",
        "print(\" MCC\"       , mcc)\n",
        "print(\" AUPRC\"     , auprc)\n",
        "print(\" AUROC\"     , auroc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "QjSVa72v4IsA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}