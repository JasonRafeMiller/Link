{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# Random Forest\n",
    "canonical lncRNA, -1 threshold, cross-valiation, middle-exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "e3829598-d7de-4895-dbba-410e196ae45d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:52:38.015097\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "fb8898b3-b66d-421a-92ee-382fe73af8a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "Running on CoLab\n",
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "/content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
    "    MODEL_DIR=PATH+'My Drive/data/Localization/Models/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR=\"/\"\n",
    "    MODEL_DIR=\"/\"\n",
    "print(DATA_DIR)\n",
    "SAVE_MODEL_FILENAME = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRX-UEr8FLA8",
    "outputId": "37881a5d-48c0-49fe-e9ca-6dae1269b4d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n",
      "sklearn 1.2.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "np.random.seed(42) # supposedly sets scikit-learn\n",
    "import time # sleep function\n",
    "from os.path import isfile\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "K=5\n",
    "ALPHABET=4**K + 1\n",
    "EPOCHS=150 \n",
    "RCI_THRESHOLD_MECHANISM = 'ZERO'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
    "RCI_THRESHOLD_VALUE = -1  # use -1 for lncRNA, use 0 for mRNA\n",
    "BREAK = False   # optionally break after first fold\n",
    "EXCLUSIONS = [1]   # possibly exclude cell line 1 = H1.hESC\n",
    "FILTER_TRAIN        = True\n",
    "FILTER_TAILS_TRAIN  = False\n",
    "FILTER_MIDDLE_TRAIN = True\n",
    "FILTER_TEST         = True\n",
    "FILTER_TAILS_TEST   = False\n",
    "FILTER_MIDDLE_TEST  = True\n",
    "MIDDLE_LOW          = -2   # -2 for lncRNA, -1 for mRNA\n",
    "MIDDLE_HIGH         = 0    #  0 for lncRNA, +1 for mRNA\n",
    "\n",
    "REPEATS = 2\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "LnkpVKdMFLA-"
   },
   "outputs": [],
   "source": [
    "RCI_FILE_TRAIN = 'train.lncRNA_RCI.all_cell_lines.csv'\n",
    "RCI_FILE_TEST  = None # use None for cross-validation\n",
    "\n",
    "SEQ_FILE_TRAIN = 'train.canon_lncRNA_transcripts.csv'\n",
    "SEQ_FILE_TEST  = None # use None for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "e3p4QzQJFLA_"
   },
   "outputs": [],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
    "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
    "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
    "    return ordered_list\n",
    "all_cell_lines = get_ordered_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "p35ehKV3Kq0z"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.cache=dict() \n",
    "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        self.gene2rci = dict()\n",
    "        \n",
    "    def load_gene_rci_values(self,filepath,exclusions):\n",
    "        '''\n",
    "        Load all the genes from the given RCI csv file.\n",
    "        The given file usually contains train or test, not both.\n",
    "        Return dict with keys=gene:str and values=RCI:float.\n",
    "        '''\n",
    "        self.gene2rci = {}\n",
    "        overall_sum = 0\n",
    "        with open (filepath,'r') as handle:\n",
    "            for row in handle:\n",
    "                line = row.strip()\n",
    "                fields = line.split(',')\n",
    "                gene_id = fields.pop(0)\n",
    "                cell_line_index = 0\n",
    "                rci_values = []\n",
    "                log_mean=0.0\n",
    "                for rci_str in fields:\n",
    "                    if cell_line_index not in exclusions:\n",
    "                        if rci_str != \"nan\":\n",
    "                            rci_val = float(rci_str)\n",
    "                            rci_values.append(rci_val)\n",
    "                    cell_line_index += 1\n",
    "                if len(rci_values)>0:\n",
    "                    values = np.array(rci_values)\n",
    "                    antilogs = [2**x for x in values]\n",
    "                    big_mean = np.mean(antilogs)\n",
    "                    # Avoid division by zero\n",
    "                    if np.absolute(big_mean)<0.000001:\n",
    "                        log_mean = -1000000 # neg infinity\n",
    "                    else:\n",
    "                        log_mean = np.log2(big_mean) \n",
    "                    self.gene2rci[gene_id] = log_mean\n",
    "        print('Number of RCI values loaded',len(self.gene2rci.keys()))\n",
    "        return self.gene2rci\n",
    "\n",
    "    def _seq_to_kmer_values(self,rna,K):\n",
    "        vec=[] # seq converted to list of K-mers \n",
    "        N_indicator = 0 # indicator value\n",
    "        length = len(rna)\n",
    "        for i in range(length-K+1):\n",
    "            kmer = rna[i:i+K]\n",
    "            if 'N' in kmer:\n",
    "                value = N_indicator\n",
    "            elif kmer in self.cache.keys():\n",
    "                value = self.cache[kmer]\n",
    "            else:\n",
    "                value = 0\n",
    "                for j in range(K):\n",
    "                    value *= 4   \n",
    "                    nextnuc = kmer[j] \n",
    "                    nucval = self.vals[nextnuc]\n",
    "                    value += nucval\n",
    "                value += 1   # NNN => 0, AAA => 1\n",
    "                self.cache[kmer] = value\n",
    "            vec.append(value)\n",
    "        return vec\n",
    "\n",
    "    def load_sequence(self,filepath):\n",
    "        '''\n",
    "        Load all the sequences from the given file. \n",
    "        Load our version of GenCode -- csv, easier to parse than fasta.\n",
    "        Each line has IDs plus sequence.\n",
    "        The IDs in the file do not include dot-version numbers.\n",
    "        The file may already be filtered e.g. canonical transcripts.\n",
    "        '''\n",
    "        allids=[]\n",
    "        allseq=[]\n",
    "        #NREPEAT = str('N'*MAXLEN)   # not used for MLP\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row\n",
    "                else:\n",
    "                    line    = row.strip()\n",
    "                    fields  = line.split(',')\n",
    "                    tran_id = fields[0]  # without version number\n",
    "                    gene_id = fields[1]  # without version number\n",
    "                    seq_len = int(fields[3])\n",
    "                    seq_txt = fields[4]\n",
    "                    # Keep only transcripts having numeric RCI given the cell lines in use.\n",
    "                    # We have validated this by spot checking.\n",
    "                    # TO DO: validate this programmatically.\n",
    "                    if gene_id in self.gene2rci.keys():\n",
    "                        allids.append( (gene_id,tran_id) )\n",
    "                        hot_vec = self._seq_to_kmer_values(seq_txt,K)\n",
    "                        allseq.append(hot_vec)\n",
    "        self.cache=dict() # save RAM\n",
    "        return allids,allseq\n",
    "\n",
    "    def load_spectra(self,filepath):\n",
    "        '''\n",
    "        Load all (variable-length) sequences as lists of kmers.\n",
    "        Then convert each sequence to (fixed-length) kmer histograms.\n",
    "        '''\n",
    "        allids,allseq = self.load_sequence(filepath)\n",
    "        allspectra = []\n",
    "        for seq in allseq:\n",
    "            spectrum = np.zeros(ALPHABET)\n",
    "            for kmer in seq:\n",
    "                spectrum[kmer] += 1\n",
    "            spectrum /= len(seq)\n",
    "            allspectra.append(spectrum)\n",
    "        return allids,allspectra        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDZ6siB_Kq04"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "AwMbRjm0FLBF"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    rfc = RFC()\n",
    "    return rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clj-wufgFLBF",
    "outputId": "a3cfe7b4-e9da-432c-cd0f-effff1bb0059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:52:39.970191\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print(model)  # Print this only once\n",
    "model=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgrC1alOKq07"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class CrossValidator():\n",
    "    def __init__(self,epochs,score_threshold=0.5):\n",
    "        self.epochs = epochs\n",
    "        self.score_threshold = score_threshold\n",
    "        self.mechanism = 'ZERO'\n",
    "        self.discriminator = RCI_THRESHOLD_VALUE\n",
    "        self.flip = False\n",
    "        self.reset_statistics()\n",
    "        \n",
    "    def reset_statistics(self):\n",
    "        self.cv_accuracy=[]\n",
    "        self.cv_precision=[]\n",
    "        self.cv_recall=[]\n",
    "        self.cv_f1=[]\n",
    "        self.cv_auprc=[]\n",
    "        self.cv_auroc=[]\n",
    "        self.cv_mcc=[]\n",
    "        \n",
    "    def _get_X_y(self, all_ids, all_seqs, rci_map): \n",
    "        # Prepare X and y for training or testing.\n",
    "        subsetX=[]\n",
    "        subsetY=[]\n",
    "        for t in range(len(all_ids)):\n",
    "            gene_id,tran_id = all_ids[t]\n",
    "            oneX            = all_seqs[t]\n",
    "            oneY            = rci_map[gene_id]\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(oneY)\n",
    "        subsetX = np.array(subsetX)\n",
    "        subsetY = np.array(subsetY).reshape((-1,1))\n",
    "        return subsetX,subsetY\n",
    "    \n",
    "    def set_threshold_mechanism(self, mechanism):\n",
    "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
    "            raise Exception('Unrecognized mechansm:',mechanism)\n",
    "        self.mechanism = mechanism\n",
    "    \n",
    "    def _apply_threshold(self, array_of_rci):\n",
    "        # Takes list of float, returns list of labels [0,1].\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            labels = self.discriminator.predict(array_of_rci)\n",
    "            if self.flip:\n",
    "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
    "                labels = np.array(list(map(IS_CYTO, labels)))\n",
    "        else:  # 'THE_MEAN' or 'ZERO'\n",
    "            rci_threshold = self.discriminator\n",
    "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
    "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
    "        return labels\n",
    "    \n",
    "    def _prepare_threshold(self, rci_values, create=True):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            if create:  # during training, create a new GMM\n",
    "                gmm = GaussianMixture(n_components=2, verbose=0, \n",
    "                  covariance_type='spherical', n_init=100) # random_state=42) \n",
    "                gmm.fit(rci_values)\n",
    "            else:   # during testing, use existing GMM\n",
    "                gmm=self.discriminator\n",
    "            self.flip = False\n",
    "            # The GMM labels are arbitrary.\n",
    "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
    "                self.flip = True\n",
    "            self.discriminator = gmm   # redundant but consistent\n",
    "        elif self.mechanism == 'THE_MEAN':\n",
    "            self.discriminator = np.mean(rci_values)\n",
    "        elif self.mechanism == 'ZERO':\n",
    "            self.discriminator = RCI_THRESHOLD_VALUE\n",
    "        else: # not expected\n",
    "            self.discriminator = 0\n",
    "    \n",
    "    def _explain_threshold(self):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            gmm=self.discriminator\n",
    "            print('Discriminator is GMM')\n",
    "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
    "            print('Variances',gmm.covariances_)\n",
    "            print('Priors',gmm.weights_)\n",
    "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
    "            print(test_rcis)\n",
    "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
    "        else:\n",
    "            print('Discriminator',self.mechanism,self.discriminator)\n",
    "    \n",
    "    def _show_sizes(self,label,values):\n",
    "        a = np.count_nonzero(values==1)\n",
    "        b = np.count_nonzero(values==0)\n",
    "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
    "        \n",
    "    def save_model(self,filename):\n",
    "        if self.model is not None:\n",
    "            filepath = MODEL_DIR + filename\n",
    "            #self.model.save(filepath)\n",
    "            print('? Saved model to',filepath)\n",
    "        \n",
    "    def load_model(self,filename):\n",
    "        filepath = MODEL_DIR + filename\n",
    "        #self.model = keras.models.load_model(filepath)\n",
    "        print('? Loaded model from',filepath)\n",
    "        \n",
    "    def train_new_model(self,train_ids,train_seq,train_rci,\n",
    "            valid_ids=None,valid_seq=None,valid_rci=None):\n",
    "        print(datetime.now())\n",
    "        X_train,y_rci = self._get_X_y(train_ids,train_seq,train_rci) \n",
    "        self._prepare_threshold(y_rci,True)  \n",
    "        self._explain_threshold()\n",
    "        y_train = self._apply_threshold(y_rci)\n",
    "        self._show_sizes('Train',y_train)\n",
    "        if valid_ids is not None:\n",
    "            X_valid,y_rci = self._get_X_y(valid_ids,valid_seq,valid_rci) \n",
    "            y_valid = self._apply_threshold(y_rci)\n",
    "            self._show_sizes('Valid',y_valid)\n",
    "        y_rci = None\n",
    "\n",
    "        self.model=build_model()\n",
    "        \n",
    "        print(\"FIT\")\n",
    "        print(datetime.now())\n",
    "        self.model.fit(X_train, y_train) # sample weight\n",
    "\n",
    "    def test_without_training(self,test_ids,test_seq,test_rci):\n",
    "        # For final test, do no train.\n",
    "        # Assume set_sequences() set the test set.\n",
    "        print(datetime.now())\n",
    "        X_test,y_rci = self._get_X_y(test_ids,test_seq,test_rci) \n",
    "        y_test = self._apply_threshold(y_rci)\n",
    "        y_rci = None\n",
    "        \n",
    "        print(\"PREDICT\")\n",
    "        print(datetime.now())        \n",
    "        yhat_pairs=self.model.predict_proba(X_test)  # [ prob of 0, prob of 1 ]\n",
    "        yhat_pred=[pair[1] for pair in yhat_pairs]\n",
    "        yhat_classes=self.model.predict(X_test)  # 0 or 1\n",
    "        \n",
    "        print('debug pred',yhat_pred[:3])\n",
    "        print('debug class',yhat_classes[:3])\n",
    "\n",
    "        self._show_sizes('Test',y_test)\n",
    "        self._show_sizes('Predict',yhat_classes)\n",
    "        print('Test sizes',X_test.shape,y_test.shape)\n",
    "        print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
    "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "        print('Score threshold',self.score_threshold)\n",
    "        cm1 = confusion_matrix(y_test,yhat_classes)\n",
    "        print('Confusion matrix\\n',cm1)\n",
    "        cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
    "        print('Normalized matrix\\n',cm2)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
    "        precision = precision_score(y_test, yhat_classes)*100.\n",
    "        recall = recall_score(y_test, yhat_classes)*100.\n",
    "        f1 = f1_score(y_test, yhat_classes)*100.\n",
    "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
    "        auprc = auc(prc_X,prc_Y)*100.\n",
    "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
    "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
    "\n",
    "        correct_pos = 0\n",
    "        correct_neg = 0\n",
    "        wrong_pos = 0\n",
    "        wrong_neg = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if yhat_pred[i]>=0.65:\n",
    "                if y_test[i]==1:\n",
    "                    correct_pos += 1\n",
    "                else:\n",
    "                    wrong_pos += 1\n",
    "            elif yhat_pred[i]<=0.35:\n",
    "                if y_test[i]==0:\n",
    "                    correct_neg += 1\n",
    "                else:\n",
    "                    wrong_neg += 1\n",
    "        print('Extreme scores correct, pos:neg',correct_pos,correct_neg)  \n",
    "        print('Extreme scores incorrect pos:neg',wrong_pos,wrong_neg)  \n",
    "\n",
    "        print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
    "        print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
    "        print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n",
    "\n",
    "        self.cv_accuracy.append(accuracy)\n",
    "        self.cv_precision.append(precision)\n",
    "        self.cv_recall.append(recall)\n",
    "        self.cv_f1.append(f1)\n",
    "        self.cv_mcc.append(mcc)\n",
    "        self.cv_auprc.append(auprc)\n",
    "        self.cv_auroc.append(auroc)\n",
    "\n",
    "    def get_statistics(self):\n",
    "        return \\\n",
    "        self.cv_accuracy,\\\n",
    "        self.cv_precision,\\\n",
    "        self.cv_recall,\\\n",
    "        self.cv_f1,\\\n",
    "        self.cv_mcc,\\\n",
    "        self.cv_auprc,\\\n",
    "        self.cv_auroc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td97uyyj5qDq"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "poe3rwAF4Ir7"
   },
   "outputs": [],
   "source": [
    "class Separator():\n",
    "    def __init__(self):\n",
    "        self.train_ids = []\n",
    "        self.train_seq = []\n",
    "        self.train_rci = dict()\n",
    "        self.val_ids = []\n",
    "        self.val_seq = []\n",
    "        self.val_rci = dict()\n",
    "    def load(self,data_dir,rep,fold):\n",
    "        filename='cv.{}.{}.validation_genes.txt'.format(rep,fold)\n",
    "        filename = data_dir + filename\n",
    "        self.val_genes = set()\n",
    "        print('Opening file',filename)\n",
    "        with open(filename,'r') as fin:\n",
    "            for line in fin:\n",
    "                gene_id = line.strip()\n",
    "                self.val_genes.add(gene_id)\n",
    "    def process(self,allids,allseq,gene_to_rci):\n",
    "        size = len(allids)\n",
    "        for t in range(size):\n",
    "            gene_id,tran_id = allids[t]\n",
    "            oneX            = allseq[t]\n",
    "            oneY            = gene_to_rci[gene_id]\n",
    "            in_middle = gene_to_rci[gene_id] >= MIDDLE_LOW and gene_to_rci[gene_id] <= MIDDLE_HIGH\n",
    "            in_tails = gene_to_rci[gene_id] < MIDDLE_LOW or gene_to_rci[gene_id] > MIDDLE_HIGH\n",
    "            if gene_id in self.val_genes:\n",
    "                if FILTER_TEST and (\\\n",
    "                    (FILTER_TAILS_TEST and in_tails) or \\\n",
    "                    (FILTER_MIDDLE_TEST and in_middle)):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.val_ids.append(allids[t])\n",
    "                    self.val_seq.append(allseq[t])\n",
    "                    self.val_rci[gene_id]=gene_to_rci[gene_id]\n",
    "            else:\n",
    "                if FILTER_TRAIN and (\\\n",
    "                    (FILTER_TAILS_TRAIN and in_tails) or \\\n",
    "                    (FILTER_MIDDLE_TRAIN and in_middle)):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.train_ids.append(allids[t])\n",
    "                    self.train_seq.append(allseq[t])\n",
    "                    self.train_rci[gene_id]=gene_to_rci[gene_id]\n",
    "    def get_ids(self):\n",
    "        return self.train_ids,self.val_ids\n",
    "    def get_seq(self):\n",
    "        return self.train_seq,self.val_seq\n",
    "    def get_rci(self):\n",
    "        return self.train_rci,self.val_rci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "d86e69ef-b12a-49cd-ed77-943332401032",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:52:40.056693\n",
      "Load RCI from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.lncRNA_RCI.all_cell_lines.csv\n",
      "Number of RCI values loaded 4372\n",
      "Num RCI: 4372\n",
      "Load sequence from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.canon_lncRNA_transcripts.csv\n",
      "Loaded 4372 sequences.\n",
      "\n",
      "Training # 1 1\n",
      "2023-04-20 14:52:46.942145\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.1.validation_genes.txt\n",
      "2023-04-20 14:52:46.955080\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1062:1013 51.18%\n",
      "Valid 1:0 259:273 48.68%\n",
      "FIT\n",
      "2023-04-20 14:52:46.971158\n",
      "\n",
      "Testing # 1 1\n",
      "2023-04-20 14:52:51.570191\n",
      "2023-04-20 14:52:51.570591\n",
      "PREDICT\n",
      "2023-04-20 14:52:51.576133\n",
      "debug pred [0.45, 0.41, 0.37]\n",
      "debug class [0 0 0]\n",
      "Test 1:0 259:273 48.68%\n",
      "Predict 1:0 281:251 52.82%\n",
      "Test sizes (532, 1025) (532,)\n",
      "Distrib of scores: 0.5117669172932331 mean 0.11625531839838749 std\n",
      "Range of scores: 0.16 to 0.97\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[164 109]\n",
      " [ 87 172]]\n",
      "Normalized matrix\n",
      " [[0.30827068 0.20488722]\n",
      " [0.16353383 0.32330827]]\n",
      "Extreme scores correct, pos:neg 45 36\n",
      "Extreme scores incorrect pos:neg 18 10\n",
      "Accuracy: 63.16% Precision: 61.21% Recall: 66.41%\n",
      "F1: 63.70% MCC: 0.2652\n",
      "AUPRC: 64.05% AUROC: 67.75%\n",
      " accuracy [63.1578947368421]\n",
      " precision [61.20996441281139]\n",
      " recall [66.40926640926641]\n",
      " F1 [63.70370370370371]\n",
      " MCC [0.2651554756981981]\n",
      " AUPRC [64.05071674771659]\n",
      " AUROC [67.74859632002489]\n",
      "\n",
      "Training # 1 2\n",
      "2023-04-20 14:52:51.688436\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.2.validation_genes.txt\n",
      "2023-04-20 14:52:51.713264\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1048:1016 50.78%\n",
      "Valid 1:0 273:270 50.28%\n",
      "FIT\n",
      "2023-04-20 14:52:51.737951\n",
      "\n",
      "Testing # 1 2\n",
      "2023-04-20 14:52:55.800009\n",
      "2023-04-20 14:52:55.800072\n",
      "PREDICT\n",
      "2023-04-20 14:52:55.804349\n",
      "debug pred [0.46, 0.61, 0.27]\n",
      "debug class [0 1 0]\n",
      "Test 1:0 273:270 50.28%\n",
      "Predict 1:0 296:247 54.51%\n",
      "Test sizes (543, 1025) (543,)\n",
      "Distrib of scores: 0.5139226519337017 mean 0.11009074401524012 std\n",
      "Range of scores: 0.16 to 0.86\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[159 111]\n",
      " [ 88 185]]\n",
      "Normalized matrix\n",
      " [[0.29281768 0.20441989]\n",
      " [0.16206262 0.34069982]]\n",
      "Extreme scores correct, pos:neg 43 36\n",
      "Extreme scores incorrect pos:neg 14 8\n",
      "Accuracy: 63.35% Precision: 62.50% Recall: 67.77%\n",
      "F1: 65.03% MCC: 0.2676\n",
      "AUPRC: 67.09% AUROC: 68.12%\n",
      " accuracy [63.35174953959485]\n",
      " precision [62.5]\n",
      " recall [67.76556776556777]\n",
      " F1 [65.02636203866433]\n",
      " MCC [0.26763241154632905]\n",
      " AUPRC [67.087824551301]\n",
      " AUROC [68.11965811965813]\n",
      "\n",
      "Training # 1 3\n",
      "2023-04-20 14:52:55.889359\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.3.validation_genes.txt\n",
      "2023-04-20 14:52:55.901735\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1070:1030 50.95%\n",
      "Valid 1:0 251:256 49.51%\n",
      "FIT\n",
      "2023-04-20 14:52:55.917581\n",
      "\n",
      "Testing # 1 3\n",
      "2023-04-20 14:52:59.670405\n",
      "2023-04-20 14:52:59.670462\n",
      "PREDICT\n",
      "2023-04-20 14:52:59.675579\n",
      "debug pred [0.57, 0.29, 0.6]\n",
      "debug class [1 0 1]\n",
      "Test 1:0 251:256 49.51%\n",
      "Predict 1:0 274:233 54.04%\n",
      "Test sizes (507, 1025) (507,)\n",
      "Distrib of scores: 0.5086390532544378 mean 0.11462967512654171 std\n",
      "Range of scores: 0.16 to 0.95\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[155 101]\n",
      " [ 78 173]]\n",
      "Normalized matrix\n",
      " [[0.30571992 0.19921105]\n",
      " [0.15384615 0.34122288]]\n",
      "Extreme scores correct, pos:neg 40 43\n",
      "Extreme scores incorrect pos:neg 15 4\n",
      "Accuracy: 64.69% Precision: 63.14% Recall: 68.92%\n",
      "F1: 65.90% MCC: 0.2957\n",
      "AUPRC: 66.03% AUROC: 69.93%\n",
      " accuracy [64.69428007889546]\n",
      " precision [63.138686131386855]\n",
      " recall [68.92430278884463]\n",
      " F1 [65.90476190476191]\n",
      " MCC [0.29566580119867975]\n",
      " AUPRC [66.03245717108955]\n",
      " AUROC [69.9273219621514]\n",
      "\n",
      "Training # 1 4\n",
      "2023-04-20 14:52:59.756535\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.4.validation_genes.txt\n",
      "2023-04-20 14:52:59.772463\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1064:1041 50.55%\n",
      "Valid 1:0 257:245 51.20%\n",
      "FIT\n",
      "2023-04-20 14:52:59.788591\n",
      "\n",
      "Testing # 1 4\n",
      "2023-04-20 14:53:03.943641\n",
      "2023-04-20 14:53:03.944055\n",
      "PREDICT\n",
      "2023-04-20 14:53:03.949333\n",
      "debug pred [0.59, 0.45, 0.51]\n",
      "debug class [1 0 1]\n",
      "Test 1:0 257:245 51.20%\n",
      "Predict 1:0 244:258 48.61%\n",
      "Test sizes (502, 1025) (502,)\n",
      "Distrib of scores: 0.4952589641434263 mean 0.10640369207211 std\n",
      "Range of scores: 0.14 to 0.94\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[165  80]\n",
      " [ 93 164]]\n",
      "Normalized matrix\n",
      " [[0.32868526 0.15936255]\n",
      " [0.18525896 0.32669323]]\n",
      "Extreme scores correct, pos:neg 27 35\n",
      "Extreme scores incorrect pos:neg 15 10\n",
      "Accuracy: 65.54% Precision: 67.21% Recall: 63.81%\n",
      "F1: 65.47% MCC: 0.3116\n",
      "AUPRC: 67.95% AUROC: 70.41%\n",
      " accuracy [65.5378486055777]\n",
      " precision [67.21311475409836]\n",
      " recall [63.81322957198443]\n",
      " F1 [65.4690618762475]\n",
      " MCC [0.31163385570757174]\n",
      " AUPRC [67.95494072894341]\n",
      " AUROC [70.40895735726197]\n",
      "\n",
      "Training # 1 5\n",
      "2023-04-20 14:53:04.043962\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.5.validation_genes.txt\n",
      "2023-04-20 14:53:04.064778\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1040:1044 49.90%\n",
      "Valid 1:0 281:242 53.73%\n",
      "FIT\n",
      "2023-04-20 14:53:04.089411\n",
      "\n",
      "Testing # 1 5\n",
      "2023-04-20 14:53:08.678647\n",
      "2023-04-20 14:53:08.678708\n",
      "PREDICT\n",
      "2023-04-20 14:53:08.684382\n",
      "debug pred [0.19, 0.39, 0.54]\n",
      "debug class [0 0 1]\n",
      "Test 1:0 281:242 53.73%\n",
      "Predict 1:0 270:253 51.63%\n",
      "Test sizes (523, 1025) (523,)\n",
      "Distrib of scores: 0.5060803059273423 mean 0.11016122920078038 std\n",
      "Range of scores: 0.12 to 0.89\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[159  83]\n",
      " [ 94 187]]\n",
      "Normalized matrix\n",
      " [[0.3040153  0.15869981]\n",
      " [0.17973231 0.35755258]]\n",
      "Extreme scores correct, pos:neg 38 39\n",
      "Extreme scores incorrect pos:neg 9 8\n",
      "Accuracy: 66.16% Precision: 69.26% Recall: 66.55%\n",
      "F1: 67.88% MCC: 0.3218\n",
      "AUPRC: 71.42% AUROC: 70.56%\n",
      " accuracy [66.1567877629063]\n",
      " precision [69.25925925925925]\n",
      " recall [66.54804270462633]\n",
      " F1 [67.87658802177857]\n",
      " MCC [0.3217773341147742]\n",
      " AUPRC [71.41504692834046]\n",
      " AUROC [70.55968942089937]\n",
      "\n",
      "Training # 2 1\n",
      "2023-04-20 14:53:08.768724\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.1.validation_genes.txt\n",
      "2023-04-20 14:53:08.783953\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1060:1030 50.72%\n",
      "Valid 1:0 261:256 50.48%\n",
      "FIT\n",
      "2023-04-20 14:53:08.799664\n",
      "\n",
      "Testing # 2 1\n",
      "2023-04-20 14:53:12.578514\n",
      "2023-04-20 14:53:12.578612\n",
      "PREDICT\n",
      "2023-04-20 14:53:12.583384\n",
      "debug pred [0.48, 0.42, 0.45]\n",
      "debug class [0 0 0]\n",
      "Test 1:0 261:256 50.48%\n",
      "Predict 1:0 248:269 47.97%\n",
      "Test sizes (517, 1025) (517,)\n",
      "Distrib of scores: 0.500909090909091 mean 0.10687284086542961 std\n",
      "Range of scores: 0.18 to 0.79\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[168  88]\n",
      " [101 160]]\n",
      "Normalized matrix\n",
      " [[0.32495164 0.17021277]\n",
      " [0.19535783 0.30947776]]\n",
      "Extreme scores correct, pos:neg 30 32\n",
      "Extreme scores incorrect pos:neg 13 8\n",
      "Accuracy: 63.44% Precision: 64.52% Recall: 61.30%\n",
      "F1: 62.87% MCC: 0.2695\n",
      "AUPRC: 64.91% AUROC: 67.76%\n",
      " accuracy [63.44294003868471]\n",
      " precision [64.51612903225806]\n",
      " recall [61.30268199233716]\n",
      " F1 [62.86836935166994]\n",
      " MCC [0.2694866313765228]\n",
      " AUPRC [64.91018189671472]\n",
      " AUROC [67.75921934865899]\n",
      "\n",
      "Training # 2 2\n",
      "2023-04-20 14:53:12.665807\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.2.validation_genes.txt\n",
      "2023-04-20 14:53:12.681725\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1043:1028 50.36%\n",
      "Valid 1:0 278:258 51.87%\n",
      "FIT\n",
      "2023-04-20 14:53:12.698243\n",
      "\n",
      "Testing # 2 2\n",
      "2023-04-20 14:53:16.499084\n",
      "2023-04-20 14:53:16.499145\n",
      "PREDICT\n",
      "2023-04-20 14:53:16.503807\n",
      "debug pred [0.3, 0.44, 0.47]\n",
      "debug class [0 0 0]\n",
      "Test 1:0 278:258 51.87%\n",
      "Predict 1:0 284:252 52.99%\n",
      "Test sizes (536, 1025) (536,)\n",
      "Distrib of scores: 0.5077985074626867 mean 0.11251535748249712 std\n",
      "Range of scores: 0.18 to 0.84\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[170  88]\n",
      " [ 82 196]]\n",
      "Normalized matrix\n",
      " [[0.31716418 0.1641791 ]\n",
      " [0.15298507 0.36567164]]\n",
      "Extreme scores correct, pos:neg 38 48\n",
      "Extreme scores incorrect pos:neg 12 7\n",
      "Accuracy: 68.28% Precision: 69.01% Recall: 70.50%\n",
      "F1: 69.75% MCC: 0.3643\n",
      "AUPRC: 70.99% AUROC: 73.08%\n",
      " accuracy [68.28358208955224]\n",
      " precision [69.01408450704226]\n",
      " recall [70.50359712230215]\n",
      " F1 [69.75088967971529]\n",
      " MCC [0.36434714387029143]\n",
      " AUPRC [70.98704320178346]\n",
      " AUROC [73.07665495510568]\n",
      "\n",
      "Training # 2 3\n",
      "2023-04-20 14:53:16.583157\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.3.validation_genes.txt\n",
      "2023-04-20 14:53:16.603903\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1050:1041 50.22%\n",
      "Valid 1:0 271:245 52.52%\n",
      "FIT\n",
      "2023-04-20 14:53:16.622338\n",
      "\n",
      "Testing # 2 3\n",
      "2023-04-20 14:53:21.471271\n",
      "2023-04-20 14:53:21.471328\n",
      "PREDICT\n",
      "2023-04-20 14:53:21.476398\n",
      "debug pred [0.52, 0.63, 0.56]\n",
      "debug class [1 1 1]\n",
      "Test 1:0 271:245 52.52%\n",
      "Predict 1:0 261:255 50.58%\n",
      "Test sizes (516, 1025) (516,)\n",
      "Distrib of scores: 0.5036627906976744 mean 0.11314374240286196 std\n",
      "Range of scores: 0.15 to 0.93\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[163  82]\n",
      " [ 92 179]]\n",
      "Normalized matrix\n",
      " [[0.31589147 0.15891473]\n",
      " [0.17829457 0.34689922]]\n",
      "Extreme scores correct, pos:neg 41 38\n",
      "Extreme scores incorrect pos:neg 14 5\n",
      "Accuracy: 66.28% Precision: 68.58% Recall: 66.05%\n",
      "F1: 67.29% MCC: 0.3254\n",
      "AUPRC: 68.88% AUROC: 70.77%\n",
      " accuracy [66.27906976744185]\n",
      " precision [68.5823754789272]\n",
      " recall [66.05166051660517]\n",
      " F1 [67.29323308270676]\n",
      " MCC [0.3254308486758233]\n",
      " AUPRC [68.87734237507995]\n",
      " AUROC [70.77415468032233]\n",
      "\n",
      "Training # 2 4\n",
      "2023-04-20 14:53:21.557475\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.4.validation_genes.txt\n",
      "2023-04-20 14:53:21.575120\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1080:1019 51.45%\n",
      "Valid 1:0 241:267 47.44%\n",
      "FIT\n",
      "2023-04-20 14:53:21.591355\n",
      "\n",
      "Testing # 2 4\n",
      "2023-04-20 14:53:25.389199\n",
      "2023-04-20 14:53:25.389257\n",
      "PREDICT\n",
      "2023-04-20 14:53:25.394296\n",
      "debug pred [0.57, 0.58, 0.54]\n",
      "debug class [1 1 1]\n",
      "Test 1:0 241:267 47.44%\n",
      "Predict 1:0 275:233 54.13%\n",
      "Test sizes (508, 1025) (508,)\n",
      "Distrib of scores: 0.5089566929133859 mean 0.12036809560451173 std\n",
      "Range of scores: 0.15 to 0.99\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[159 108]\n",
      " [ 74 167]]\n",
      "Normalized matrix\n",
      " [[0.31299213 0.21259843]\n",
      " [0.14566929 0.32874016]]\n",
      "Extreme scores correct, pos:neg 40 45\n",
      "Extreme scores incorrect pos:neg 12 10\n",
      "Accuracy: 64.17% Precision: 60.73% Recall: 69.29%\n",
      "F1: 64.73% MCC: 0.2891\n",
      "AUPRC: 64.99% AUROC: 69.80%\n",
      " accuracy [64.1732283464567]\n",
      " precision [60.72727272727273]\n",
      " recall [69.29460580912863]\n",
      " F1 [64.72868217054264]\n",
      " MCC [0.2890632700383492]\n",
      " AUPRC [64.98908247078477]\n",
      " AUROC [69.79657171274496]\n",
      "\n",
      "Training # 2 5\n",
      "2023-04-20 14:53:25.480314\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.5.validation_genes.txt\n",
      "2023-04-20 14:53:25.498378\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1051:1026 50.60%\n",
      "Valid 1:0 270:260 50.94%\n",
      "FIT\n",
      "2023-04-20 14:53:25.515559\n",
      "\n",
      "Testing # 2 5\n",
      "2023-04-20 14:53:29.896022\n",
      "2023-04-20 14:53:29.896080\n",
      "PREDICT\n",
      "2023-04-20 14:53:29.900978\n",
      "debug pred [0.53, 0.56, 0.48]\n",
      "debug class [1 1 0]\n",
      "Test 1:0 270:260 50.94%\n",
      "Predict 1:0 285:245 53.77%\n",
      "Test sizes (530, 1025) (530,)\n",
      "Distrib of scores: 0.5090377358490565 mean 0.10576236486240612 std\n",
      "Range of scores: 0.23 to 0.96\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[153 107]\n",
      " [ 92 178]]\n",
      "Normalized matrix\n",
      " [[0.28867925 0.20188679]\n",
      " [0.17358491 0.33584906]]\n",
      "Extreme scores correct, pos:neg 36 37\n",
      "Extreme scores incorrect pos:neg 9 9\n",
      "Accuracy: 62.45% Precision: 62.46% Recall: 65.93%\n",
      "F1: 64.14% MCC: 0.2484\n",
      "AUPRC: 68.20% AUROC: 68.82%\n",
      " accuracy [62.45283018867924]\n",
      " precision [62.4561403508772]\n",
      " recall [65.92592592592592]\n",
      " F1 [64.14414414414415]\n",
      " MCC [0.2483851078374314]\n",
      " AUPRC [68.19787392979883]\n",
      " AUROC [68.81695156695157]\n",
      "2023-04-20 14:53:29.991345\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "mcc=[]\n",
    "auprc=[]\n",
    "auroc=[]\n",
    "\n",
    "loader = DataLoader()\n",
    "filepath = DATA_DIR+RCI_FILE_TRAIN\n",
    "print(\"Load RCI from\",filepath)\n",
    "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "filepath = DATA_DIR+SEQ_FILE_TRAIN\n",
    "print('Load sequence from',filepath)\n",
    "allids,allseq = loader.load_spectra(filepath)  # for MLP (load_sequence() for CNN)\n",
    "print('Loaded',len(allseq),'sequences.')\n",
    "test_gene_to_rci = None\n",
    "test_allids = None\n",
    "test_allseq = None\n",
    "if SEQ_FILE_TEST is not None:\n",
    "    # Train on the entire train set (no cross-validation).\n",
    "    # Evaluate with the test files.\n",
    "    test_loader = DataLoader()\n",
    "    filepath = DATA_DIR+RCI_FILE_TEST\n",
    "    print(\"Load RCI from\",filepath)\n",
    "    test_gene_to_rci = test_loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "    print('Num RCI:', len(test_gene_to_rci.keys()))\n",
    "    filepath = DATA_DIR+SEQ_FILE_TEST\n",
    "    print('Load sequence from',filepath)\n",
    "    test_allids,test_allseq = test_loader.load_spectra(filepath)\n",
    "    print('Loaded',len(test_allseq),'sequences.')\n",
    "\n",
    "for repeat in range(REPEATS):\n",
    "    for fold in range(FOLDS):\n",
    "        show_r = repeat+1  # display one-based counting\n",
    "        show_f = fold+1    # display one-based counting\n",
    "\n",
    "        print()\n",
    "        print(\"Training #\",show_r,show_f)\n",
    "        print(datetime.now())\n",
    "        cvdo = CrossValidator(EPOCHS)\n",
    "        cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
    "        if SEQ_FILE_TEST is None:\n",
    "            # Train on 80% and evaluate on 20%.\n",
    "            separator = Separator()\n",
    "            separator.load(DATA_DIR,show_r,show_f)\n",
    "            separator.process(allids,allseq,gene_to_rci)\n",
    "            train_allids,test_allids = separator.get_ids()\n",
    "            train_allseq,test_allseq = separator.get_seq()\n",
    "            train_gene_to_rci,test_gene_to_rci = separator.get_rci()\n",
    "            cvdo.train_new_model(\n",
    "                train_allids,train_allseq,train_gene_to_rci,\n",
    "                test_allids,test_allseq,test_gene_to_rci)\n",
    "            if SAVE_MODEL_FILENAME is not None:\n",
    "                filename = f\"{SAVE_MODEL_FILENAME}.{show_r}.{show_f}.model\"\n",
    "                cvdo.save_model(filename)\n",
    "        else:\n",
    "            # Train on the entire train set (no cross-validation).\n",
    "            # Evaluate with the test files.\n",
    "            train_allids = allids\n",
    "            train_allseq = allseq\n",
    "            train_gene_to_rci = gene_to_rci\n",
    "            BREAK = True\n",
    "            cvdo.train_new_model(\n",
    "                train_allids,train_allseq,train_gene_to_rci,\n",
    "                None,None,None)\n",
    "\n",
    "        print()\n",
    "        print(\"Testing #\",show_r,show_f)\n",
    "        print(datetime.now())\n",
    "        cvdo.reset_statistics()\n",
    "        cvdo.test_without_training(\n",
    "            test_allids,test_allseq,test_gene_to_rci)\n",
    "        cv_accuracy,cv_precision,cv_recall,cv_f1,cv_mcc,cv_auprc,cv_auroc=\\\n",
    "            cvdo.get_statistics()\n",
    "\n",
    "        print(\" accuracy\" ,  cv_accuracy)\n",
    "        print(\" precision\" , cv_precision)\n",
    "        print(\" recall\" ,    cv_recall)\n",
    "        print(\" F1\" ,        cv_f1)\n",
    "        print(\" MCC\" ,       cv_mcc)\n",
    "        print(\" AUPRC\" ,     cv_auprc)\n",
    "        print(\" AUROC\" ,     cv_auroc)\n",
    "\n",
    "        accuracy.append(cv_accuracy)\n",
    "        precision.append(cv_precision)\n",
    "        recall.append(cv_recall)\n",
    "        f1.append(cv_f1)\n",
    "        mcc.append(cv_mcc)\n",
    "        auprc.append(cv_auprc)\n",
    "        auroc.append(cv_auroc)\n",
    "        if BREAK: break\n",
    "    if BREAK: break\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkCeDg_HdQ36",
    "outputId": "a47d9023-b6e6-4e16-d3c8-434843c3dbe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy mean 64.75% std 1.80\n",
      " precision mean 64.86% std 3.35\n",
      " recall mean 66.65% std 2.70\n",
      " F1 mean 65.68% std 2.10\n",
      " MCC mean 0.2959 std 0.0353\n",
      " AUPRC mean 67.45% std 2.52\n",
      " AUROC mean 69.70% std 1.66\n",
      " accuracy [[63.1578947368421], [63.35174953959485], [64.69428007889546], [65.5378486055777], [66.1567877629063], [63.44294003868471], [68.28358208955224], [66.27906976744185], [64.1732283464567], [62.45283018867924]]\n",
      " precision [[61.20996441281139], [62.5], [63.138686131386855], [67.21311475409836], [69.25925925925925], [64.51612903225806], [69.01408450704226], [68.5823754789272], [60.72727272727273], [62.4561403508772]]\n",
      " recall [[66.40926640926641], [67.76556776556777], [68.92430278884463], [63.81322957198443], [66.54804270462633], [61.30268199233716], [70.50359712230215], [66.05166051660517], [69.29460580912863], [65.92592592592592]]\n",
      " F1 [[63.70370370370371], [65.02636203866433], [65.90476190476191], [65.4690618762475], [67.87658802177857], [62.86836935166994], [69.75088967971529], [67.29323308270676], [64.72868217054264], [64.14414414414415]]\n",
      " MCC [[0.2651554756981981], [0.26763241154632905], [0.29566580119867975], [0.31163385570757174], [0.3217773341147742], [0.2694866313765228], [0.36434714387029143], [0.3254308486758233], [0.2890632700383492], [0.2483851078374314]]\n",
      " AUPRC [[64.05071674771659], [67.087824551301], [66.03245717108955], [67.95494072894341], [71.41504692834046], [64.91018189671472], [70.98704320178346], [68.87734237507995], [64.98908247078477], [68.19787392979883]]\n",
      " AUROC [[67.74859632002489], [68.11965811965813], [69.9273219621514], [70.40895735726197], [70.55968942089937], [67.75921934865899], [73.07665495510568], [70.77415468032233], [69.79657171274496], [68.81695156695157]]\n"
     ]
    }
   ],
   "source": [
    "def STD (values):\n",
    "    # ddof=1 reduces bias when extrapolating from sample to population\n",
    "    return np.std(values,ddof=1)\n",
    "\n",
    "print(\" accuracy mean %.2f%% std %.2f\" %  (np.mean(accuracy),  STD(accuracy)))\n",
    "print(\" precision mean %.2f%% std %.2f\" % (np.mean(precision), STD(precision)))\n",
    "print(\" recall mean %.2f%% std %.2f\" %    (np.mean(recall),    STD(recall)))\n",
    "print(\" F1 mean %.2f%% std %.2f\" %        (np.mean(f1),        STD(f1)))\n",
    "print(\" MCC mean %.4f std %.4f\" %       (np.mean(mcc),       STD(mcc)))\n",
    "print(\" AUPRC mean %.2f%% std %.2f\" %     (np.mean(auprc),     STD(auprc)))\n",
    "print(\" AUROC mean %.2f%% std %.2f\" %     (np.mean(auroc),     STD(auroc)))\n",
    "\n",
    "print(\" accuracy\"  , accuracy)\n",
    "print(\" precision\" , precision)\n",
    "print(\" recall\"    , recall)\n",
    "print(\" F1\"        , f1)\n",
    "print(\" MCC\"       , mcc)\n",
    "print(\" AUPRC\"     , auprc)\n",
    "print(\" AUROC\"     , auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "QjSVa72v4IsA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
