{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# Support Vector Machine\n",
    "canonical lncRNA, -1 threshold, cross-valiation, all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "81ca8001-d21f-4fc3-a744-dc968ab32785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 16:02:23.326467\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "1f8ebd8e-8dc6-4e93-e3d6-5ca56d150d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "Running on CoLab\n",
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "/content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
    "    MODEL_DIR=PATH+'My Drive/data/Localization/Models/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR=\"/\"\n",
    "    MODEL_DIR=\"/\"\n",
    "print(DATA_DIR)\n",
    "SAVE_MODEL_FILENAME = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRX-UEr8FLA8",
    "outputId": "0c3fd561-ad35-440a-9267-9e17af25f752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n",
      "sklearn 1.2.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "np.random.seed(42) # supposedly sets scikit-learn\n",
    "import time # sleep function\n",
    "from os.path import isfile\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "K=5\n",
    "ALPHABET=4**K + 1\n",
    "EPOCHS=150 \n",
    "RCI_THRESHOLD_MECHANISM = 'ZERO'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
    "RCI_THRESHOLD_VALUE = -1  # use -1 for lncRNA, use 0 for mRNA\n",
    "BREAK = False   # optionally break after first fold\n",
    "EXCLUSIONS = [1]   # possibly exclude cell line 1 = H1.hESC\n",
    "FILTER_TRAIN        = False\n",
    "FILTER_TAILS_TRAIN  = False\n",
    "FILTER_MIDDLE_TRAIN = False\n",
    "FILTER_TEST         = False\n",
    "FILTER_TAILS_TEST   = False\n",
    "FILTER_MIDDLE_TEST  = False\n",
    "MIDDLE_LOW          = -2   # -2 for lncRNA, -1 for mRNA\n",
    "MIDDLE_HIGH         = 0    #  0 for lncRNA, +1 for mRNA\n",
    "\n",
    "REPEATS = 2\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "LnkpVKdMFLA-"
   },
   "outputs": [],
   "source": [
    "RCI_FILE_TRAIN = 'train.lncRNA_RCI.all_cell_lines.csv'\n",
    "RCI_FILE_TEST  = None # use None for cross-validation\n",
    "\n",
    "SEQ_FILE_TRAIN = 'train.canon_lncRNA_transcripts.csv'\n",
    "SEQ_FILE_TEST  = None # use None for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "e3p4QzQJFLA_"
   },
   "outputs": [],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
    "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
    "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
    "    return ordered_list\n",
    "all_cell_lines = get_ordered_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "p35ehKV3Kq0z"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.cache=dict() \n",
    "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        self.gene2rci = dict()\n",
    "        \n",
    "    def load_gene_rci_values(self,filepath,exclusions):\n",
    "        '''\n",
    "        Load all the genes from the given RCI csv file.\n",
    "        The given file usually contains train or test, not both.\n",
    "        Return dict with keys=gene:str and values=RCI:float.\n",
    "        '''\n",
    "        self.gene2rci = {}\n",
    "        overall_sum = 0\n",
    "        with open (filepath,'r') as handle:\n",
    "            for row in handle:\n",
    "                line = row.strip()\n",
    "                fields = line.split(',')\n",
    "                gene_id = fields.pop(0)\n",
    "                cell_line_index = 0\n",
    "                rci_values = []\n",
    "                log_mean=0.0\n",
    "                for rci_str in fields:\n",
    "                    if cell_line_index not in exclusions:\n",
    "                        if rci_str != \"nan\":\n",
    "                            rci_val = float(rci_str)\n",
    "                            rci_values.append(rci_val)\n",
    "                    cell_line_index += 1\n",
    "                if len(rci_values)>0:\n",
    "                    values = np.array(rci_values)\n",
    "                    antilogs = [2**x for x in values]\n",
    "                    big_mean = np.mean(antilogs)\n",
    "                    # Avoid division by zero\n",
    "                    if np.absolute(big_mean)<0.000001:\n",
    "                        log_mean = -1000000 # neg infinity\n",
    "                    else:\n",
    "                        log_mean = np.log2(big_mean) \n",
    "                    self.gene2rci[gene_id] = log_mean\n",
    "        print('Number of RCI values loaded',len(self.gene2rci.keys()))\n",
    "        return self.gene2rci\n",
    "\n",
    "    def _seq_to_kmer_values(self,rna,K):\n",
    "        vec=[] # seq converted to list of K-mers \n",
    "        N_indicator = 0 # indicator value\n",
    "        length = len(rna)\n",
    "        for i in range(length-K+1):\n",
    "            kmer = rna[i:i+K]\n",
    "            if 'N' in kmer:\n",
    "                value = N_indicator\n",
    "            elif kmer in self.cache.keys():\n",
    "                value = self.cache[kmer]\n",
    "            else:\n",
    "                value = 0\n",
    "                for j in range(K):\n",
    "                    value *= 4   \n",
    "                    nextnuc = kmer[j] \n",
    "                    nucval = self.vals[nextnuc]\n",
    "                    value += nucval\n",
    "                value += 1   # NNN => 0, AAA => 1\n",
    "                self.cache[kmer] = value\n",
    "            vec.append(value)\n",
    "        return vec\n",
    "\n",
    "    def load_sequence(self,filepath):\n",
    "        '''\n",
    "        Load all the sequences from the given file. \n",
    "        Load our version of GenCode -- csv, easier to parse than fasta.\n",
    "        Each line has IDs plus sequence.\n",
    "        The IDs in the file do not include dot-version numbers.\n",
    "        The file may already be filtered e.g. canonical transcripts.\n",
    "        '''\n",
    "        allids=[]\n",
    "        allseq=[]\n",
    "        #NREPEAT = str('N'*MAXLEN)   # not used for MLP\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row\n",
    "                else:\n",
    "                    line    = row.strip()\n",
    "                    fields  = line.split(',')\n",
    "                    tran_id = fields[0]  # without version number\n",
    "                    gene_id = fields[1]  # without version number\n",
    "                    seq_len = int(fields[3])\n",
    "                    seq_txt = fields[4]\n",
    "                    # Keep only transcripts having numeric RCI given the cell lines in use.\n",
    "                    # We have validated this by spot checking.\n",
    "                    # TO DO: validate this programmatically.\n",
    "                    if gene_id in self.gene2rci.keys():\n",
    "                        allids.append( (gene_id,tran_id) )\n",
    "                        hot_vec = self._seq_to_kmer_values(seq_txt,K)\n",
    "                        allseq.append(hot_vec)\n",
    "        self.cache=dict() # save RAM\n",
    "        return allids,allseq\n",
    "\n",
    "    def load_spectra(self,filepath):\n",
    "        '''\n",
    "        Load all (variable-length) sequences as lists of kmers.\n",
    "        Then convert each sequence to (fixed-length) kmer histograms.\n",
    "        '''\n",
    "        allids,allseq = self.load_sequence(filepath)\n",
    "        allspectra = []\n",
    "        for seq in allseq:\n",
    "            spectrum = np.zeros(ALPHABET)\n",
    "            for kmer in seq:\n",
    "                spectrum[kmer] += 1\n",
    "            spectrum /= len(seq)\n",
    "            allspectra.append(spectrum)\n",
    "        return allids,allspectra        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDZ6siB_Kq04"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "AwMbRjm0FLBF"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "    Probability is not the default with SVM.\n",
    "    We use probablity to compute the ARPRC statistic.\n",
    "    The sklearn documenation says:\n",
    "    Whether to enable probability estimates. \n",
    "    This must be enabled prior to calling fit, \n",
    "    will slow down that method as it internally uses 5-fold cross-validation, \n",
    "    and predict_proba may be inconsistent with predict.\n",
    "    '''\n",
    "    svc = SVC(probability=True)\n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clj-wufgFLBF",
    "outputId": "888e7f97-41e4-4eae-cf63-bbe05f1e7e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 16:02:24.468562\n",
      "SVC(probability=True)\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print(model)  # Print this only once\n",
    "model=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgrC1alOKq07"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class CrossValidator():\n",
    "    def __init__(self,epochs,score_threshold=0.5):\n",
    "        self.epochs = epochs\n",
    "        self.score_threshold = score_threshold\n",
    "        self.mechanism = 'ZERO'\n",
    "        self.discriminator = RCI_THRESHOLD_VALUE\n",
    "        self.flip = False\n",
    "        self.reset_statistics()\n",
    "        \n",
    "    def reset_statistics(self):\n",
    "        self.cv_accuracy=[]\n",
    "        self.cv_precision=[]\n",
    "        self.cv_recall=[]\n",
    "        self.cv_f1=[]\n",
    "        self.cv_auprc=[]\n",
    "        self.cv_auroc=[]\n",
    "        self.cv_mcc=[]\n",
    "        \n",
    "    def _get_X_y(self, all_ids, all_seqs, rci_map): \n",
    "        # Prepare X and y for training or testing.\n",
    "        subsetX=[]\n",
    "        subsetY=[]\n",
    "        for t in range(len(all_ids)):\n",
    "            gene_id,tran_id = all_ids[t]\n",
    "            oneX            = all_seqs[t]\n",
    "            oneY            = rci_map[gene_id]\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(oneY)\n",
    "        subsetX = np.array(subsetX)\n",
    "        subsetY = np.array(subsetY).reshape((-1,1))\n",
    "        return subsetX,subsetY\n",
    "    \n",
    "    def set_threshold_mechanism(self, mechanism):\n",
    "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
    "            raise Exception('Unrecognized mechansm:',mechanism)\n",
    "        self.mechanism = mechanism\n",
    "    \n",
    "    def _apply_threshold(self, array_of_rci):\n",
    "        # Takes list of float, returns list of labels [0,1].\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            labels = self.discriminator.predict(array_of_rci)\n",
    "            if self.flip:\n",
    "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
    "                labels = np.array(list(map(IS_CYTO, labels)))\n",
    "        else:  # 'THE_MEAN' or 'ZERO'\n",
    "            rci_threshold = self.discriminator\n",
    "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
    "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
    "        return labels\n",
    "    \n",
    "    def _prepare_threshold(self, rci_values, create=True):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            if create:  # during training, create a new GMM\n",
    "                gmm = GaussianMixture(n_components=2, verbose=0, \n",
    "                  covariance_type='spherical', n_init=100) # random_state=42) \n",
    "                gmm.fit(rci_values)\n",
    "            else:   # during testing, use existing GMM\n",
    "                gmm=self.discriminator\n",
    "            self.flip = False\n",
    "            # The GMM labels are arbitrary.\n",
    "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
    "                self.flip = True\n",
    "            self.discriminator = gmm   # redundant but consistent\n",
    "        elif self.mechanism == 'THE_MEAN':\n",
    "            self.discriminator = np.mean(rci_values)\n",
    "        elif self.mechanism == 'ZERO':\n",
    "            self.discriminator = RCI_THRESHOLD_VALUE\n",
    "        else: # not expected\n",
    "            self.discriminator = 0\n",
    "    \n",
    "    def _explain_threshold(self):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            gmm=self.discriminator\n",
    "            print('Discriminator is GMM')\n",
    "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
    "            print('Variances',gmm.covariances_)\n",
    "            print('Priors',gmm.weights_)\n",
    "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
    "            print(test_rcis)\n",
    "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
    "        else:\n",
    "            print('Discriminator',self.mechanism,self.discriminator)\n",
    "    \n",
    "    def _show_sizes(self,label,values):\n",
    "        a = np.count_nonzero(values==1)\n",
    "        b = np.count_nonzero(values==0)\n",
    "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
    "        \n",
    "    def save_model(self,filename):\n",
    "        if self.model is not None:\n",
    "            filepath = MODEL_DIR + filename\n",
    "            #self.model.save(filepath)\n",
    "            print('? Saved model to',filepath)\n",
    "        \n",
    "    def load_model(self,filename):\n",
    "        filepath = MODEL_DIR + filename\n",
    "        #self.model = keras.models.load_model(filepath)\n",
    "        print('? Loaded model from',filepath)\n",
    "        \n",
    "    def train_new_model(self,train_ids,train_seq,train_rci,\n",
    "            valid_ids=None,valid_seq=None,valid_rci=None):\n",
    "        print(datetime.now())\n",
    "        X_train,y_rci = self._get_X_y(train_ids,train_seq,train_rci) \n",
    "        self._prepare_threshold(y_rci,True)  \n",
    "        self._explain_threshold()\n",
    "        y_train = self._apply_threshold(y_rci)\n",
    "        self._show_sizes('Train',y_train)\n",
    "        if valid_ids is not None:\n",
    "            X_valid,y_rci = self._get_X_y(valid_ids,valid_seq,valid_rci) \n",
    "            y_valid = self._apply_threshold(y_rci)\n",
    "            self._show_sizes('Valid',y_valid)\n",
    "        y_rci = None\n",
    "\n",
    "        self.model=build_model()\n",
    "        \n",
    "        print(\"FIT\")\n",
    "        print(datetime.now())\n",
    "        self.model.fit(X_train, y_train) # sample weight\n",
    "\n",
    "    def test_without_training(self,test_ids,test_seq,test_rci):\n",
    "        # For final test, do no train.\n",
    "        # Assume set_sequences() set the test set.\n",
    "        print(datetime.now())\n",
    "        X_test,y_rci = self._get_X_y(test_ids,test_seq,test_rci) \n",
    "        y_test = self._apply_threshold(y_rci)\n",
    "        y_rci = None\n",
    "        \n",
    "        print(\"PREDICT\")\n",
    "        print(datetime.now())        \n",
    "        yhat_pairs=self.model.predict_proba(X_test)  # [ prob of 0, prob of 1 ]\n",
    "        yhat_pred=[pair[1] for pair in yhat_pairs]\n",
    "        yhat_classes=self.model.predict(X_test)  # 0 or 1\n",
    "        \n",
    "        print('debug pred',yhat_pred[:3])\n",
    "        print('debug class',yhat_classes[:3])\n",
    "\n",
    "        self._show_sizes('Test',y_test)\n",
    "        self._show_sizes('Predict',yhat_classes)\n",
    "        print('Test sizes',X_test.shape,y_test.shape)\n",
    "        print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
    "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "        print('Score threshold',self.score_threshold)\n",
    "        cm1 = confusion_matrix(y_test,yhat_classes)\n",
    "        print('Confusion matrix\\n',cm1)\n",
    "        cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
    "        print('Normalized matrix\\n',cm2)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
    "        precision = precision_score(y_test, yhat_classes)*100.\n",
    "        recall = recall_score(y_test, yhat_classes)*100.\n",
    "        f1 = f1_score(y_test, yhat_classes)*100.\n",
    "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
    "        auprc = auc(prc_X,prc_Y)*100.\n",
    "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
    "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
    "\n",
    "        correct_pos = 0\n",
    "        correct_neg = 0\n",
    "        wrong_pos = 0\n",
    "        wrong_neg = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if yhat_pred[i]>=0.65:\n",
    "                if y_test[i]==1:\n",
    "                    correct_pos += 1\n",
    "                else:\n",
    "                    wrong_pos += 1\n",
    "            elif yhat_pred[i]<=0.35:\n",
    "                if y_test[i]==0:\n",
    "                    correct_neg += 1\n",
    "                else:\n",
    "                    wrong_neg += 1\n",
    "        print('Extreme scores correct, pos:neg',correct_pos,correct_neg)  \n",
    "        print('Extreme scores incorrect pos:neg',wrong_pos,wrong_neg)  \n",
    "\n",
    "        print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
    "        print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
    "        print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n",
    "\n",
    "        self.cv_accuracy.append(accuracy)\n",
    "        self.cv_precision.append(precision)\n",
    "        self.cv_recall.append(recall)\n",
    "        self.cv_f1.append(f1)\n",
    "        self.cv_mcc.append(mcc)\n",
    "        self.cv_auprc.append(auprc)\n",
    "        self.cv_auroc.append(auroc)\n",
    "\n",
    "    def get_statistics(self):\n",
    "        return \\\n",
    "        self.cv_accuracy,\\\n",
    "        self.cv_precision,\\\n",
    "        self.cv_recall,\\\n",
    "        self.cv_f1,\\\n",
    "        self.cv_mcc,\\\n",
    "        self.cv_auprc,\\\n",
    "        self.cv_auroc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td97uyyj5qDq"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "poe3rwAF4Ir7"
   },
   "outputs": [],
   "source": [
    "class Separator():\n",
    "    def __init__(self):\n",
    "        self.train_ids = []\n",
    "        self.train_seq = []\n",
    "        self.train_rci = dict()\n",
    "        self.val_ids = []\n",
    "        self.val_seq = []\n",
    "        self.val_rci = dict()\n",
    "    def load(self,data_dir,rep,fold):\n",
    "        filename='cv.{}.{}.validation_genes.txt'.format(rep,fold)\n",
    "        filename = data_dir + filename\n",
    "        self.val_genes = set()\n",
    "        print('Opening file',filename)\n",
    "        with open(filename,'r') as fin:\n",
    "            for line in fin:\n",
    "                gene_id = line.strip()\n",
    "                self.val_genes.add(gene_id)\n",
    "    def process(self,allids,allseq,gene_to_rci):\n",
    "        size = len(allids)\n",
    "        for t in range(size):\n",
    "            gene_id,tran_id = allids[t]\n",
    "            oneX            = allseq[t]\n",
    "            oneY            = gene_to_rci[gene_id]\n",
    "            in_middle = gene_to_rci[gene_id] >= MIDDLE_LOW and gene_to_rci[gene_id] <= MIDDLE_HIGH\n",
    "            in_tails = gene_to_rci[gene_id] < MIDDLE_LOW or gene_to_rci[gene_id] > MIDDLE_HIGH\n",
    "            if gene_id in self.val_genes:\n",
    "                if FILTER_TEST and (\\\n",
    "                    (FILTER_TAILS_TEST and in_tails) or \\\n",
    "                    (FILTER_MIDDLE_TEST and in_middle)):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.val_ids.append(allids[t])\n",
    "                    self.val_seq.append(allseq[t])\n",
    "                    self.val_rci[gene_id]=gene_to_rci[gene_id]\n",
    "            else:\n",
    "                if FILTER_TRAIN and (\\\n",
    "                    (FILTER_TAILS_TRAIN and in_tails) or \\\n",
    "                    (FILTER_MIDDLE_TRAIN and in_middle)):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.train_ids.append(allids[t])\n",
    "                    self.train_seq.append(allseq[t])\n",
    "                    self.train_rci[gene_id]=gene_to_rci[gene_id]\n",
    "    def get_ids(self):\n",
    "        return self.train_ids,self.val_ids\n",
    "    def get_seq(self):\n",
    "        return self.train_seq,self.val_seq\n",
    "    def get_rci(self):\n",
    "        return self.train_rci,self.val_rci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "8ab60f57-50da-4bb1-c5f6-4f6c1885e486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 16:02:24.557068\n",
      "Load RCI from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.lncRNA_RCI.all_cell_lines.csv\n",
      "Number of RCI values loaded 4372\n",
      "Num RCI: 4372\n",
      "Load sequence from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.canon_lncRNA_transcripts.csv\n",
      "Loaded 4372 sequences.\n",
      "\n",
      "Training # 1 1\n",
      "2023-04-20 16:02:33.778598\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.1.validation_genes.txt\n",
      "2023-04-20 16:02:33.789697\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1810:1687 51.76%\n",
      "Valid 1:0 433:442 49.49%\n",
      "FIT\n",
      "2023-04-20 16:02:33.814100\n",
      "\n",
      "Testing # 1 1\n",
      "2023-04-20 16:03:23.925348\n",
      "2023-04-20 16:03:23.925417\n",
      "PREDICT\n",
      "2023-04-20 16:03:23.936259\n",
      "debug pred [0.5977560500885706, 0.3941707967551193, 0.30807496246726507]\n",
      "debug class [1 0 0]\n",
      "Test 1:0 433:442 49.49%\n",
      "Predict 1:0 490:385 56.00%\n",
      "Test sizes (875, 1025) (875,)\n",
      "Distrib of scores: 0.5290515794819569 mean 0.14297878141695802 std\n",
      "Range of scores: 0.16791161159806292 to 0.9106752877304697\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[246 196]\n",
      " [139 294]]\n",
      "Normalized matrix\n",
      " [[0.28114286 0.224     ]\n",
      " [0.15885714 0.336     ]]\n",
      "Extreme scores correct, pos:neg 134 70\n",
      "Extreme scores incorrect pos:neg 48 26\n",
      "Accuracy: 61.71% Precision: 60.00% Recall: 67.90%\n",
      "F1: 63.71% MCC: 0.2372\n",
      "AUPRC: 64.70% AUROC: 67.02%\n",
      " accuracy [61.71428571428571]\n",
      " precision [60.0]\n",
      " recall [67.89838337182448]\n",
      " F1 [63.705308775731304]\n",
      " MCC [0.23724683081419373]\n",
      " AUPRC [64.70172584300064]\n",
      " AUROC [67.01691868788731]\n",
      "\n",
      "Training # 1 2\n",
      "2023-04-20 16:03:31.061464\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.2.validation_genes.txt\n",
      "2023-04-20 16:03:31.078512\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1789:1708 51.16%\n",
      "Valid 1:0 454:421 51.89%\n",
      "FIT\n",
      "2023-04-20 16:03:31.103303\n",
      "\n",
      "Testing # 1 2\n",
      "2023-04-20 16:04:20.967405\n",
      "2023-04-20 16:04:20.967813\n",
      "PREDICT\n",
      "2023-04-20 16:04:20.976038\n",
      "debug pred [0.39933020961823257, 0.3598735856898879, 0.6954356351384762]\n",
      "debug class [0 0 1]\n",
      "Test 1:0 454:421 51.89%\n",
      "Predict 1:0 451:424 51.54%\n",
      "Test sizes (875, 1025) (875,)\n",
      "Distrib of scores: 0.5108590684653743 mean 0.139969594603659 std\n",
      "Range of scores: 0.09691156199468895 to 0.8486182227759871\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[251 170]\n",
      " [173 281]]\n",
      "Normalized matrix\n",
      " [[0.28685714 0.19428571]\n",
      " [0.19771429 0.32114286]]\n",
      "Extreme scores correct, pos:neg 95 86\n",
      "Extreme scores incorrect pos:neg 50 29\n",
      "Accuracy: 60.80% Precision: 62.31% Recall: 61.89%\n",
      "F1: 62.10% MCC: 0.2151\n",
      "AUPRC: 65.88% AUROC: 65.37%\n",
      " accuracy [60.8]\n",
      " precision [62.3059866962306]\n",
      " recall [61.89427312775331]\n",
      " F1 [62.09944751381216]\n",
      " MCC [0.21509162166944729]\n",
      " AUPRC [65.87591315859216]\n",
      " AUROC [65.3708916257704]\n",
      "\n",
      "Training # 1 3\n",
      "2023-04-20 16:04:28.042935\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.3.validation_genes.txt\n",
      "2023-04-20 16:04:28.057450\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1810:1688 51.74%\n",
      "Valid 1:0 433:441 49.54%\n",
      "FIT\n",
      "2023-04-20 16:04:28.082256\n",
      "\n",
      "Testing # 1 3\n",
      "2023-04-20 16:05:18.037496\n",
      "2023-04-20 16:05:18.037563\n",
      "PREDICT\n",
      "2023-04-20 16:05:18.045144\n",
      "debug pred [0.5392789856589862, 0.6501511585452294, 0.3161454790283082]\n",
      "debug class [1 1 0]\n",
      "Test 1:0 433:441 49.54%\n",
      "Predict 1:0 452:422 51.72%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5085149044267118 mean 0.14451194878580134 std\n",
      "Range of scores: 0.0996695478390367 to 0.9013371171251342\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[263 178]\n",
      " [159 274]]\n",
      "Normalized matrix\n",
      " [[0.30091533 0.20366133]\n",
      " [0.1819222  0.31350114]]\n",
      "Extreme scores correct, pos:neg 95 82\n",
      "Extreme scores incorrect pos:neg 52 26\n",
      "Accuracy: 61.44% Precision: 60.62% Recall: 63.28%\n",
      "F1: 61.92% MCC: 0.2293\n",
      "AUPRC: 61.67% AUROC: 65.06%\n",
      " accuracy [61.441647597254004]\n",
      " precision [60.61946902654868]\n",
      " recall [63.279445727482674]\n",
      " F1 [61.92090395480226]\n",
      " MCC [0.22929185484811085]\n",
      " AUPRC [61.66767801673514]\n",
      " AUROC [65.0631307180301]\n",
      "\n",
      "Training # 1 4\n",
      "2023-04-20 16:05:24.798881\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.4.validation_genes.txt\n",
      "2023-04-20 16:05:24.822658\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1778:1720 50.83%\n",
      "Valid 1:0 465:409 53.20%\n",
      "FIT\n",
      "2023-04-20 16:05:24.850617\n",
      "\n",
      "Testing # 1 4\n",
      "2023-04-20 16:06:14.830351\n",
      "2023-04-20 16:06:14.830590\n",
      "PREDICT\n",
      "2023-04-20 16:06:14.836280\n",
      "debug pred [0.47178055384015427, 0.46595404816125546, 0.7204099983222205]\n",
      "debug class [0 0 1]\n",
      "Test 1:0 465:409 53.20%\n",
      "Predict 1:0 452:422 51.72%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5078789964510182 mean 0.13565766913924307 std\n",
      "Range of scores: 0.12743271123411554 to 0.8787718079156545\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[245 164]\n",
      " [177 288]]\n",
      "Normalized matrix\n",
      " [[0.28032037 0.18764302]\n",
      " [0.20251716 0.32951945]]\n",
      "Extreme scores correct, pos:neg 104 80\n",
      "Extreme scores incorrect pos:neg 35 33\n",
      "Accuracy: 60.98% Precision: 63.72% Recall: 61.94%\n",
      "F1: 62.81% MCC: 0.2181\n",
      "AUPRC: 67.37% AUROC: 65.73%\n",
      " accuracy [60.983981693363845]\n",
      " precision [63.716814159292035]\n",
      " recall [61.935483870967744]\n",
      " F1 [62.81352235550709]\n",
      " MCC [0.21805661799806342]\n",
      " AUPRC [67.37006013823441]\n",
      " AUROC [65.72810684333675]\n",
      "\n",
      "Training # 1 5\n",
      "2023-04-20 16:06:21.700433\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.5.validation_genes.txt\n",
      "2023-04-20 16:06:21.718447\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1785:1713 51.03%\n",
      "Valid 1:0 458:416 52.40%\n",
      "FIT\n",
      "2023-04-20 16:06:21.744507\n",
      "\n",
      "Testing # 1 5\n",
      "2023-04-20 16:07:10.752471\n",
      "2023-04-20 16:07:10.752559\n",
      "PREDICT\n",
      "2023-04-20 16:07:10.758771\n",
      "debug pred [0.32891919349591425, 0.49408263204232133, 0.38976054007306477]\n",
      "debug class [0 0 0]\n",
      "Test 1:0 458:416 52.40%\n",
      "Predict 1:0 444:430 50.80%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5045336049559381 mean 0.13683809478157563 std\n",
      "Range of scores: 0.14919589960593052 to 0.8729943560238452\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[249 167]\n",
      " [181 277]]\n",
      "Normalized matrix\n",
      " [[0.28489703 0.19107551]\n",
      " [0.20709382 0.31693364]]\n",
      "Extreme scores correct, pos:neg 95 82\n",
      "Extreme scores incorrect pos:neg 39 28\n",
      "Accuracy: 60.18% Precision: 62.39% Recall: 60.48%\n",
      "F1: 61.42% MCC: 0.2032\n",
      "AUPRC: 64.41% AUROC: 65.10%\n",
      " accuracy [60.18306636155606]\n",
      " precision [62.387387387387385]\n",
      " recall [60.480349344978166]\n",
      " F1 [61.41906873614191]\n",
      " MCC [0.20315230626283132]\n",
      " AUPRC [64.41179221752242]\n",
      " AUROC [65.10276704736312]\n",
      "\n",
      "Training # 2 1\n",
      "2023-04-20 16:07:17.476538\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.1.validation_genes.txt\n",
      "2023-04-20 16:07:17.498571\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1807:1690 51.67%\n",
      "Valid 1:0 436:439 49.83%\n",
      "FIT\n",
      "2023-04-20 16:07:17.528026\n",
      "\n",
      "Testing # 2 1\n",
      "2023-04-20 16:08:07.559718\n",
      "2023-04-20 16:08:07.559789\n",
      "PREDICT\n",
      "2023-04-20 16:08:07.566134\n",
      "debug pred [0.6291534265425311, 0.5288219165340712, 0.29711818550776253]\n",
      "debug class [1 1 0]\n",
      "Test 1:0 436:439 49.83%\n",
      "Predict 1:0 444:431 50.74%\n",
      "Test sizes (875, 1025) (875,)\n",
      "Distrib of scores: 0.5070142066446359 mean 0.1418706451605843 std\n",
      "Range of scores: 0.10147696494766685 to 0.8894742150198032\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[265 174]\n",
      " [166 270]]\n",
      "Normalized matrix\n",
      " [[0.30285714 0.19885714]\n",
      " [0.18971429 0.30857143]]\n",
      "Extreme scores correct, pos:neg 91 84\n",
      "Extreme scores incorrect pos:neg 50 39\n",
      "Accuracy: 61.14% Precision: 60.81% Recall: 61.93%\n",
      "F1: 61.36% MCC: 0.2229\n",
      "AUPRC: 60.77% AUROC: 63.55%\n",
      " accuracy [61.142857142857146]\n",
      " precision [60.810810810810814]\n",
      " recall [61.92660550458715]\n",
      " F1 [61.36363636363637]\n",
      " MCC [0.22293399778962905]\n",
      " AUPRC [60.76807449971364]\n",
      " AUROC [63.551702158784565]\n",
      "\n",
      "Training # 2 2\n",
      "2023-04-20 16:08:14.442768\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.2.validation_genes.txt\n",
      "2023-04-20 16:08:14.464459\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1794:1703 51.30%\n",
      "Valid 1:0 449:426 51.31%\n",
      "FIT\n",
      "2023-04-20 16:08:14.498393\n",
      "\n",
      "Testing # 2 2\n",
      "2023-04-20 16:09:05.229667\n",
      "2023-04-20 16:09:05.229726\n",
      "PREDICT\n",
      "2023-04-20 16:09:05.236146\n",
      "debug pred [0.5299647641255479, 0.4823388353682192, 0.28521825957486807]\n",
      "debug class [1 0 0]\n",
      "Test 1:0 449:426 51.31%\n",
      "Predict 1:0 503:372 57.49%\n",
      "Test sizes (875, 1025) (875,)\n",
      "Distrib of scores: 0.5265002985765416 mean 0.13642317658968864 std\n",
      "Range of scores: 0.11989580565693957 to 0.8630125711397202\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[243 183]\n",
      " [129 320]]\n",
      "Normalized matrix\n",
      " [[0.27771429 0.20914286]\n",
      " [0.14742857 0.36571429]]\n",
      "Extreme scores correct, pos:neg 122 70\n",
      "Extreme scores incorrect pos:neg 47 22\n",
      "Accuracy: 64.34% Precision: 63.62% Recall: 71.27%\n",
      "F1: 67.23% MCC: 0.2862\n",
      "AUPRC: 67.65% AUROC: 68.60%\n",
      " accuracy [64.34285714285714]\n",
      " precision [63.618290258449306]\n",
      " recall [71.26948775055679]\n",
      " F1 [67.22689075630252]\n",
      " MCC [0.2862457771217276]\n",
      " AUPRC [67.64879613071803]\n",
      " AUROC [68.60028022627226]\n",
      "\n",
      "Training # 2 3\n",
      "2023-04-20 16:09:12.383764\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.3.validation_genes.txt\n",
      "2023-04-20 16:09:12.411129\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1771:1727 50.63%\n",
      "Valid 1:0 472:402 54.00%\n",
      "FIT\n",
      "2023-04-20 16:09:12.452989\n",
      "\n",
      "Testing # 2 3\n",
      "2023-04-20 16:10:03.310811\n",
      "2023-04-20 16:10:03.310872\n",
      "PREDICT\n",
      "2023-04-20 16:10:03.318582\n",
      "debug pred [0.44946510504506393, 0.6605915059283206, 0.7531204093113117]\n",
      "debug class [0 1 1]\n",
      "Test 1:0 472:402 54.00%\n",
      "Predict 1:0 440:434 50.34%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5064219764535635 mean 0.13907601653957127 std\n",
      "Range of scores: 0.11654274488685008 to 0.8787311036359983\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[247 155]\n",
      " [187 285]]\n",
      "Normalized matrix\n",
      " [[0.2826087  0.17734554]\n",
      " [0.21395881 0.32608696]]\n",
      "Extreme scores correct, pos:neg 94 84\n",
      "Extreme scores incorrect pos:neg 40 32\n",
      "Accuracy: 60.87% Precision: 64.77% Recall: 60.38%\n",
      "F1: 62.50% MCC: 0.2175\n",
      "AUPRC: 66.75% AUROC: 64.87%\n",
      " accuracy [60.86956521739131]\n",
      " precision [64.77272727272727]\n",
      " recall [60.381355932203384]\n",
      " F1 [62.499999999999986]\n",
      " MCC [0.21754544862889336]\n",
      " AUPRC [66.75281607685409]\n",
      " AUROC [64.86819082553335]\n",
      "\n",
      "Training # 2 4\n",
      "2023-04-20 16:10:10.744586\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.4.validation_genes.txt\n",
      "2023-04-20 16:10:10.772835\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1816:1682 51.92%\n",
      "Valid 1:0 427:447 48.86%\n",
      "FIT\n",
      "2023-04-20 16:10:10.824241\n",
      "\n",
      "Testing # 2 4\n",
      "2023-04-20 16:10:59.888236\n",
      "2023-04-20 16:10:59.888324\n",
      "PREDICT\n",
      "2023-04-20 16:10:59.893985\n",
      "debug pred [0.4068856321933041, 0.4818973549457395, 0.6593174805792592]\n",
      "debug class [0 0 1]\n",
      "Test 1:0 427:447 48.86%\n",
      "Predict 1:0 452:422 51.72%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5089775376970956 mean 0.13889693595339975 std\n",
      "Range of scores: 0.13368887924273257 to 0.8868931194456121\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[263 184]\n",
      " [159 268]]\n",
      "Normalized matrix\n",
      " [[0.30091533 0.21052632]\n",
      " [0.1819222  0.30663616]]\n",
      "Extreme scores correct, pos:neg 94 88\n",
      "Extreme scores incorrect pos:neg 43 24\n",
      "Accuracy: 60.76% Precision: 59.29% Recall: 62.76%\n",
      "F1: 60.98% MCC: 0.2161\n",
      "AUPRC: 61.78% AUROC: 65.09%\n",
      " accuracy [60.755148741418765]\n",
      " precision [59.29203539823009]\n",
      " recall [62.76346604215457]\n",
      " F1 [60.978384527872585]\n",
      " MCC [0.21607231520807663]\n",
      " AUPRC [61.78234576121295]\n",
      " AUROC [65.08731119249327]\n",
      "\n",
      "Training # 2 5\n",
      "2023-04-20 16:11:07.469193\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.5.validation_genes.txt\n",
      "2023-04-20 16:11:07.494424\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1784:1714 51.00%\n",
      "Valid 1:0 459:415 52.52%\n",
      "FIT\n",
      "2023-04-20 16:11:07.541594\n",
      "\n",
      "Testing # 2 5\n",
      "2023-04-20 16:11:56.100181\n",
      "2023-04-20 16:11:56.100339\n",
      "PREDICT\n",
      "2023-04-20 16:11:56.107386\n",
      "debug pred [0.6576924827911943, 0.6024502162519818, 0.5862192140834038]\n",
      "debug class [1 1 1]\n",
      "Test 1:0 459:415 52.52%\n",
      "Predict 1:0 465:409 53.20%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5131216588667823 mean 0.13341967200222934 std\n",
      "Range of scores: 0.18172478666372102 to 0.8707323579745414\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[254 161]\n",
      " [155 304]]\n",
      "Normalized matrix\n",
      " [[0.29061785 0.18421053]\n",
      " [0.17734554 0.34782609]]\n",
      "Extreme scores correct, pos:neg 101 69\n",
      "Extreme scores incorrect pos:neg 43 32\n",
      "Accuracy: 63.84% Precision: 65.38% Recall: 66.23%\n",
      "F1: 65.80% MCC: 0.2746\n",
      "AUPRC: 69.20% AUROC: 67.96%\n",
      " accuracy [63.84439359267735]\n",
      " precision [65.3763440860215]\n",
      " recall [66.23093681917211]\n",
      " F1 [65.80086580086581]\n",
      " MCC [0.2745738630785252]\n",
      " AUPRC [69.20275808729627]\n",
      " AUROC [67.95679449825445]\n",
      "2023-04-20 16:12:03.595368\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "mcc=[]\n",
    "auprc=[]\n",
    "auroc=[]\n",
    "\n",
    "loader = DataLoader()\n",
    "filepath = DATA_DIR+RCI_FILE_TRAIN\n",
    "print(\"Load RCI from\",filepath)\n",
    "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "filepath = DATA_DIR+SEQ_FILE_TRAIN\n",
    "print('Load sequence from',filepath)\n",
    "allids,allseq = loader.load_spectra(filepath)  # for MLP (load_sequence() for CNN)\n",
    "print('Loaded',len(allseq),'sequences.')\n",
    "test_gene_to_rci = None\n",
    "test_allids = None\n",
    "test_allseq = None\n",
    "if SEQ_FILE_TEST is not None:\n",
    "    # Train on the entire train set (no cross-validation).\n",
    "    # Evaluate with the test files.\n",
    "    test_loader = DataLoader()\n",
    "    filepath = DATA_DIR+RCI_FILE_TEST\n",
    "    print(\"Load RCI from\",filepath)\n",
    "    test_gene_to_rci = test_loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "    print('Num RCI:', len(test_gene_to_rci.keys()))\n",
    "    filepath = DATA_DIR+SEQ_FILE_TEST\n",
    "    print('Load sequence from',filepath)\n",
    "    test_allids,test_allseq = test_loader.load_spectra(filepath)\n",
    "    print('Loaded',len(test_allseq),'sequences.')\n",
    "\n",
    "for repeat in range(REPEATS):\n",
    "    for fold in range(FOLDS):\n",
    "        show_r = repeat+1  # display one-based counting\n",
    "        show_f = fold+1    # display one-based counting\n",
    "\n",
    "        print()\n",
    "        print(\"Training #\",show_r,show_f)\n",
    "        print(datetime.now())\n",
    "        cvdo = CrossValidator(EPOCHS)\n",
    "        cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
    "        if SEQ_FILE_TEST is None:\n",
    "            # Train on 80% and evaluate on 20%.\n",
    "            separator = Separator()\n",
    "            separator.load(DATA_DIR,show_r,show_f)\n",
    "            separator.process(allids,allseq,gene_to_rci)\n",
    "            train_allids,test_allids = separator.get_ids()\n",
    "            train_allseq,test_allseq = separator.get_seq()\n",
    "            train_gene_to_rci,test_gene_to_rci = separator.get_rci()\n",
    "            cvdo.train_new_model(\n",
    "                train_allids,train_allseq,train_gene_to_rci,\n",
    "                test_allids,test_allseq,test_gene_to_rci)\n",
    "            if SAVE_MODEL_FILENAME is not None:\n",
    "                filename = f\"{SAVE_MODEL_FILENAME}.{show_r}.{show_f}.model\"\n",
    "                cvdo.save_model(filename)\n",
    "        else:\n",
    "            # Train on the entire train set (no cross-validation).\n",
    "            # Evaluate with the test files.\n",
    "            train_allids = allids\n",
    "            train_allseq = allseq\n",
    "            train_gene_to_rci = gene_to_rci\n",
    "            BREAK = True\n",
    "            cvdo.train_new_model(\n",
    "                train_allids,train_allseq,train_gene_to_rci,\n",
    "                None,None,None)\n",
    "\n",
    "        print()\n",
    "        print(\"Testing #\",show_r,show_f)\n",
    "        print(datetime.now())\n",
    "        cvdo.reset_statistics()\n",
    "        cvdo.test_without_training(\n",
    "            test_allids,test_allseq,test_gene_to_rci)\n",
    "        cv_accuracy,cv_precision,cv_recall,cv_f1,cv_mcc,cv_auprc,cv_auroc=\\\n",
    "            cvdo.get_statistics()\n",
    "\n",
    "        print(\" accuracy\" ,  cv_accuracy)\n",
    "        print(\" precision\" , cv_precision)\n",
    "        print(\" recall\" ,    cv_recall)\n",
    "        print(\" F1\" ,        cv_f1)\n",
    "        print(\" MCC\" ,       cv_mcc)\n",
    "        print(\" AUPRC\" ,     cv_auprc)\n",
    "        print(\" AUROC\" ,     cv_auroc)\n",
    "\n",
    "        accuracy.append(cv_accuracy)\n",
    "        precision.append(cv_precision)\n",
    "        recall.append(cv_recall)\n",
    "        f1.append(cv_f1)\n",
    "        mcc.append(cv_mcc)\n",
    "        auprc.append(cv_auprc)\n",
    "        auroc.append(cv_auroc)\n",
    "        if BREAK: break\n",
    "    if BREAK: break\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkCeDg_HdQ36",
    "outputId": "571cbf2c-c539-4925-c1d6-35260532d499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy mean 61.61% std 1.38\n",
      " precision mean 62.29% std 2.07\n",
      " recall mean 63.81% std 3.55\n",
      " F1 mean 62.98% std 2.05\n",
      " MCC mean 0.2320 std 0.0272\n",
      " AUPRC mean 65.02% std 2.87\n",
      " AUROC mean 65.83% std 1.55\n",
      " accuracy [[61.71428571428571], [60.8], [61.441647597254004], [60.983981693363845], [60.18306636155606], [61.142857142857146], [64.34285714285714], [60.86956521739131], [60.755148741418765], [63.84439359267735]]\n",
      " precision [[60.0], [62.3059866962306], [60.61946902654868], [63.716814159292035], [62.387387387387385], [60.810810810810814], [63.618290258449306], [64.77272727272727], [59.29203539823009], [65.3763440860215]]\n",
      " recall [[67.89838337182448], [61.89427312775331], [63.279445727482674], [61.935483870967744], [60.480349344978166], [61.92660550458715], [71.26948775055679], [60.381355932203384], [62.76346604215457], [66.23093681917211]]\n",
      " F1 [[63.705308775731304], [62.09944751381216], [61.92090395480226], [62.81352235550709], [61.41906873614191], [61.36363636363637], [67.22689075630252], [62.499999999999986], [60.978384527872585], [65.80086580086581]]\n",
      " MCC [[0.23724683081419373], [0.21509162166944729], [0.22929185484811085], [0.21805661799806342], [0.20315230626283132], [0.22293399778962905], [0.2862457771217276], [0.21754544862889336], [0.21607231520807663], [0.2745738630785252]]\n",
      " AUPRC [[64.70172584300064], [65.87591315859216], [61.66767801673514], [67.37006013823441], [64.41179221752242], [60.76807449971364], [67.64879613071803], [66.75281607685409], [61.78234576121295], [69.20275808729627]]\n",
      " AUROC [[67.01691868788731], [65.3708916257704], [65.0631307180301], [65.72810684333675], [65.10276704736312], [63.551702158784565], [68.60028022627226], [64.86819082553335], [65.08731119249327], [67.95679449825445]]\n"
     ]
    }
   ],
   "source": [
    "def STD (values):\n",
    "    # ddof=1 reduces bias when extrapolating from sample to population\n",
    "    return np.std(values,ddof=1)\n",
    "\n",
    "print(\" accuracy mean %.2f%% std %.2f\" %  (np.mean(accuracy),  STD(accuracy)))\n",
    "print(\" precision mean %.2f%% std %.2f\" % (np.mean(precision), STD(precision)))\n",
    "print(\" recall mean %.2f%% std %.2f\" %    (np.mean(recall),    STD(recall)))\n",
    "print(\" F1 mean %.2f%% std %.2f\" %        (np.mean(f1),        STD(f1)))\n",
    "print(\" MCC mean %.4f std %.4f\" %       (np.mean(mcc),       STD(mcc)))\n",
    "print(\" AUPRC mean %.2f%% std %.2f\" %     (np.mean(auprc),     STD(auprc)))\n",
    "print(\" AUROC mean %.2f%% std %.2f\" %     (np.mean(auroc),     STD(auroc)))\n",
    "\n",
    "print(\" accuracy\"  , accuracy)\n",
    "print(\" precision\" , precision)\n",
    "print(\" recall\"    , recall)\n",
    "print(\" F1\"        , f1)\n",
    "print(\" MCC\"       , mcc)\n",
    "print(\" AUPRC\"     , auprc)\n",
    "print(\" AUROC\"     , auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "QjSVa72v4IsA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
