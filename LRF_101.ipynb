{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# Random Forest\n",
    "canonical lncRNA, -1 threshold, cross-valiation, all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "4b701da6-b339-4b73-9e8b-11f37a7cfe6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:49:35.482257\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "8e38ff38-ccb0-4fd3-f81e-9493cbb819f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "Running on CoLab\n",
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "/content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
    "    MODEL_DIR=PATH+'My Drive/data/Localization/Models/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR=\"/\"\n",
    "    MODEL_DIR=\"/\"\n",
    "print(DATA_DIR)\n",
    "SAVE_MODEL_FILENAME = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRX-UEr8FLA8",
    "outputId": "675b9f73-5b84-4bee-860e-7bdff3d602e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n",
      "sklearn 1.2.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "np.random.seed(42) # supposedly sets scikit-learn\n",
    "import time # sleep function\n",
    "from os.path import isfile\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "K=5\n",
    "ALPHABET=4**K + 1\n",
    "EPOCHS=150 \n",
    "RCI_THRESHOLD_MECHANISM = 'ZERO'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
    "RCI_THRESHOLD_VALUE = -1  # use -1 for lncRNA, use 0 for mRNA\n",
    "BREAK = False   # optionally break after first fold\n",
    "EXCLUSIONS = [1]   # possibly exclude cell line 1 = H1.hESC\n",
    "FILTER_TRAIN        = False\n",
    "FILTER_TAILS_TRAIN  = False\n",
    "FILTER_MIDDLE_TRAIN = False\n",
    "FILTER_TEST         = False\n",
    "FILTER_TAILS_TEST   = False\n",
    "FILTER_MIDDLE_TEST  = False\n",
    "MIDDLE_LOW          = -2   # -2 for lncRNA, -1 for mRNA\n",
    "MIDDLE_HIGH         = 0    #  0 for lncRNA, +1 for mRNA\n",
    "\n",
    "REPEATS = 2\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "LnkpVKdMFLA-"
   },
   "outputs": [],
   "source": [
    "RCI_FILE_TRAIN = 'train.lncRNA_RCI.all_cell_lines.csv'\n",
    "RCI_FILE_TEST  = None # use None for cross-validation\n",
    "\n",
    "SEQ_FILE_TRAIN = 'train.canon_lncRNA_transcripts.csv'\n",
    "SEQ_FILE_TEST  = None # use None for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "e3p4QzQJFLA_"
   },
   "outputs": [],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
    "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
    "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
    "    return ordered_list\n",
    "all_cell_lines = get_ordered_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "p35ehKV3Kq0z"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.cache=dict() \n",
    "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        self.gene2rci = dict()\n",
    "        \n",
    "    def load_gene_rci_values(self,filepath,exclusions):\n",
    "        '''\n",
    "        Load all the genes from the given RCI csv file.\n",
    "        The given file usually contains train or test, not both.\n",
    "        Return dict with keys=gene:str and values=RCI:float.\n",
    "        '''\n",
    "        self.gene2rci = {}\n",
    "        overall_sum = 0\n",
    "        with open (filepath,'r') as handle:\n",
    "            for row in handle:\n",
    "                line = row.strip()\n",
    "                fields = line.split(',')\n",
    "                gene_id = fields.pop(0)\n",
    "                cell_line_index = 0\n",
    "                rci_values = []\n",
    "                log_mean=0.0\n",
    "                for rci_str in fields:\n",
    "                    if cell_line_index not in exclusions:\n",
    "                        if rci_str != \"nan\":\n",
    "                            rci_val = float(rci_str)\n",
    "                            rci_values.append(rci_val)\n",
    "                    cell_line_index += 1\n",
    "                if len(rci_values)>0:\n",
    "                    values = np.array(rci_values)\n",
    "                    antilogs = [2**x for x in values]\n",
    "                    big_mean = np.mean(antilogs)\n",
    "                    # Avoid division by zero\n",
    "                    if np.absolute(big_mean)<0.000001:\n",
    "                        log_mean = -1000000 # neg infinity\n",
    "                    else:\n",
    "                        log_mean = np.log2(big_mean) \n",
    "                    self.gene2rci[gene_id] = log_mean\n",
    "        print('Number of RCI values loaded',len(self.gene2rci.keys()))\n",
    "        return self.gene2rci\n",
    "\n",
    "    def _seq_to_kmer_values(self,rna,K):\n",
    "        vec=[] # seq converted to list of K-mers \n",
    "        N_indicator = 0 # indicator value\n",
    "        length = len(rna)\n",
    "        for i in range(length-K+1):\n",
    "            kmer = rna[i:i+K]\n",
    "            if 'N' in kmer:\n",
    "                value = N_indicator\n",
    "            elif kmer in self.cache.keys():\n",
    "                value = self.cache[kmer]\n",
    "            else:\n",
    "                value = 0\n",
    "                for j in range(K):\n",
    "                    value *= 4   \n",
    "                    nextnuc = kmer[j] \n",
    "                    nucval = self.vals[nextnuc]\n",
    "                    value += nucval\n",
    "                value += 1   # NNN => 0, AAA => 1\n",
    "                self.cache[kmer] = value\n",
    "            vec.append(value)\n",
    "        return vec\n",
    "\n",
    "    def load_sequence(self,filepath):\n",
    "        '''\n",
    "        Load all the sequences from the given file. \n",
    "        Load our version of GenCode -- csv, easier to parse than fasta.\n",
    "        Each line has IDs plus sequence.\n",
    "        The IDs in the file do not include dot-version numbers.\n",
    "        The file may already be filtered e.g. canonical transcripts.\n",
    "        '''\n",
    "        allids=[]\n",
    "        allseq=[]\n",
    "        #NREPEAT = str('N'*MAXLEN)   # not used for MLP\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row\n",
    "                else:\n",
    "                    line    = row.strip()\n",
    "                    fields  = line.split(',')\n",
    "                    tran_id = fields[0]  # without version number\n",
    "                    gene_id = fields[1]  # without version number\n",
    "                    seq_len = int(fields[3])\n",
    "                    seq_txt = fields[4]\n",
    "                    # Keep only transcripts having numeric RCI given the cell lines in use.\n",
    "                    # We have validated this by spot checking.\n",
    "                    # TO DO: validate this programmatically.\n",
    "                    if gene_id in self.gene2rci.keys():\n",
    "                        allids.append( (gene_id,tran_id) )\n",
    "                        hot_vec = self._seq_to_kmer_values(seq_txt,K)\n",
    "                        allseq.append(hot_vec)\n",
    "        self.cache=dict() # save RAM\n",
    "        return allids,allseq\n",
    "\n",
    "    def load_spectra(self,filepath):\n",
    "        '''\n",
    "        Load all (variable-length) sequences as lists of kmers.\n",
    "        Then convert each sequence to (fixed-length) kmer histograms.\n",
    "        '''\n",
    "        allids,allseq = self.load_sequence(filepath)\n",
    "        allspectra = []\n",
    "        for seq in allseq:\n",
    "            spectrum = np.zeros(ALPHABET)\n",
    "            for kmer in seq:\n",
    "                spectrum[kmer] += 1\n",
    "            spectrum /= len(seq)\n",
    "            allspectra.append(spectrum)\n",
    "        return allids,allspectra        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDZ6siB_Kq04"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "AwMbRjm0FLBF"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    rfc = RFC()\n",
    "    return rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clj-wufgFLBF",
    "outputId": "04c0bb44-d8fe-408d-fbe0-1022019aab70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:49:39.089154\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print(model)  # Print this only once\n",
    "model=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgrC1alOKq07"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class CrossValidator():\n",
    "    def __init__(self,epochs,score_threshold=0.5):\n",
    "        self.epochs = epochs\n",
    "        self.score_threshold = score_threshold\n",
    "        self.mechanism = 'ZERO'\n",
    "        self.discriminator = RCI_THRESHOLD_VALUE\n",
    "        self.flip = False\n",
    "        self.reset_statistics()\n",
    "        \n",
    "    def reset_statistics(self):\n",
    "        self.cv_accuracy=[]\n",
    "        self.cv_precision=[]\n",
    "        self.cv_recall=[]\n",
    "        self.cv_f1=[]\n",
    "        self.cv_auprc=[]\n",
    "        self.cv_auroc=[]\n",
    "        self.cv_mcc=[]\n",
    "        \n",
    "    def _get_X_y(self, all_ids, all_seqs, rci_map): \n",
    "        # Prepare X and y for training or testing.\n",
    "        subsetX=[]\n",
    "        subsetY=[]\n",
    "        for t in range(len(all_ids)):\n",
    "            gene_id,tran_id = all_ids[t]\n",
    "            oneX            = all_seqs[t]\n",
    "            oneY            = rci_map[gene_id]\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(oneY)\n",
    "        subsetX = np.array(subsetX)\n",
    "        subsetY = np.array(subsetY).reshape((-1,1))\n",
    "        return subsetX,subsetY\n",
    "    \n",
    "    def set_threshold_mechanism(self, mechanism):\n",
    "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
    "            raise Exception('Unrecognized mechansm:',mechanism)\n",
    "        self.mechanism = mechanism\n",
    "    \n",
    "    def _apply_threshold(self, array_of_rci):\n",
    "        # Takes list of float, returns list of labels [0,1].\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            labels = self.discriminator.predict(array_of_rci)\n",
    "            if self.flip:\n",
    "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
    "                labels = np.array(list(map(IS_CYTO, labels)))\n",
    "        else:  # 'THE_MEAN' or 'ZERO'\n",
    "            rci_threshold = self.discriminator\n",
    "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
    "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
    "        return labels\n",
    "    \n",
    "    def _prepare_threshold(self, rci_values, create=True):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            if create:  # during training, create a new GMM\n",
    "                gmm = GaussianMixture(n_components=2, verbose=0, \n",
    "                  covariance_type='spherical', n_init=100) # random_state=42) \n",
    "                gmm.fit(rci_values)\n",
    "            else:   # during testing, use existing GMM\n",
    "                gmm=self.discriminator\n",
    "            self.flip = False\n",
    "            # The GMM labels are arbitrary.\n",
    "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
    "                self.flip = True\n",
    "            self.discriminator = gmm   # redundant but consistent\n",
    "        elif self.mechanism == 'THE_MEAN':\n",
    "            self.discriminator = np.mean(rci_values)\n",
    "        elif self.mechanism == 'ZERO':\n",
    "            self.discriminator = RCI_THRESHOLD_VALUE\n",
    "        else: # not expected\n",
    "            self.discriminator = 0\n",
    "    \n",
    "    def _explain_threshold(self):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            gmm=self.discriminator\n",
    "            print('Discriminator is GMM')\n",
    "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
    "            print('Variances',gmm.covariances_)\n",
    "            print('Priors',gmm.weights_)\n",
    "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
    "            print(test_rcis)\n",
    "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
    "        else:\n",
    "            print('Discriminator',self.mechanism,self.discriminator)\n",
    "    \n",
    "    def _show_sizes(self,label,values):\n",
    "        a = np.count_nonzero(values==1)\n",
    "        b = np.count_nonzero(values==0)\n",
    "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
    "        \n",
    "    def save_model(self,filename):\n",
    "        if self.model is not None:\n",
    "            filepath = MODEL_DIR + filename\n",
    "            #self.model.save(filepath)\n",
    "            print('? Saved model to',filepath)\n",
    "        \n",
    "    def load_model(self,filename):\n",
    "        filepath = MODEL_DIR + filename\n",
    "        #self.model = keras.models.load_model(filepath)\n",
    "        print('? Loaded model from',filepath)\n",
    "        \n",
    "    def train_new_model(self,train_ids,train_seq,train_rci,\n",
    "            valid_ids=None,valid_seq=None,valid_rci=None):\n",
    "        print(datetime.now())\n",
    "        X_train,y_rci = self._get_X_y(train_ids,train_seq,train_rci) \n",
    "        self._prepare_threshold(y_rci,True)  \n",
    "        self._explain_threshold()\n",
    "        y_train = self._apply_threshold(y_rci)\n",
    "        self._show_sizes('Train',y_train)\n",
    "        if valid_ids is not None:\n",
    "            X_valid,y_rci = self._get_X_y(valid_ids,valid_seq,valid_rci) \n",
    "            y_valid = self._apply_threshold(y_rci)\n",
    "            self._show_sizes('Valid',y_valid)\n",
    "        y_rci = None\n",
    "\n",
    "        self.model=build_model()\n",
    "        \n",
    "        print(\"FIT\")\n",
    "        print(datetime.now())\n",
    "        self.model.fit(X_train, y_train) # sample weight\n",
    "\n",
    "    def test_without_training(self,test_ids,test_seq,test_rci):\n",
    "        # For final test, do no train.\n",
    "        # Assume set_sequences() set the test set.\n",
    "        print(datetime.now())\n",
    "        X_test,y_rci = self._get_X_y(test_ids,test_seq,test_rci) \n",
    "        y_test = self._apply_threshold(y_rci)\n",
    "        y_rci = None\n",
    "        \n",
    "        print(\"PREDICT\")\n",
    "        print(datetime.now())        \n",
    "        yhat_pairs=self.model.predict_proba(X_test)  # [ prob of 0, prob of 1 ]\n",
    "        yhat_pred=[pair[1] for pair in yhat_pairs]\n",
    "        yhat_classes=self.model.predict(X_test)  # 0 or 1\n",
    "        \n",
    "        print('debug pred',yhat_pred[:3])\n",
    "        print('debug class',yhat_classes[:3])\n",
    "\n",
    "        self._show_sizes('Test',y_test)\n",
    "        self._show_sizes('Predict',yhat_classes)\n",
    "        print('Test sizes',X_test.shape,y_test.shape)\n",
    "        print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
    "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "        print('Score threshold',self.score_threshold)\n",
    "        cm1 = confusion_matrix(y_test,yhat_classes)\n",
    "        print('Confusion matrix\\n',cm1)\n",
    "        cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
    "        print('Normalized matrix\\n',cm2)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
    "        precision = precision_score(y_test, yhat_classes)*100.\n",
    "        recall = recall_score(y_test, yhat_classes)*100.\n",
    "        f1 = f1_score(y_test, yhat_classes)*100.\n",
    "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
    "        auprc = auc(prc_X,prc_Y)*100.\n",
    "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
    "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
    "\n",
    "        correct_pos = 0\n",
    "        correct_neg = 0\n",
    "        wrong_pos = 0\n",
    "        wrong_neg = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if yhat_pred[i]>=0.65:\n",
    "                if y_test[i]==1:\n",
    "                    correct_pos += 1\n",
    "                else:\n",
    "                    wrong_pos += 1\n",
    "            elif yhat_pred[i]<=0.35:\n",
    "                if y_test[i]==0:\n",
    "                    correct_neg += 1\n",
    "                else:\n",
    "                    wrong_neg += 1\n",
    "        print('Extreme scores correct, pos:neg',correct_pos,correct_neg)  \n",
    "        print('Extreme scores incorrect pos:neg',wrong_pos,wrong_neg)  \n",
    "\n",
    "        print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
    "        print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
    "        print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n",
    "\n",
    "        self.cv_accuracy.append(accuracy)\n",
    "        self.cv_precision.append(precision)\n",
    "        self.cv_recall.append(recall)\n",
    "        self.cv_f1.append(f1)\n",
    "        self.cv_mcc.append(mcc)\n",
    "        self.cv_auprc.append(auprc)\n",
    "        self.cv_auroc.append(auroc)\n",
    "\n",
    "    def get_statistics(self):\n",
    "        return \\\n",
    "        self.cv_accuracy,\\\n",
    "        self.cv_precision,\\\n",
    "        self.cv_recall,\\\n",
    "        self.cv_f1,\\\n",
    "        self.cv_mcc,\\\n",
    "        self.cv_auprc,\\\n",
    "        self.cv_auroc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td97uyyj5qDq"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "poe3rwAF4Ir7"
   },
   "outputs": [],
   "source": [
    "class Separator():\n",
    "    def __init__(self):\n",
    "        self.train_ids = []\n",
    "        self.train_seq = []\n",
    "        self.train_rci = dict()\n",
    "        self.val_ids = []\n",
    "        self.val_seq = []\n",
    "        self.val_rci = dict()\n",
    "    def load(self,data_dir,rep,fold):\n",
    "        filename='cv.{}.{}.validation_genes.txt'.format(rep,fold)\n",
    "        filename = data_dir + filename\n",
    "        self.val_genes = set()\n",
    "        print('Opening file',filename)\n",
    "        with open(filename,'r') as fin:\n",
    "            for line in fin:\n",
    "                gene_id = line.strip()\n",
    "                self.val_genes.add(gene_id)\n",
    "    def process(self,allids,allseq,gene_to_rci):\n",
    "        size = len(allids)\n",
    "        for t in range(size):\n",
    "            gene_id,tran_id = allids[t]\n",
    "            oneX            = allseq[t]\n",
    "            oneY            = gene_to_rci[gene_id]\n",
    "            in_middle = gene_to_rci[gene_id] >= MIDDLE_LOW and gene_to_rci[gene_id] <= MIDDLE_HIGH\n",
    "            in_tails = gene_to_rci[gene_id] < MIDDLE_LOW or gene_to_rci[gene_id] > MIDDLE_HIGH\n",
    "            if gene_id in self.val_genes:\n",
    "                if FILTER_TEST and (\\\n",
    "                    (FILTER_TAILS_TEST and in_tails) or \\\n",
    "                    (FILTER_MIDDLE_TEST and in_middle)):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.val_ids.append(allids[t])\n",
    "                    self.val_seq.append(allseq[t])\n",
    "                    self.val_rci[gene_id]=gene_to_rci[gene_id]\n",
    "            else:\n",
    "                if FILTER_TRAIN and (\\\n",
    "                    (FILTER_TAILS_TRAIN and in_tails) or \\\n",
    "                    (FILTER_MIDDLE_TRAIN and in_middle)):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.train_ids.append(allids[t])\n",
    "                    self.train_seq.append(allseq[t])\n",
    "                    self.train_rci[gene_id]=gene_to_rci[gene_id]\n",
    "    def get_ids(self):\n",
    "        return self.train_ids,self.val_ids\n",
    "    def get_seq(self):\n",
    "        return self.train_seq,self.val_seq\n",
    "    def get_rci(self):\n",
    "        return self.train_rci,self.val_rci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "df279405-8d83-4140-e713-8d1f2541a16d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:49:39.223488\n",
      "Load RCI from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.lncRNA_RCI.all_cell_lines.csv\n",
      "Number of RCI values loaded 4372\n",
      "Num RCI: 4372\n",
      "Load sequence from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.canon_lncRNA_transcripts.csv\n",
      "Loaded 4372 sequences.\n",
      "\n",
      "Training # 1 1\n",
      "2023-04-20 14:49:47.670375\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.1.validation_genes.txt\n",
      "2023-04-20 14:49:47.682538\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1810:1687 51.76%\n",
      "Valid 1:0 433:442 49.49%\n",
      "FIT\n",
      "2023-04-20 14:49:47.707402\n",
      "\n",
      "Testing # 1 1\n",
      "2023-04-20 14:49:56.755540\n",
      "2023-04-20 14:49:56.755598\n",
      "PREDICT\n",
      "2023-04-20 14:49:56.764626\n",
      "debug pred [0.55, 0.4, 0.47]\n",
      "debug class [1 0 0]\n",
      "Test 1:0 433:442 49.49%\n",
      "Predict 1:0 524:351 59.89%\n",
      "Test sizes (875, 1025) (875,)\n",
      "Distrib of scores: 0.5239085714285715 mean 0.09434546055073668 std\n",
      "Range of scores: 0.21 to 0.97\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[226 216]\n",
      " [125 308]]\n",
      "Normalized matrix\n",
      " [[0.25828571 0.24685714]\n",
      " [0.14285714 0.352     ]]\n",
      "Extreme scores correct, pos:neg 54 23\n",
      "Extreme scores incorrect pos:neg 22 10\n",
      "Accuracy: 61.03% Precision: 58.78% Recall: 71.13%\n",
      "F1: 64.37% MCC: 0.2271\n",
      "AUPRC: 62.89% AUROC: 64.37%\n",
      " accuracy [61.02857142857143]\n",
      " precision [58.778625954198475]\n",
      " recall [71.13163972286374]\n",
      " F1 [64.36781609195403]\n",
      " MCC [0.22709985896885213]\n",
      " AUPRC [62.88742908184795]\n",
      " AUROC [64.36703834136249]\n",
      "\n",
      "Training # 1 2\n",
      "2023-04-20 14:49:56.871801\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.2.validation_genes.txt\n",
      "2023-04-20 14:49:56.886737\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1789:1708 51.16%\n",
      "Valid 1:0 454:421 51.89%\n",
      "FIT\n",
      "2023-04-20 14:49:56.911204\n",
      "\n",
      "Testing # 1 2\n",
      "2023-04-20 14:50:04.066612\n",
      "2023-04-20 14:50:04.066937\n",
      "PREDICT\n",
      "2023-04-20 14:50:04.072661\n",
      "debug pred [0.62, 0.42, 0.6]\n",
      "debug class [1 0 1]\n",
      "Test 1:0 454:421 51.89%\n",
      "Predict 1:0 479:396 54.74%\n",
      "Test sizes (875, 1025) (875,)\n",
      "Distrib of scores: 0.5089485714285715 mean 0.0935217785833212 std\n",
      "Range of scores: 0.12 to 0.84\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[247 174]\n",
      " [149 305]]\n",
      "Normalized matrix\n",
      " [[0.28228571 0.19885714]\n",
      " [0.17028571 0.34857143]]\n",
      "Extreme scores correct, pos:neg 47 43\n",
      "Extreme scores incorrect pos:neg 5 7\n",
      "Accuracy: 63.09% Precision: 63.67% Recall: 67.18%\n",
      "F1: 65.38% MCC: 0.2595\n",
      "AUPRC: 70.08% AUROC: 67.60%\n",
      " accuracy [63.08571428571429]\n",
      " precision [63.67432150313152]\n",
      " recall [67.18061674008811]\n",
      " F1 [65.38049303322614]\n",
      " MCC [0.2594906656930111]\n",
      " AUPRC [70.07973130756379]\n",
      " AUROC [67.59864806889408]\n",
      "\n",
      "Training # 1 3\n",
      "2023-04-20 14:50:04.173389\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.3.validation_genes.txt\n",
      "2023-04-20 14:50:04.192338\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1810:1688 51.74%\n",
      "Valid 1:0 433:441 49.54%\n",
      "FIT\n",
      "2023-04-20 14:50:04.217561\n",
      "\n",
      "Testing # 1 3\n",
      "2023-04-20 14:50:12.459989\n",
      "2023-04-20 14:50:12.460052\n",
      "PREDICT\n",
      "2023-04-20 14:50:12.467553\n",
      "debug pred [0.5, 0.57, 0.33]\n",
      "debug class [0 1 0]\n",
      "Test 1:0 433:441 49.54%\n",
      "Predict 1:0 478:396 54.69%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5138558352402746 mean 0.09319344460917776 std\n",
      "Range of scores: 0.03 to 0.93\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[249 192]\n",
      " [147 286]]\n",
      "Normalized matrix\n",
      " [[0.28489703 0.21967963]\n",
      " [0.16819222 0.32723112]]\n",
      "Extreme scores correct, pos:neg 45 30\n",
      "Extreme scores incorrect pos:neg 24 5\n",
      "Accuracy: 61.21% Precision: 59.83% Recall: 66.05%\n",
      "F1: 62.79% MCC: 0.2261\n",
      "AUPRC: 61.17% AUROC: 65.01%\n",
      " accuracy [61.212814645308924]\n",
      " precision [59.83263598326359]\n",
      " recall [66.05080831408776]\n",
      " F1 [62.78814489571898]\n",
      " MCC [0.22612191819941302]\n",
      " AUPRC [61.17174365377308]\n",
      " AUROC [65.01023812142255]\n",
      "\n",
      "Training # 1 4\n",
      "2023-04-20 14:50:12.569341\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.4.validation_genes.txt\n",
      "2023-04-20 14:50:12.588456\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1778:1720 50.83%\n",
      "Valid 1:0 465:409 53.20%\n",
      "FIT\n",
      "2023-04-20 14:50:12.615044\n",
      "\n",
      "Testing # 1 4\n",
      "2023-04-20 14:50:20.102476\n",
      "2023-04-20 14:50:20.102548\n",
      "PREDICT\n",
      "2023-04-20 14:50:20.108908\n",
      "debug pred [0.48, 0.55, 0.64]\n",
      "debug class [0 1 1]\n",
      "Test 1:0 465:409 53.20%\n",
      "Predict 1:0 436:438 49.89%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5011441647597255 mean 0.09636800077567999 std\n",
      "Range of scores: 0.15 to 0.94\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[246 163]\n",
      " [192 273]]\n",
      "Normalized matrix\n",
      " [[0.28146453 0.18649886]\n",
      " [0.21967963 0.31235698]]\n",
      "Extreme scores correct, pos:neg 35 45\n",
      "Extreme scores incorrect pos:neg 6 17\n",
      "Accuracy: 59.38% Precision: 62.61% Recall: 58.71%\n",
      "F1: 60.60% MCC: 0.1882\n",
      "AUPRC: 66.95% AUROC: 64.00%\n",
      " accuracy [59.382151029748286]\n",
      " precision [62.61467889908256]\n",
      " recall [58.70967741935483]\n",
      " F1 [60.59933407325193]\n",
      " MCC [0.1881767986672964]\n",
      " AUPRC [66.95317495727456]\n",
      " AUROC [63.995846149801515]\n",
      "\n",
      "Training # 1 5\n",
      "2023-04-20 14:50:20.215958\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.5.validation_genes.txt\n",
      "2023-04-20 14:50:20.232334\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1785:1713 51.03%\n",
      "Valid 1:0 458:416 52.40%\n",
      "FIT\n",
      "2023-04-20 14:50:20.259570\n",
      "\n",
      "Testing # 1 5\n",
      "2023-04-20 14:50:28.489364\n",
      "2023-04-20 14:50:28.489425\n",
      "PREDICT\n",
      "2023-04-20 14:50:28.496472\n",
      "debug pred [0.2, 0.57, 0.46]\n",
      "debug class [0 1 0]\n",
      "Test 1:0 458:416 52.40%\n",
      "Predict 1:0 440:434 50.34%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5051830663615561 mean 0.09012590169972123 std\n",
      "Range of scores: 0.16 to 0.85\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[248 168]\n",
      " [186 272]]\n",
      "Normalized matrix\n",
      " [[0.28375286 0.19221968]\n",
      " [0.21281465 0.31121281]]\n",
      "Extreme scores correct, pos:neg 33 33\n",
      "Extreme scores incorrect pos:neg 15 5\n",
      "Accuracy: 59.50% Precision: 61.82% Recall: 59.39%\n",
      "F1: 60.58% MCC: 0.1898\n",
      "AUPRC: 63.64% AUROC: 64.39%\n",
      " accuracy [59.49656750572082]\n",
      " precision [61.81818181818181]\n",
      " recall [59.388646288209614]\n",
      " F1 [60.57906458797328]\n",
      " MCC [0.18982522761209547]\n",
      " AUPRC [63.64133079169084]\n",
      " AUROC [64.38528720188108]\n",
      "\n",
      "Training # 2 1\n",
      "2023-04-20 14:50:28.603103\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.1.validation_genes.txt\n",
      "2023-04-20 14:50:28.625555\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1807:1690 51.67%\n",
      "Valid 1:0 436:439 49.83%\n",
      "FIT\n",
      "2023-04-20 14:50:28.650501\n",
      "\n",
      "Testing # 2 1\n",
      "2023-04-20 14:50:36.077239\n",
      "2023-04-20 14:50:36.077733\n",
      "PREDICT\n",
      "2023-04-20 14:50:36.086150\n",
      "debug pred [0.61, 0.49, 0.41]\n",
      "debug class [1 0 0]\n",
      "Test 1:0 436:439 49.83%\n",
      "Predict 1:0 487:388 55.66%\n",
      "Test sizes (875, 1025) (875,)\n",
      "Distrib of scores: 0.5163885714285714 mean 0.08997896824553286 std\n",
      "Range of scores: 0.22 to 0.79\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[236 203]\n",
      " [152 284]]\n",
      "Normalized matrix\n",
      " [[0.26971429 0.232     ]\n",
      " [0.17371429 0.32457143]]\n",
      "Extreme scores correct, pos:neg 48 25\n",
      "Extreme scores incorrect pos:neg 22 7\n",
      "Accuracy: 59.43% Precision: 58.32% Recall: 65.14%\n",
      "F1: 61.54% MCC: 0.1902\n",
      "AUPRC: 60.52% AUROC: 62.71%\n",
      " accuracy [59.42857142857143]\n",
      " precision [58.31622176591375]\n",
      " recall [65.13761467889908]\n",
      " F1 [61.53846153846154]\n",
      " MCC [0.1901816652766679]\n",
      " AUPRC [60.52489263435793]\n",
      " AUROC [62.71211677916867]\n",
      "\n",
      "Training # 2 2\n",
      "2023-04-20 14:50:36.207102\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.2.validation_genes.txt\n",
      "2023-04-20 14:50:36.240231\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1794:1703 51.30%\n",
      "Valid 1:0 449:426 51.31%\n",
      "FIT\n",
      "2023-04-20 14:50:36.290170\n",
      "\n",
      "Testing # 2 2\n",
      "2023-04-20 14:50:44.469147\n",
      "2023-04-20 14:50:44.469211\n",
      "PREDICT\n",
      "2023-04-20 14:50:44.475173\n",
      "debug pred [0.52, 0.37, 0.39]\n",
      "debug class [1 0 0]\n",
      "Test 1:0 449:426 51.31%\n",
      "Predict 1:0 470:405 53.71%\n",
      "Test sizes (875, 1025) (875,)\n",
      "Distrib of scores: 0.5130057142857144 mean 0.09611299880232388 std\n",
      "Range of scores: 0.14 to 0.9\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[251 175]\n",
      " [154 295]]\n",
      "Normalized matrix\n",
      " [[0.28685714 0.2       ]\n",
      " [0.176      0.33714286]]\n",
      "Extreme scores correct, pos:neg 43 35\n",
      "Extreme scores incorrect pos:neg 16 7\n",
      "Accuracy: 62.40% Precision: 62.77% Recall: 65.70%\n",
      "F1: 64.20% MCC: 0.2468\n",
      "AUPRC: 65.15% AUROC: 66.10%\n",
      " accuracy [62.4]\n",
      " precision [62.76595744680851]\n",
      " recall [65.70155902004454]\n",
      " F1 [64.20021762785638]\n",
      " MCC [0.24681434105067118]\n",
      " AUPRC [65.1498607857626]\n",
      " AUROC [66.10412288131162]\n",
      "\n",
      "Training # 2 3\n",
      "2023-04-20 14:50:44.581120\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.3.validation_genes.txt\n",
      "2023-04-20 14:50:44.599869\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1771:1727 50.63%\n",
      "Valid 1:0 472:402 54.00%\n",
      "FIT\n",
      "2023-04-20 14:50:44.628916\n",
      "\n",
      "Testing # 2 3\n",
      "2023-04-20 14:50:52.605672\n",
      "2023-04-20 14:50:52.606111\n",
      "PREDICT\n",
      "2023-04-20 14:50:52.614644\n",
      "debug pred [0.56, 0.59, 0.63]\n",
      "debug class [1 1 1]\n",
      "Test 1:0 472:402 54.00%\n",
      "Predict 1:0 443:431 50.69%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5075057208237986 mean 0.09599152846510065 std\n",
      "Range of scores: 0.16 to 0.92\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[235 167]\n",
      " [196 276]]\n",
      "Normalized matrix\n",
      " [[0.26887872 0.19107551]\n",
      " [0.22425629 0.31578947]]\n",
      "Extreme scores correct, pos:neg 49 30\n",
      "Extreme scores incorrect pos:neg 16 11\n",
      "Accuracy: 58.47% Precision: 62.30% Recall: 58.47%\n",
      "F1: 60.33% MCC: 0.1688\n",
      "AUPRC: 64.56% AUROC: 62.20%\n",
      " accuracy [58.46681922196796]\n",
      " precision [62.30248306997742]\n",
      " recall [58.47457627118644]\n",
      " F1 [60.32786885245902]\n",
      " MCC [0.16879484031776698]\n",
      " AUPRC [64.56163136966906]\n",
      " AUROC [62.20302091238722]\n",
      "\n",
      "Training # 2 4\n",
      "2023-04-20 14:50:52.749016\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.4.validation_genes.txt\n",
      "2023-04-20 14:50:52.773539\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1816:1682 51.92%\n",
      "Valid 1:0 427:447 48.86%\n",
      "FIT\n",
      "2023-04-20 14:50:52.825739\n",
      "\n",
      "Testing # 2 4\n",
      "2023-04-20 14:51:00.272182\n",
      "2023-04-20 14:51:00.272247\n",
      "PREDICT\n",
      "2023-04-20 14:51:00.278976\n",
      "debug pred [0.43, 0.55, 0.61]\n",
      "debug class [0 1 1]\n",
      "Test 1:0 427:447 48.86%\n",
      "Predict 1:0 470:404 53.78%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.512883295194508 mean 0.10058145654435185 std\n",
      "Range of scores: 0.17 to 0.93\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[242 205]\n",
      " [162 265]]\n",
      "Normalized matrix\n",
      " [[0.27688787 0.23455378]\n",
      " [0.18535469 0.30320366]]\n",
      "Extreme scores correct, pos:neg 46 35\n",
      "Extreme scores incorrect pos:neg 24 12\n",
      "Accuracy: 58.01% Precision: 56.38% Recall: 62.06%\n",
      "F1: 59.09% MCC: 0.1624\n",
      "AUPRC: 59.49% AUROC: 62.18%\n",
      " accuracy [58.0091533180778]\n",
      " precision [56.38297872340425]\n",
      " recall [62.06088992974239]\n",
      " F1 [59.08584169453734]\n",
      " MCC [0.16241725814217708]\n",
      " AUPRC [59.49165142013039]\n",
      " AUROC [62.183749063493806]\n",
      "\n",
      "Training # 2 5\n",
      "2023-04-20 14:51:00.384606\n",
      "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.5.validation_genes.txt\n",
      "2023-04-20 14:51:00.405014\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 1784:1714 51.00%\n",
      "Valid 1:0 459:415 52.52%\n",
      "FIT\n",
      "2023-04-20 14:51:00.430149\n",
      "\n",
      "Testing # 2 5\n",
      "2023-04-20 14:51:08.733341\n",
      "2023-04-20 14:51:08.733398\n",
      "PREDICT\n",
      "2023-04-20 14:51:08.739765\n",
      "debug pred [0.44, 0.6, 0.66]\n",
      "debug class [0 1 1]\n",
      "Test 1:0 459:415 52.52%\n",
      "Predict 1:0 443:431 50.69%\n",
      "Test sizes (874, 1025) (874,)\n",
      "Distrib of scores: 0.5111556064073226 mean 0.09227317936995338 std\n",
      "Range of scores: 0.09 to 0.97\n",
      "Score threshold 0.5\n",
      "Confusion matrix\n",
      " [[252 163]\n",
      " [179 280]]\n",
      "Normalized matrix\n",
      " [[0.28832952 0.18649886]\n",
      " [0.20480549 0.32036613]]\n",
      "Extreme scores correct, pos:neg 42 27\n",
      "Extreme scores incorrect pos:neg 14 9\n",
      "Accuracy: 60.87% Precision: 63.21% Recall: 61.00%\n",
      "F1: 62.08% MCC: 0.2170\n",
      "AUPRC: 65.71% AUROC: 65.11%\n",
      " accuracy [60.86956521739131]\n",
      " precision [63.20541760722348]\n",
      " recall [61.00217864923747]\n",
      " F1 [62.08425720620843]\n",
      " MCC [0.21699567690069183]\n",
      " AUPRC [65.70694535834434]\n",
      " AUROC [65.1148384387222]\n",
      "2023-04-20 14:51:08.839667\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "mcc=[]\n",
    "auprc=[]\n",
    "auroc=[]\n",
    "\n",
    "loader = DataLoader()\n",
    "filepath = DATA_DIR+RCI_FILE_TRAIN\n",
    "print(\"Load RCI from\",filepath)\n",
    "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "filepath = DATA_DIR+SEQ_FILE_TRAIN\n",
    "print('Load sequence from',filepath)\n",
    "allids,allseq = loader.load_spectra(filepath)  # for MLP (load_sequence() for CNN)\n",
    "print('Loaded',len(allseq),'sequences.')\n",
    "test_gene_to_rci = None\n",
    "test_allids = None\n",
    "test_allseq = None\n",
    "if SEQ_FILE_TEST is not None:\n",
    "    # Train on the entire train set (no cross-validation).\n",
    "    # Evaluate with the test files.\n",
    "    test_loader = DataLoader()\n",
    "    filepath = DATA_DIR+RCI_FILE_TEST\n",
    "    print(\"Load RCI from\",filepath)\n",
    "    test_gene_to_rci = test_loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "    print('Num RCI:', len(test_gene_to_rci.keys()))\n",
    "    filepath = DATA_DIR+SEQ_FILE_TEST\n",
    "    print('Load sequence from',filepath)\n",
    "    test_allids,test_allseq = test_loader.load_spectra(filepath)\n",
    "    print('Loaded',len(test_allseq),'sequences.')\n",
    "\n",
    "for repeat in range(REPEATS):\n",
    "    for fold in range(FOLDS):\n",
    "        show_r = repeat+1  # display one-based counting\n",
    "        show_f = fold+1    # display one-based counting\n",
    "\n",
    "        print()\n",
    "        print(\"Training #\",show_r,show_f)\n",
    "        print(datetime.now())\n",
    "        cvdo = CrossValidator(EPOCHS)\n",
    "        cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
    "        if SEQ_FILE_TEST is None:\n",
    "            # Train on 80% and evaluate on 20%.\n",
    "            separator = Separator()\n",
    "            separator.load(DATA_DIR,show_r,show_f)\n",
    "            separator.process(allids,allseq,gene_to_rci)\n",
    "            train_allids,test_allids = separator.get_ids()\n",
    "            train_allseq,test_allseq = separator.get_seq()\n",
    "            train_gene_to_rci,test_gene_to_rci = separator.get_rci()\n",
    "            cvdo.train_new_model(\n",
    "                train_allids,train_allseq,train_gene_to_rci,\n",
    "                test_allids,test_allseq,test_gene_to_rci)\n",
    "            if SAVE_MODEL_FILENAME is not None:\n",
    "                filename = f\"{SAVE_MODEL_FILENAME}.{show_r}.{show_f}.model\"\n",
    "                cvdo.save_model(filename)\n",
    "        else:\n",
    "            # Train on the entire train set (no cross-validation).\n",
    "            # Evaluate with the test files.\n",
    "            train_allids = allids\n",
    "            train_allseq = allseq\n",
    "            train_gene_to_rci = gene_to_rci\n",
    "            BREAK = True\n",
    "            cvdo.train_new_model(\n",
    "                train_allids,train_allseq,train_gene_to_rci,\n",
    "                None,None,None)\n",
    "\n",
    "        print()\n",
    "        print(\"Testing #\",show_r,show_f)\n",
    "        print(datetime.now())\n",
    "        cvdo.reset_statistics()\n",
    "        cvdo.test_without_training(\n",
    "            test_allids,test_allseq,test_gene_to_rci)\n",
    "        cv_accuracy,cv_precision,cv_recall,cv_f1,cv_mcc,cv_auprc,cv_auroc=\\\n",
    "            cvdo.get_statistics()\n",
    "\n",
    "        print(\" accuracy\" ,  cv_accuracy)\n",
    "        print(\" precision\" , cv_precision)\n",
    "        print(\" recall\" ,    cv_recall)\n",
    "        print(\" F1\" ,        cv_f1)\n",
    "        print(\" MCC\" ,       cv_mcc)\n",
    "        print(\" AUPRC\" ,     cv_auprc)\n",
    "        print(\" AUROC\" ,     cv_auroc)\n",
    "\n",
    "        accuracy.append(cv_accuracy)\n",
    "        precision.append(cv_precision)\n",
    "        recall.append(cv_recall)\n",
    "        f1.append(cv_f1)\n",
    "        mcc.append(cv_mcc)\n",
    "        auprc.append(cv_auprc)\n",
    "        auroc.append(cv_auroc)\n",
    "        if BREAK: break\n",
    "    if BREAK: break\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkCeDg_HdQ36",
    "outputId": "f202abdf-5745-442c-cd3e-ece649fdd18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy mean 60.34% std 1.66\n",
      " precision mean 60.97% std 2.47\n",
      " recall mean 63.48% std 4.21\n",
      " F1 mean 62.10% std 2.05\n",
      " MCC mean 0.2076 std 0.0326\n",
      " AUPRC mean 64.02% std 3.20\n",
      " AUROC mean 64.37% std 1.72\n",
      " accuracy [[61.02857142857143], [63.08571428571429], [61.212814645308924], [59.382151029748286], [59.49656750572082], [59.42857142857143], [62.4], [58.46681922196796], [58.0091533180778], [60.86956521739131]]\n",
      " precision [[58.778625954198475], [63.67432150313152], [59.83263598326359], [62.61467889908256], [61.81818181818181], [58.31622176591375], [62.76595744680851], [62.30248306997742], [56.38297872340425], [63.20541760722348]]\n",
      " recall [[71.13163972286374], [67.18061674008811], [66.05080831408776], [58.70967741935483], [59.388646288209614], [65.13761467889908], [65.70155902004454], [58.47457627118644], [62.06088992974239], [61.00217864923747]]\n",
      " F1 [[64.36781609195403], [65.38049303322614], [62.78814489571898], [60.59933407325193], [60.57906458797328], [61.53846153846154], [64.20021762785638], [60.32786885245902], [59.08584169453734], [62.08425720620843]]\n",
      " MCC [[0.22709985896885213], [0.2594906656930111], [0.22612191819941302], [0.1881767986672964], [0.18982522761209547], [0.1901816652766679], [0.24681434105067118], [0.16879484031776698], [0.16241725814217708], [0.21699567690069183]]\n",
      " AUPRC [[62.88742908184795], [70.07973130756379], [61.17174365377308], [66.95317495727456], [63.64133079169084], [60.52489263435793], [65.1498607857626], [64.56163136966906], [59.49165142013039], [65.70694535834434]]\n",
      " AUROC [[64.36703834136249], [67.59864806889408], [65.01023812142255], [63.995846149801515], [64.38528720188108], [62.71211677916867], [66.10412288131162], [62.20302091238722], [62.183749063493806], [65.1148384387222]]\n"
     ]
    }
   ],
   "source": [
    "def STD (values):\n",
    "    # ddof=1 reduces bias when extrapolating from sample to population\n",
    "    return np.std(values,ddof=1)\n",
    "\n",
    "print(\" accuracy mean %.2f%% std %.2f\" %  (np.mean(accuracy),  STD(accuracy)))\n",
    "print(\" precision mean %.2f%% std %.2f\" % (np.mean(precision), STD(precision)))\n",
    "print(\" recall mean %.2f%% std %.2f\" %    (np.mean(recall),    STD(recall)))\n",
    "print(\" F1 mean %.2f%% std %.2f\" %        (np.mean(f1),        STD(f1)))\n",
    "print(\" MCC mean %.4f std %.4f\" %       (np.mean(mcc),       STD(mcc)))\n",
    "print(\" AUPRC mean %.2f%% std %.2f\" %     (np.mean(auprc),     STD(auprc)))\n",
    "print(\" AUROC mean %.2f%% std %.2f\" %     (np.mean(auroc),     STD(auroc)))\n",
    "\n",
    "print(\" accuracy\"  , accuracy)\n",
    "print(\" precision\" , precision)\n",
    "print(\" recall\"    , recall)\n",
    "print(\" F1\"        , f1)\n",
    "print(\" MCC\"       , mcc)\n",
    "print(\" AUPRC\"     , auprc)\n",
    "print(\" AUROC\"     , auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "QjSVa72v4IsA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
