{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Support Vector Machine\n",
        "canonical lncRNA, -1 threshold, cross-valiation, middle-exclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "476075d8-d5e1-46a5-b5c2-533d1b06275a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-20 16:31:11.924122\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "96bc9e95-7755-49d0-f700-060d320ad205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/Localization/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATA_DIR=\"/\"\n",
        "    MODEL_DIR=\"/\"\n",
        "print(DATA_DIR)\n",
        "SAVE_MODEL_FILENAME = None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX-UEr8FLA8",
        "outputId": "2ee8f516-4e44-4695-e8d2-e3ef7e5b39d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.16\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import numpy as np\n",
        "np.random.seed(42) # supposedly sets scikit-learn\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "from matplotlib import pyplot as plt \n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "K=5\n",
        "ALPHABET=4**K + 1\n",
        "EPOCHS=150 \n",
        "RCI_THRESHOLD_MECHANISM = 'ZERO'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
        "RCI_THRESHOLD_VALUE = -1  # use -1 for lncRNA, use 0 for mRNA\n",
        "BREAK = False   # optionally break after first fold\n",
        "EXCLUSIONS = [1]   # possibly exclude cell line 1 = H1.hESC\n",
        "FILTER_TRAIN        = True\n",
        "FILTER_TAILS_TRAIN  = False\n",
        "FILTER_MIDDLE_TRAIN = True\n",
        "FILTER_TEST         = True\n",
        "FILTER_TAILS_TEST   = False\n",
        "FILTER_MIDDLE_TEST  = True\n",
        "MIDDLE_LOW          = -2   # -2 for lncRNA, -1 for mRNA\n",
        "MIDDLE_HIGH         = 0    #  0 for lncRNA, +1 for mRNA\n",
        "\n",
        "REPEATS = 2\n",
        "FOLDS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "LnkpVKdMFLA-"
      },
      "outputs": [],
      "source": [
        "RCI_FILE_TRAIN = 'train.lncRNA_RCI.all_cell_lines.csv'\n",
        "RCI_FILE_TEST  = None # use None for cross-validation\n",
        "\n",
        "SEQ_FILE_TRAIN = 'train.canon_lncRNA_transcripts.csv'\n",
        "SEQ_FILE_TEST  = None # use None for cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "e3p4QzQJFLA_"
      },
      "outputs": [],
      "source": [
        "def get_ordered_list():\n",
        "    ordered_list = \\\n",
        "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
        "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
        "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
        "    return ordered_list\n",
        "all_cell_lines = get_ordered_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self):\n",
        "        self.cache=dict() \n",
        "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
        "        self.gene2rci = dict()\n",
        "        \n",
        "    def load_gene_rci_values(self,filepath,exclusions):\n",
        "        '''\n",
        "        Load all the genes from the given RCI csv file.\n",
        "        The given file usually contains train or test, not both.\n",
        "        Return dict with keys=gene:str and values=RCI:float.\n",
        "        '''\n",
        "        self.gene2rci = {}\n",
        "        overall_sum = 0\n",
        "        with open (filepath,'r') as handle:\n",
        "            for row in handle:\n",
        "                line = row.strip()\n",
        "                fields = line.split(',')\n",
        "                gene_id = fields.pop(0)\n",
        "                cell_line_index = 0\n",
        "                rci_values = []\n",
        "                log_mean=0.0\n",
        "                for rci_str in fields:\n",
        "                    if cell_line_index not in exclusions:\n",
        "                        if rci_str != \"nan\":\n",
        "                            rci_val = float(rci_str)\n",
        "                            rci_values.append(rci_val)\n",
        "                    cell_line_index += 1\n",
        "                if len(rci_values)>0:\n",
        "                    values = np.array(rci_values)\n",
        "                    antilogs = [2**x for x in values]\n",
        "                    big_mean = np.mean(antilogs)\n",
        "                    # Avoid division by zero\n",
        "                    if np.absolute(big_mean)<0.000001:\n",
        "                        log_mean = -1000000 # neg infinity\n",
        "                    else:\n",
        "                        log_mean = np.log2(big_mean) \n",
        "                    self.gene2rci[gene_id] = log_mean\n",
        "        print('Number of RCI values loaded',len(self.gene2rci.keys()))\n",
        "        return self.gene2rci\n",
        "\n",
        "    def _seq_to_kmer_values(self,rna,K):\n",
        "        vec=[] # seq converted to list of K-mers \n",
        "        N_indicator = 0 # indicator value\n",
        "        length = len(rna)\n",
        "        for i in range(length-K+1):\n",
        "            kmer = rna[i:i+K]\n",
        "            if 'N' in kmer:\n",
        "                value = N_indicator\n",
        "            elif kmer in self.cache.keys():\n",
        "                value = self.cache[kmer]\n",
        "            else:\n",
        "                value = 0\n",
        "                for j in range(K):\n",
        "                    value *= 4   \n",
        "                    nextnuc = kmer[j] \n",
        "                    nucval = self.vals[nextnuc]\n",
        "                    value += nucval\n",
        "                value += 1   # NNN => 0, AAA => 1\n",
        "                self.cache[kmer] = value\n",
        "            vec.append(value)\n",
        "        return vec\n",
        "\n",
        "    def load_sequence(self,filepath):\n",
        "        '''\n",
        "        Load all the sequences from the given file. \n",
        "        Load our version of GenCode -- csv, easier to parse than fasta.\n",
        "        Each line has IDs plus sequence.\n",
        "        The IDs in the file do not include dot-version numbers.\n",
        "        The file may already be filtered e.g. canonical transcripts.\n",
        "        '''\n",
        "        allids=[]\n",
        "        allseq=[]\n",
        "        #NREPEAT = str('N'*MAXLEN)   # not used for MLP\n",
        "        with open (filepath,'r') as handle:\n",
        "            header = None\n",
        "            for row in handle:\n",
        "                if header is None:\n",
        "                    header = row\n",
        "                else:\n",
        "                    line    = row.strip()\n",
        "                    fields  = line.split(',')\n",
        "                    tran_id = fields[0]  # without version number\n",
        "                    gene_id = fields[1]  # without version number\n",
        "                    seq_len = int(fields[3])\n",
        "                    seq_txt = fields[4]\n",
        "                    # Keep only transcripts having numeric RCI given the cell lines in use.\n",
        "                    # We have validated this by spot checking.\n",
        "                    # TO DO: validate this programmatically.\n",
        "                    if gene_id in self.gene2rci.keys():\n",
        "                        allids.append( (gene_id,tran_id) )\n",
        "                        hot_vec = self._seq_to_kmer_values(seq_txt,K)\n",
        "                        allseq.append(hot_vec)\n",
        "        self.cache=dict() # save RAM\n",
        "        return allids,allseq\n",
        "\n",
        "    def load_spectra(self,filepath):\n",
        "        '''\n",
        "        Load all (variable-length) sequences as lists of kmers.\n",
        "        Then convert each sequence to (fixed-length) kmer histograms.\n",
        "        '''\n",
        "        allids,allseq = self.load_sequence(filepath)\n",
        "        allspectra = []\n",
        "        for seq in allseq:\n",
        "            spectrum = np.zeros(ALPHABET)\n",
        "            for kmer in seq:\n",
        "                spectrum[kmer] += 1\n",
        "            spectrum /= len(seq)\n",
        "            allspectra.append(spectrum)\n",
        "        return allids,allspectra        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    '''\n",
        "    Probability is not the default with SVM.\n",
        "    We use probablity to compute the ARPRC statistic.\n",
        "    The sklearn documenation says:\n",
        "    Whether to enable probability estimates. \n",
        "    This must be enabled prior to calling fit, \n",
        "    will slow down that method as it internally uses 5-fold cross-validation, \n",
        "    and predict_proba may be inconsistent with predict.\n",
        "    '''\n",
        "    svc = SVC(probability=True)\n",
        "    return svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-wufgFLBF",
        "outputId": "8880ecdf-0071-4acf-e231-c50f66140434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-20 16:31:13.611385\n",
            "SVC(probability=True)\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "model=build_model()\n",
        "print(model)  # Print this only once\n",
        "model=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrC1alOKq07"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "W9xiFzNbFLBE"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "class CrossValidator():\n",
        "    def __init__(self,epochs,score_threshold=0.5):\n",
        "        self.epochs = epochs\n",
        "        self.score_threshold = score_threshold\n",
        "        self.mechanism = 'ZERO'\n",
        "        self.discriminator = RCI_THRESHOLD_VALUE\n",
        "        self.flip = False\n",
        "        self.reset_statistics()\n",
        "        \n",
        "    def reset_statistics(self):\n",
        "        self.cv_accuracy=[]\n",
        "        self.cv_precision=[]\n",
        "        self.cv_recall=[]\n",
        "        self.cv_f1=[]\n",
        "        self.cv_auprc=[]\n",
        "        self.cv_auroc=[]\n",
        "        self.cv_mcc=[]\n",
        "        \n",
        "    def _get_X_y(self, all_ids, all_seqs, rci_map): \n",
        "        # Prepare X and y for training or testing.\n",
        "        subsetX=[]\n",
        "        subsetY=[]\n",
        "        for t in range(len(all_ids)):\n",
        "            gene_id,tran_id = all_ids[t]\n",
        "            oneX            = all_seqs[t]\n",
        "            oneY            = rci_map[gene_id]\n",
        "            subsetX.append(oneX)\n",
        "            subsetY.append(oneY)\n",
        "        subsetX = np.array(subsetX)\n",
        "        subsetY = np.array(subsetY).reshape((-1,1))\n",
        "        return subsetX,subsetY\n",
        "    \n",
        "    def set_threshold_mechanism(self, mechanism):\n",
        "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
        "            raise Exception('Unrecognized mechansm:',mechanism)\n",
        "        self.mechanism = mechanism\n",
        "    \n",
        "    def _apply_threshold(self, array_of_rci):\n",
        "        # Takes list of float, returns list of labels [0,1].\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            labels = self.discriminator.predict(array_of_rci)\n",
        "            if self.flip:\n",
        "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
        "                labels = np.array(list(map(IS_CYTO, labels)))\n",
        "        else:  # 'THE_MEAN' or 'ZERO'\n",
        "            rci_threshold = self.discriminator\n",
        "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
        "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
        "        return labels\n",
        "    \n",
        "    def _prepare_threshold(self, rci_values, create=True):\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            if create:  # during training, create a new GMM\n",
        "                gmm = GaussianMixture(n_components=2, verbose=0, \n",
        "                  covariance_type='spherical', n_init=100) # random_state=42) \n",
        "                gmm.fit(rci_values)\n",
        "            else:   # during testing, use existing GMM\n",
        "                gmm=self.discriminator\n",
        "            self.flip = False\n",
        "            # The GMM labels are arbitrary.\n",
        "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
        "                self.flip = True\n",
        "            self.discriminator = gmm   # redundant but consistent\n",
        "        elif self.mechanism == 'THE_MEAN':\n",
        "            self.discriminator = np.mean(rci_values)\n",
        "        elif self.mechanism == 'ZERO':\n",
        "            self.discriminator = RCI_THRESHOLD_VALUE\n",
        "        else: # not expected\n",
        "            self.discriminator = 0\n",
        "    \n",
        "    def _explain_threshold(self):\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            gmm=self.discriminator\n",
        "            print('Discriminator is GMM')\n",
        "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
        "            print('Variances',gmm.covariances_)\n",
        "            print('Priors',gmm.weights_)\n",
        "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
        "            print(test_rcis)\n",
        "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
        "        else:\n",
        "            print('Discriminator',self.mechanism,self.discriminator)\n",
        "    \n",
        "    def _show_sizes(self,label,values):\n",
        "        a = np.count_nonzero(values==1)\n",
        "        b = np.count_nonzero(values==0)\n",
        "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
        "        \n",
        "    def save_model(self,filename):\n",
        "        if self.model is not None:\n",
        "            filepath = MODEL_DIR + filename\n",
        "            #self.model.save(filepath)\n",
        "            print('? Saved model to',filepath)\n",
        "        \n",
        "    def load_model(self,filename):\n",
        "        filepath = MODEL_DIR + filename\n",
        "        #self.model = keras.models.load_model(filepath)\n",
        "        print('? Loaded model from',filepath)\n",
        "        \n",
        "    def train_new_model(self,train_ids,train_seq,train_rci,\n",
        "            valid_ids=None,valid_seq=None,valid_rci=None):\n",
        "        print(datetime.now())\n",
        "        X_train,y_rci = self._get_X_y(train_ids,train_seq,train_rci) \n",
        "        self._prepare_threshold(y_rci,True)  \n",
        "        self._explain_threshold()\n",
        "        y_train = self._apply_threshold(y_rci)\n",
        "        self._show_sizes('Train',y_train)\n",
        "        if valid_ids is not None:\n",
        "            X_valid,y_rci = self._get_X_y(valid_ids,valid_seq,valid_rci) \n",
        "            y_valid = self._apply_threshold(y_rci)\n",
        "            self._show_sizes('Valid',y_valid)\n",
        "        y_rci = None\n",
        "\n",
        "        self.model=build_model()\n",
        "        \n",
        "        print(\"FIT\")\n",
        "        print(datetime.now())\n",
        "        self.model.fit(X_train, y_train) # sample weight\n",
        "\n",
        "    def test_without_training(self,test_ids,test_seq,test_rci):\n",
        "        # For final test, do no train.\n",
        "        # Assume set_sequences() set the test set.\n",
        "        print(datetime.now())\n",
        "        X_test,y_rci = self._get_X_y(test_ids,test_seq,test_rci) \n",
        "        y_test = self._apply_threshold(y_rci)\n",
        "        y_rci = None\n",
        "        \n",
        "        print(\"PREDICT\")\n",
        "        print(datetime.now())        \n",
        "        yhat_pairs=self.model.predict_proba(X_test)  # [ prob of 0, prob of 1 ]\n",
        "        yhat_pred=[pair[1] for pair in yhat_pairs]\n",
        "        yhat_classes=self.model.predict(X_test)  # 0 or 1\n",
        "        \n",
        "        print('debug pred',yhat_pred[:3])\n",
        "        print('debug class',yhat_classes[:3])\n",
        "\n",
        "        self._show_sizes('Test',y_test)\n",
        "        self._show_sizes('Predict',yhat_classes)\n",
        "        print('Test sizes',X_test.shape,y_test.shape)\n",
        "        print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
        "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "        print('Score threshold',self.score_threshold)\n",
        "        cm1 = confusion_matrix(y_test,yhat_classes)\n",
        "        print('Confusion matrix\\n',cm1)\n",
        "        cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
        "        print('Normalized matrix\\n',cm2)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
        "        precision = precision_score(y_test, yhat_classes)*100.\n",
        "        recall = recall_score(y_test, yhat_classes)*100.\n",
        "        f1 = f1_score(y_test, yhat_classes)*100.\n",
        "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
        "        auprc = auc(prc_X,prc_Y)*100.\n",
        "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
        "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
        "\n",
        "        correct_pos = 0\n",
        "        correct_neg = 0\n",
        "        wrong_pos = 0\n",
        "        wrong_neg = 0\n",
        "        for i in range(len(y_test)):\n",
        "            if yhat_pred[i]>=0.65:\n",
        "                if y_test[i]==1:\n",
        "                    correct_pos += 1\n",
        "                else:\n",
        "                    wrong_pos += 1\n",
        "            elif yhat_pred[i]<=0.35:\n",
        "                if y_test[i]==0:\n",
        "                    correct_neg += 1\n",
        "                else:\n",
        "                    wrong_neg += 1\n",
        "        print('Extreme scores correct, pos:neg',correct_pos,correct_neg)  \n",
        "        print('Extreme scores incorrect pos:neg',wrong_pos,wrong_neg)  \n",
        "\n",
        "        print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
        "        print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
        "        print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n",
        "\n",
        "        self.cv_accuracy.append(accuracy)\n",
        "        self.cv_precision.append(precision)\n",
        "        self.cv_recall.append(recall)\n",
        "        self.cv_f1.append(f1)\n",
        "        self.cv_mcc.append(mcc)\n",
        "        self.cv_auprc.append(auprc)\n",
        "        self.cv_auroc.append(auroc)\n",
        "\n",
        "    def get_statistics(self):\n",
        "        return \\\n",
        "        self.cv_accuracy,\\\n",
        "        self.cv_precision,\\\n",
        "        self.cv_recall,\\\n",
        "        self.cv_f1,\\\n",
        "        self.cv_mcc,\\\n",
        "        self.cv_auprc,\\\n",
        "        self.cv_auroc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td97uyyj5qDq"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "poe3rwAF4Ir7"
      },
      "outputs": [],
      "source": [
        "class Separator():\n",
        "    def __init__(self):\n",
        "        self.train_ids = []\n",
        "        self.train_seq = []\n",
        "        self.train_rci = dict()\n",
        "        self.val_ids = []\n",
        "        self.val_seq = []\n",
        "        self.val_rci = dict()\n",
        "    def load(self,data_dir,rep,fold):\n",
        "        filename='cv.{}.{}.validation_genes.txt'.format(rep,fold)\n",
        "        filename = data_dir + filename\n",
        "        self.val_genes = set()\n",
        "        print('Opening file',filename)\n",
        "        with open(filename,'r') as fin:\n",
        "            for line in fin:\n",
        "                gene_id = line.strip()\n",
        "                self.val_genes.add(gene_id)\n",
        "    def process(self,allids,allseq,gene_to_rci):\n",
        "        size = len(allids)\n",
        "        for t in range(size):\n",
        "            gene_id,tran_id = allids[t]\n",
        "            oneX            = allseq[t]\n",
        "            oneY            = gene_to_rci[gene_id]\n",
        "            in_middle = gene_to_rci[gene_id] >= MIDDLE_LOW and gene_to_rci[gene_id] <= MIDDLE_HIGH\n",
        "            in_tails = gene_to_rci[gene_id] < MIDDLE_LOW or gene_to_rci[gene_id] > MIDDLE_HIGH\n",
        "            if gene_id in self.val_genes:\n",
        "                if FILTER_TEST and (\\\n",
        "                    (FILTER_TAILS_TEST and in_tails) or \\\n",
        "                    (FILTER_MIDDLE_TEST and in_middle)):\n",
        "                    pass\n",
        "                else:\n",
        "                    self.val_ids.append(allids[t])\n",
        "                    self.val_seq.append(allseq[t])\n",
        "                    self.val_rci[gene_id]=gene_to_rci[gene_id]\n",
        "            else:\n",
        "                if FILTER_TRAIN and (\\\n",
        "                    (FILTER_TAILS_TRAIN and in_tails) or \\\n",
        "                    (FILTER_MIDDLE_TRAIN and in_middle)):\n",
        "                    pass\n",
        "                else:\n",
        "                    self.train_ids.append(allids[t])\n",
        "                    self.train_seq.append(allseq[t])\n",
        "                    self.train_rci[gene_id]=gene_to_rci[gene_id]\n",
        "    def get_ids(self):\n",
        "        return self.train_ids,self.val_ids\n",
        "    def get_seq(self):\n",
        "        return self.train_seq,self.val_seq\n",
        "    def get_rci(self):\n",
        "        return self.train_rci,self.val_rci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC9m0W-pFLBH",
        "outputId": "4fc7af5d-8776-46bb-ee42-2194377a5022",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-20 16:31:13.693541\n",
            "Load RCI from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.lncRNA_RCI.all_cell_lines.csv\n",
            "Number of RCI values loaded 4372\n",
            "Num RCI: 4372\n",
            "Load sequence from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.canon_lncRNA_transcripts.csv\n",
            "Loaded 4372 sequences.\n",
            "\n",
            "Training # 1 1\n",
            "2023-04-20 16:31:21.621497\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.1.validation_genes.txt\n",
            "2023-04-20 16:31:21.643013\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1062:1013 51.18%\n",
            "Valid 1:0 259:273 48.68%\n",
            "FIT\n",
            "2023-04-20 16:31:21.667889\n",
            "\n",
            "Testing # 1 1\n",
            "2023-04-20 16:31:34.024066\n",
            "2023-04-20 16:31:34.024124\n",
            "PREDICT\n",
            "2023-04-20 16:31:34.030109\n",
            "debug pred [0.34112447076421504, 0.23735360703904676, 0.3575985498198057]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 259:273 48.68%\n",
            "Predict 1:0 279:253 52.44%\n",
            "Test sizes (532, 1025) (532,)\n",
            "Distrib of scores: 0.5103115572448258 mean 0.19907633034705735 std\n",
            "Range of scores: 0.07749977240222886 to 0.9585501493631539\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[173 100]\n",
            " [ 80 179]]\n",
            "Normalized matrix\n",
            " [[0.32518797 0.18796992]\n",
            " [0.15037594 0.33646617]]\n",
            "Extreme scores correct, pos:neg 102 94\n",
            "Extreme scores incorrect pos:neg 40 32\n",
            "Accuracy: 66.17% Precision: 64.16% Recall: 69.11%\n",
            "F1: 66.54% MCC: 0.3251\n",
            "AUPRC: 67.11% AUROC: 71.55%\n",
            " accuracy [66.16541353383458]\n",
            " precision [64.15770609318996]\n",
            " recall [69.1119691119691]\n",
            " F1 [66.54275092936803]\n",
            " MCC [0.3250953088317443]\n",
            " AUPRC [67.10621964539894]\n",
            " AUROC [71.55302869588584]\n",
            "\n",
            "Training # 1 2\n",
            "2023-04-20 16:31:36.827491\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.2.validation_genes.txt\n",
            "2023-04-20 16:31:36.850467\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1048:1016 50.78%\n",
            "Valid 1:0 273:270 50.28%\n",
            "FIT\n",
            "2023-04-20 16:31:36.874109\n",
            "\n",
            "Testing # 1 2\n",
            "2023-04-20 16:31:48.672706\n",
            "2023-04-20 16:31:48.673041\n",
            "PREDICT\n",
            "2023-04-20 16:31:48.678166\n",
            "debug pred [0.3850256945107589, 0.7372341957176943, 0.16571658150634833]\n",
            "debug class [0 1 0]\n",
            "Test 1:0 273:270 50.28%\n",
            "Predict 1:0 283:260 52.12%\n",
            "Test sizes (543, 1025) (543,)\n",
            "Distrib of scores: 0.5130224059588695 mean 0.19280227957181428 std\n",
            "Range of scores: 0.05705652118939031 to 0.9291918952599316\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[181  89]\n",
            " [ 79 194]]\n",
            "Normalized matrix\n",
            " [[0.33333333 0.16390424]\n",
            " [0.14548803 0.3572744 ]]\n",
            "Extreme scores correct, pos:neg 105 88\n",
            "Extreme scores incorrect pos:neg 44 25\n",
            "Accuracy: 69.06% Precision: 68.55% Recall: 71.06%\n",
            "F1: 69.78% MCC: 0.3813\n",
            "AUPRC: 70.05% AUROC: 71.99%\n",
            " accuracy [69.06077348066299]\n",
            " precision [68.55123674911661]\n",
            " recall [71.06227106227107]\n",
            " F1 [69.78417266187049]\n",
            " MCC [0.38132949879018896]\n",
            " AUPRC [70.04772149581157]\n",
            " AUROC [71.99362366029033]\n",
            "\n",
            "Training # 1 3\n",
            "2023-04-20 16:31:51.570599\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.3.validation_genes.txt\n",
            "2023-04-20 16:31:51.598921\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1070:1030 50.95%\n",
            "Valid 1:0 251:256 49.51%\n",
            "FIT\n",
            "2023-04-20 16:31:51.625903\n",
            "\n",
            "Testing # 1 3\n",
            "2023-04-20 16:32:04.524125\n",
            "2023-04-20 16:32:04.524518\n",
            "PREDICT\n",
            "2023-04-20 16:32:04.529882\n",
            "debug pred [0.5381399695197553, 0.2710971694753819, 0.5504035019643847]\n",
            "debug class [1 0 1]\n",
            "Test 1:0 251:256 49.51%\n",
            "Predict 1:0 281:226 55.42%\n",
            "Test sizes (507, 1025) (507,)\n",
            "Distrib of scores: 0.5165742384196741 mean 0.18781404272705501 std\n",
            "Range of scores: 0.0602083924392811 to 0.9397871620797842\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[162  94]\n",
            " [ 64 187]]\n",
            "Normalized matrix\n",
            " [[0.31952663 0.18540434]\n",
            " [0.12623274 0.36883629]]\n",
            "Extreme scores correct, pos:neg 92 80\n",
            "Extreme scores incorrect pos:neg 37 20\n",
            "Accuracy: 68.84% Precision: 66.55% Recall: 74.50%\n",
            "F1: 70.30% MCC: 0.3801\n",
            "AUPRC: 69.52% AUROC: 73.09%\n",
            " accuracy [68.83629191321499]\n",
            " precision [66.54804270462633]\n",
            " recall [74.5019920318725]\n",
            " F1 [70.30075187969925]\n",
            " MCC [0.38005695471987516]\n",
            " AUPRC [69.51873324815686]\n",
            " AUROC [73.08578187250995]\n",
            "\n",
            "Training # 1 4\n",
            "2023-04-20 16:32:07.326524\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.4.validation_genes.txt\n",
            "2023-04-20 16:32:07.339494\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1064:1041 50.55%\n",
            "Valid 1:0 257:245 51.20%\n",
            "FIT\n",
            "2023-04-20 16:32:07.355952\n",
            "\n",
            "Testing # 1 4\n",
            "2023-04-20 16:32:19.919250\n",
            "2023-04-20 16:32:19.919644\n",
            "PREDICT\n",
            "2023-04-20 16:32:19.924908\n",
            "debug pred [0.41693557008288085, 0.36368436417186356, 0.4060638095654222]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 257:245 51.20%\n",
            "Predict 1:0 232:270 46.22%\n",
            "Test sizes (502, 1025) (502,)\n",
            "Distrib of scores: 0.4906213779501059 mean 0.18391712617453 std\n",
            "Range of scores: 0.04163042120722006 to 0.9378965683316621\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[176  69]\n",
            " [ 94 163]]\n",
            "Normalized matrix\n",
            " [[0.35059761 0.1374502 ]\n",
            " [0.187251   0.3247012 ]]\n",
            "Extreme scores correct, pos:neg 80 91\n",
            "Extreme scores incorrect pos:neg 24 25\n",
            "Accuracy: 67.53% Precision: 70.26% Recall: 63.42%\n",
            "F1: 66.67% MCC: 0.3535\n",
            "AUPRC: 71.89% AUROC: 73.25%\n",
            " accuracy [67.52988047808765]\n",
            " precision [70.25862068965517]\n",
            " recall [63.42412451361867]\n",
            " F1 [66.66666666666666]\n",
            " MCC [0.3535221419841441]\n",
            " AUPRC [71.88740643807535]\n",
            " AUROC [73.24863019137618]\n",
            "\n",
            "Training # 1 5\n",
            "2023-04-20 16:32:22.388619\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.5.validation_genes.txt\n",
            "2023-04-20 16:32:22.408343\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1040:1044 49.90%\n",
            "Valid 1:0 281:242 53.73%\n",
            "FIT\n",
            "2023-04-20 16:32:22.424729\n",
            "\n",
            "Testing # 1 5\n",
            "2023-04-20 16:32:35.203520\n",
            "2023-04-20 16:32:35.203938\n",
            "PREDICT\n",
            "2023-04-20 16:32:35.209183\n",
            "debug pred [0.2782812660897595, 0.21067531336598264, 0.3908933915796222]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 281:242 53.73%\n",
            "Predict 1:0 277:246 52.96%\n",
            "Test sizes (523, 1025) (523,)\n",
            "Distrib of scores: 0.505206393089296 mean 0.18090869224330983 std\n",
            "Range of scores: 0.08090048282940672 to 0.9285926548355083\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[157  85]\n",
            " [ 89 192]]\n",
            "Normalized matrix\n",
            " [[0.3001912  0.1625239 ]\n",
            " [0.17017208 0.36711281]]\n",
            "Extreme scores correct, pos:neg 94 86\n",
            "Extreme scores incorrect pos:neg 29 22\n",
            "Accuracy: 66.73% Precision: 69.31% Recall: 68.33%\n",
            "F1: 68.82% MCC: 0.3317\n",
            "AUPRC: 73.74% AUROC: 73.34%\n",
            " accuracy [66.73040152963671]\n",
            " precision [69.31407942238266]\n",
            " recall [68.32740213523132]\n",
            " F1 [68.81720430107526]\n",
            " MCC [0.3316930887599853]\n",
            " AUPRC [73.74149550964168]\n",
            " AUROC [73.34048998558865]\n",
            "\n",
            "Training # 2 1\n",
            "2023-04-20 16:32:37.325600\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.1.validation_genes.txt\n",
            "2023-04-20 16:32:37.345927\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1060:1030 50.72%\n",
            "Valid 1:0 261:256 50.48%\n",
            "FIT\n",
            "2023-04-20 16:32:37.365462\n",
            "\n",
            "Testing # 2 1\n",
            "2023-04-20 16:32:50.147027\n",
            "2023-04-20 16:32:50.147089\n",
            "PREDICT\n",
            "2023-04-20 16:32:50.152468\n",
            "debug pred [0.46673974820736047, 0.25761741707819946, 0.268205255245902]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 261:256 50.48%\n",
            "Predict 1:0 259:258 50.10%\n",
            "Test sizes (517, 1025) (517,)\n",
            "Distrib of scores: 0.4923737652071065 mean 0.19173545887987395 std\n",
            "Range of scores: 0.06035502864130793 to 0.9568123632018225\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[169  87]\n",
            " [ 89 172]]\n",
            "Normalized matrix\n",
            " [[0.32688588 0.16827853]\n",
            " [0.172147   0.33268859]]\n",
            "Extreme scores correct, pos:neg 90 97\n",
            "Extreme scores incorrect pos:neg 32 38\n",
            "Accuracy: 65.96% Precision: 66.41% Recall: 65.90%\n",
            "F1: 66.15% MCC: 0.3191\n",
            "AUPRC: 67.87% AUROC: 70.91%\n",
            " accuracy [65.95744680851064]\n",
            " precision [66.40926640926641]\n",
            " recall [65.90038314176245]\n",
            " F1 [66.15384615384615]\n",
            " MCC [0.31914575227844216]\n",
            " AUPRC [67.86513382402927]\n",
            " AUROC [70.90592073754789]\n",
            "\n",
            "Training # 2 2\n",
            "2023-04-20 16:32:52.278903\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.2.validation_genes.txt\n",
            "2023-04-20 16:32:52.297823\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1043:1028 50.36%\n",
            "Valid 1:0 278:258 51.87%\n",
            "FIT\n",
            "2023-04-20 16:32:52.314215\n",
            "\n",
            "Testing # 2 2\n",
            "2023-04-20 16:33:07.154766\n",
            "2023-04-20 16:33:07.154861\n",
            "PREDICT\n",
            "2023-04-20 16:33:07.160451\n",
            "debug pred [0.14820437048687327, 0.38511873434851296, 0.4431659119538918]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 278:258 51.87%\n",
            "Predict 1:0 290:246 54.10%\n",
            "Test sizes (536, 1025) (536,)\n",
            "Distrib of scores: 0.5187915794048542 mean 0.19403515210928715 std\n",
            "Range of scores: 0.05154931434702982 to 0.9142088298575682\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[174  84]\n",
            " [ 72 206]]\n",
            "Normalized matrix\n",
            " [[0.32462687 0.15671642]\n",
            " [0.13432836 0.38432836]]\n",
            "Extreme scores correct, pos:neg 118 90\n",
            "Extreme scores incorrect pos:neg 36 18\n",
            "Accuracy: 70.90% Precision: 71.03% Recall: 74.10%\n",
            "F1: 72.54% MCC: 0.4165\n",
            "AUPRC: 75.69% AUROC: 76.07%\n",
            " accuracy [70.8955223880597]\n",
            " precision [71.03448275862068]\n",
            " recall [74.10071942446042]\n",
            " F1 [72.53521126760563]\n",
            " MCC [0.4165423493359058]\n",
            " AUPRC [75.6919487168029]\n",
            " AUROC [76.06519435614298]\n",
            "\n",
            "Training # 2 3\n",
            "2023-04-20 16:33:09.366011\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.3.validation_genes.txt\n",
            "2023-04-20 16:33:09.385433\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1050:1041 50.22%\n",
            "Valid 1:0 271:245 52.52%\n",
            "FIT\n",
            "2023-04-20 16:33:09.405731\n",
            "\n",
            "Testing # 2 3\n",
            "2023-04-20 16:33:22.183816\n",
            "2023-04-20 16:33:22.183878\n",
            "PREDICT\n",
            "2023-04-20 16:33:22.188070\n",
            "debug pred [0.5, 0.807981723549303, 0.5422819410818301]\n",
            "debug class [0 1 1]\n",
            "Test 1:0 271:245 52.52%\n",
            "Predict 1:0 264:252 51.16%\n",
            "Test sizes (516, 1025) (516,)\n",
            "Distrib of scores: 0.5064061623909488 mean 0.1963375444918755 std\n",
            "Range of scores: 0.0511125274278009 to 0.9412439690726842\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[163  82]\n",
            " [ 89 182]]\n",
            "Normalized matrix\n",
            " [[0.31589147 0.15891473]\n",
            " [0.17248062 0.35271318]]\n",
            "Extreme scores correct, pos:neg 94 92\n",
            "Extreme scores incorrect pos:neg 45 22\n",
            "Accuracy: 66.86% Precision: 68.94% Recall: 67.16%\n",
            "F1: 68.04% MCC: 0.3366\n",
            "AUPRC: 69.01% AUROC: 71.53%\n",
            " accuracy [66.86046511627907]\n",
            " precision [68.93939393939394]\n",
            " recall [67.15867158671587]\n",
            " F1 [68.03738317757009]\n",
            " MCC [0.33655591879463387]\n",
            " AUPRC [69.00907008996587]\n",
            " AUROC [71.53400105429625]\n",
            "\n",
            "Training # 2 4\n",
            "2023-04-20 16:33:24.308734\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.4.validation_genes.txt\n",
            "2023-04-20 16:33:24.325080\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1080:1019 51.45%\n",
            "Valid 1:0 241:267 47.44%\n",
            "FIT\n",
            "2023-04-20 16:33:24.343370\n",
            "\n",
            "Testing # 2 4\n",
            "2023-04-20 16:33:37.360270\n",
            "2023-04-20 16:33:37.360326\n",
            "PREDICT\n",
            "2023-04-20 16:33:37.365379\n",
            "debug pred [0.40896895041050646, 0.47284314469363714, 0.6790870219530117]\n",
            "debug class [0 0 1]\n",
            "Test 1:0 241:267 47.44%\n",
            "Predict 1:0 263:245 51.77%\n",
            "Test sizes (508, 1025) (508,)\n",
            "Distrib of scores: 0.5033780836569113 mean 0.2039519451904508 std\n",
            "Range of scores: 0.04997692145238257 to 0.9518551925647688\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[168  99]\n",
            " [ 77 164]]\n",
            "Normalized matrix\n",
            " [[0.33070866 0.19488189]\n",
            " [0.1515748  0.32283465]]\n",
            "Extreme scores correct, pos:neg 90 96\n",
            "Extreme scores incorrect pos:neg 38 27\n",
            "Accuracy: 65.35% Precision: 62.36% Recall: 68.05%\n",
            "F1: 65.08% MCC: 0.3095\n",
            "AUPRC: 66.42% AUROC: 71.69%\n",
            " accuracy [65.35433070866141]\n",
            " precision [62.3574144486692]\n",
            " recall [68.04979253112033]\n",
            " F1 [65.07936507936508]\n",
            " MCC [0.30949984707117884]\n",
            " AUPRC [66.41844998545305]\n",
            " AUROC [71.68943385083996]\n",
            "\n",
            "Training # 2 5\n",
            "2023-04-20 16:33:39.558952\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.5.validation_genes.txt\n",
            "2023-04-20 16:33:39.574900\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1051:1026 50.60%\n",
            "Valid 1:0 270:260 50.94%\n",
            "FIT\n",
            "2023-04-20 16:33:39.591534\n",
            "\n",
            "Testing # 2 5\n",
            "2023-04-20 16:33:52.101582\n",
            "2023-04-20 16:33:52.101879\n",
            "PREDICT\n",
            "2023-04-20 16:33:52.105602\n",
            "debug pred [0.5914103738063413, 0.6123625659713926, 0.3907510500350286]\n",
            "debug class [1 1 0]\n",
            "Test 1:0 270:260 50.94%\n",
            "Predict 1:0 265:265 50.00%\n",
            "Test sizes (530, 1025) (530,)\n",
            "Distrib of scores: 0.50527008320784 mean 0.18356784200845502 std\n",
            "Range of scores: 0.062245339901789466 to 0.9538171945943299\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[174  86]\n",
            " [ 91 179]]\n",
            "Normalized matrix\n",
            " [[0.32830189 0.16226415]\n",
            " [0.17169811 0.33773585]]\n",
            "Extreme scores correct, pos:neg 91 85\n",
            "Extreme scores incorrect pos:neg 34 28\n",
            "Accuracy: 66.60% Precision: 67.55% Recall: 66.30%\n",
            "F1: 66.92% MCC: 0.3321\n",
            "AUPRC: 71.00% AUROC: 71.23%\n",
            " accuracy [66.60377358490565]\n",
            " precision [67.54716981132076]\n",
            " recall [66.2962962962963]\n",
            " F1 [66.91588785046729]\n",
            " MCC [0.33213459668241474]\n",
            " AUPRC [71.00406872524272]\n",
            " AUROC [71.23361823361823]\n",
            "2023-04-20 16:33:54.245967\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "\n",
        "accuracy=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "f1=[]\n",
        "mcc=[]\n",
        "auprc=[]\n",
        "auroc=[]\n",
        "\n",
        "loader = DataLoader()\n",
        "filepath = DATA_DIR+RCI_FILE_TRAIN\n",
        "print(\"Load RCI from\",filepath)\n",
        "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
        "print('Num RCI:', len(gene_to_rci.keys()))\n",
        "filepath = DATA_DIR+SEQ_FILE_TRAIN\n",
        "print('Load sequence from',filepath)\n",
        "allids,allseq = loader.load_spectra(filepath)  # for MLP (load_sequence() for CNN)\n",
        "print('Loaded',len(allseq),'sequences.')\n",
        "test_gene_to_rci = None\n",
        "test_allids = None\n",
        "test_allseq = None\n",
        "if SEQ_FILE_TEST is not None:\n",
        "    # Train on the entire train set (no cross-validation).\n",
        "    # Evaluate with the test files.\n",
        "    test_loader = DataLoader()\n",
        "    filepath = DATA_DIR+RCI_FILE_TEST\n",
        "    print(\"Load RCI from\",filepath)\n",
        "    test_gene_to_rci = test_loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
        "    print('Num RCI:', len(test_gene_to_rci.keys()))\n",
        "    filepath = DATA_DIR+SEQ_FILE_TEST\n",
        "    print('Load sequence from',filepath)\n",
        "    test_allids,test_allseq = test_loader.load_spectra(filepath)\n",
        "    print('Loaded',len(test_allseq),'sequences.')\n",
        "\n",
        "for repeat in range(REPEATS):\n",
        "    for fold in range(FOLDS):\n",
        "        show_r = repeat+1  # display one-based counting\n",
        "        show_f = fold+1    # display one-based counting\n",
        "\n",
        "        print()\n",
        "        print(\"Training #\",show_r,show_f)\n",
        "        print(datetime.now())\n",
        "        cvdo = CrossValidator(EPOCHS)\n",
        "        cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
        "        if SEQ_FILE_TEST is None:\n",
        "            # Train on 80% and evaluate on 20%.\n",
        "            separator = Separator()\n",
        "            separator.load(DATA_DIR,show_r,show_f)\n",
        "            separator.process(allids,allseq,gene_to_rci)\n",
        "            train_allids,test_allids = separator.get_ids()\n",
        "            train_allseq,test_allseq = separator.get_seq()\n",
        "            train_gene_to_rci,test_gene_to_rci = separator.get_rci()\n",
        "            cvdo.train_new_model(\n",
        "                train_allids,train_allseq,train_gene_to_rci,\n",
        "                test_allids,test_allseq,test_gene_to_rci)\n",
        "            if SAVE_MODEL_FILENAME is not None:\n",
        "                filename = f\"{SAVE_MODEL_FILENAME}.{show_r}.{show_f}.model\"\n",
        "                cvdo.save_model(filename)\n",
        "        else:\n",
        "            # Train on the entire train set (no cross-validation).\n",
        "            # Evaluate with the test files.\n",
        "            train_allids = allids\n",
        "            train_allseq = allseq\n",
        "            train_gene_to_rci = gene_to_rci\n",
        "            BREAK = True\n",
        "            cvdo.train_new_model(\n",
        "                train_allids,train_allseq,train_gene_to_rci,\n",
        "                None,None,None)\n",
        "\n",
        "        print()\n",
        "        print(\"Testing #\",show_r,show_f)\n",
        "        print(datetime.now())\n",
        "        cvdo.reset_statistics()\n",
        "        cvdo.test_without_training(\n",
        "            test_allids,test_allseq,test_gene_to_rci)\n",
        "        cv_accuracy,cv_precision,cv_recall,cv_f1,cv_mcc,cv_auprc,cv_auroc=\\\n",
        "            cvdo.get_statistics()\n",
        "\n",
        "        print(\" accuracy\" ,  cv_accuracy)\n",
        "        print(\" precision\" , cv_precision)\n",
        "        print(\" recall\" ,    cv_recall)\n",
        "        print(\" F1\" ,        cv_f1)\n",
        "        print(\" MCC\" ,       cv_mcc)\n",
        "        print(\" AUPRC\" ,     cv_auprc)\n",
        "        print(\" AUROC\" ,     cv_auroc)\n",
        "\n",
        "        accuracy.append(cv_accuracy)\n",
        "        precision.append(cv_precision)\n",
        "        recall.append(cv_recall)\n",
        "        f1.append(cv_f1)\n",
        "        mcc.append(cv_mcc)\n",
        "        auprc.append(cv_auprc)\n",
        "        auroc.append(cv_auroc)\n",
        "        if BREAK: break\n",
        "    if BREAK: break\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkCeDg_HdQ36",
        "outputId": "653d99ae-b1a5-49aa-c516-747a913d75bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " accuracy mean 67.40% std 1.71\n",
            " precision mean 67.51% std 2.71\n",
            " recall mean 68.79% std 3.54\n",
            " F1 mean 68.08% std 2.28\n",
            " MCC mean 0.3486 std 0.0339\n",
            " AUPRC mean 70.23% std 2.93\n",
            " AUROC mean 72.46% std 1.53\n",
            " accuracy [[66.16541353383458], [69.06077348066299], [68.83629191321499], [67.52988047808765], [66.73040152963671], [65.95744680851064], [70.8955223880597], [66.86046511627907], [65.35433070866141], [66.60377358490565]]\n",
            " precision [[64.15770609318996], [68.55123674911661], [66.54804270462633], [70.25862068965517], [69.31407942238266], [66.40926640926641], [71.03448275862068], [68.93939393939394], [62.3574144486692], [67.54716981132076]]\n",
            " recall [[69.1119691119691], [71.06227106227107], [74.5019920318725], [63.42412451361867], [68.32740213523132], [65.90038314176245], [74.10071942446042], [67.15867158671587], [68.04979253112033], [66.2962962962963]]\n",
            " F1 [[66.54275092936803], [69.78417266187049], [70.30075187969925], [66.66666666666666], [68.81720430107526], [66.15384615384615], [72.53521126760563], [68.03738317757009], [65.07936507936508], [66.91588785046729]]\n",
            " MCC [[0.3250953088317443], [0.38132949879018896], [0.38005695471987516], [0.3535221419841441], [0.3316930887599853], [0.31914575227844216], [0.4165423493359058], [0.33655591879463387], [0.30949984707117884], [0.33213459668241474]]\n",
            " AUPRC [[67.10621964539894], [70.04772149581157], [69.51873324815686], [71.88740643807535], [73.74149550964168], [67.86513382402927], [75.6919487168029], [69.00907008996587], [66.41844998545305], [71.00406872524272]]\n",
            " AUROC [[71.55302869588584], [71.99362366029033], [73.08578187250995], [73.24863019137618], [73.34048998558865], [70.90592073754789], [76.06519435614298], [71.53400105429625], [71.68943385083996], [71.23361823361823]]\n"
          ]
        }
      ],
      "source": [
        "def STD (values):\n",
        "    # ddof=1 reduces bias when extrapolating from sample to population\n",
        "    return np.std(values,ddof=1)\n",
        "\n",
        "print(\" accuracy mean %.2f%% std %.2f\" %  (np.mean(accuracy),  STD(accuracy)))\n",
        "print(\" precision mean %.2f%% std %.2f\" % (np.mean(precision), STD(precision)))\n",
        "print(\" recall mean %.2f%% std %.2f\" %    (np.mean(recall),    STD(recall)))\n",
        "print(\" F1 mean %.2f%% std %.2f\" %        (np.mean(f1),        STD(f1)))\n",
        "print(\" MCC mean %.4f std %.4f\" %       (np.mean(mcc),       STD(mcc)))\n",
        "print(\" AUPRC mean %.2f%% std %.2f\" %     (np.mean(auprc),     STD(auprc)))\n",
        "print(\" AUROC mean %.2f%% std %.2f\" %     (np.mean(auroc),     STD(auroc)))\n",
        "\n",
        "print(\" accuracy\"  , accuracy)\n",
        "print(\" precision\" , precision)\n",
        "print(\" recall\"    , recall)\n",
        "print(\" F1\"        , f1)\n",
        "print(\" MCC\"       , mcc)\n",
        "print(\" AUPRC\"     , auprc)\n",
        "print(\" AUROC\"     , auroc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "QjSVa72v4IsA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}